This file was created with JabRef 1.8.1.
Encoding: Cp1252

@INBOOK{konrad00,
  chapter = {3.10},
  pages = {207--225},
  title = {Motion Detection and Estimation},
  publisher = {Academic Press},
  year = {2000},
  author = {Konrad, Janusz},
  type = {Chapter},
  crossref = {bovik00},
  key = {konr00},
}

@INBOOK{murat00,
  chapter = {4.8},
  pages = {383--399},
  title = {Video Segmentation},
  publisher = {Academic Press},
  year = {2000},
  author = {Murat Tekalp, A.},
  type = {Chapter},
  crossref = {bovik00},
  key = {mura00},
}

@INPROCEEDINGS{aach93,
  author = {Aach, Til and Kaup, Andr{\'e} and Mester, Rudolf},
  title = {Change detection in image sequences using Gibbs Random Fields: A
	Bayesian approach},
  booktitle = {International Workshop on Intelligent Signal Processing and Communication
	Systems {{ISPACS}--1993}},
  year = {1993},
  pages = {56--61},
  address = {Sendai, Japan},
  month = {October},
  abstract = {Conventional nonadaptive methods for change detection suffer from
	the dilemma of either causing lots of false alarms or missing considerable
	parts of nonstationary areas. This contribution presents a way out
	of this dilemma by viewing change detection as an inverse, ill--posed
	problem. As such, the problem can be solved using prior knowledge
	about typical properties of change masks. This reasoning leads to
	a Bayesian formulation of change detection, where the prior knowledge
	is brought to bear by appropriately specified a priori probabilities.
	Based on this approach, a new, adaptive algorithm for change detection
	with drastically improved performance is derived. The algorithm
	requires only a single raster scan per picture, thus increasing
	the computational load only slightly in comparison to conventional
	nonadaptive techniques.},
  key = {Aach93},
  keywords = {Change Detection, Gibbs Random Fields},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\change
	detection\Change Detection in Image Sequences Using Gibbs Random
	Fields_A Bayesian Approach (T. Aach, A. Kaup and R. Mester).pdf},
}

@ARTICLE{abidi04,
  author = {Abidi, Besma and Liang, Jimin and Mitckes, Mark and Abidi, Mongi},
  title = {Improving the Detection of Low--Density Weapons in X--Ray Luggage
	Scans using Image Enhancement and Novel Scene--Decluttering Techniques},
  journal = {Journal of Electronic Imaging},
  year = {2004},
  volume = {13},
  pages = {523--538},
  number = {3},
  month = {July},
  abstract = {Very few image processing applications have dealt with x-ray luggage
	scenes in the past. Concealed threats in general, and low--density
	items in particular, pose a major challenge to airport screeners.
	A simple enhancement method for data decluttering is introduced.
	Initially, the method is applied using manually selected thresholds
	to progressively generate decluttered slices. Further automation
	of the algorithm, using a novel metric based on the Radon transform,
	is conducted to determine the optimum number and values of thresholds
	and to generate a single optimum slice for screener interpretation.
	A comparison of the newly developed metric to other known metrics
	demonstrates the merits of the new approach. On--site quantitative
	and qualitative evaluations of the various decluttered images by
	airport screeners further establishes that the single slice from
	the image hashing algorithm outperforms traditional enhancement
	techniques with a noted increase of 58% in low--density threat detection
	rates.},
  doi = {10.1117/1.1760571},
  keywords = {LIP},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\LIP\Improving
	the detection of low-density weapons in x-ray etc (B Abidi et al).pdf},
}

@ARTICLE{baylor79,
  author = {Baylor, D. A. and Lamb, T.D. and Yau, K.W.},
  title = {Responses of Retinal Rods to Single Photons},
  journal = {Journal of Physiology},
  year = {1979},
  volume = {288},
  pages = {613--634},
  number = {1},
  month = {March},
  abstract = {1. A suction electrode was used to record the membrane current of
	single rod outer segments in pieces of toad retina. During dim illumination
	the membrane current showed pronounced fluctuations. 2. Amplitude
	histograms of responses to dim flashes of fixed intensity exhibited
	two discrete peaks, one at 0 pA and one near 1 pA, suggesting that
	the response was quantized. By setting a criterion amplitude level,
	flash responses could be classed as 'failures' (no response) or
	as 'successes' (at least one quantal event). 3. The variation of
	fraction of successes with flash intensity was consistent with the
	hypothesis that each quantal electrical event resulted from a single
	photoisomerization. 4. The quantal event had a mean amplitude of
	about 1 pA (5% of the standing dark current) and a standard deviation
	of 0.2 pA. Dispersion in the event amplitude prevented identification
	of histogram peaks corresponding to two or more photoisomerizations.
	5. Individual quantal responses exhibited a smooth shape very similar
	to that of the average quantal response. This suggests that a single
	photoisomerization releases many particles of transmitter and that
	radial diffusion of internal transmitter is not a major source of
	delay in the light response. 6. The 'quantum efficiency' with which
	an absorbed photon generated an electrical event was measured as
	0.5 +/- 0.1 (S.E. of mean, n = 4). This is slightly lower than the
	quantum efficiency of photoisomerization obtained previously for
	rhodopsin in solution. 7. At wavelengths between 420 and 700 nm
	the quantal event was invariant in size, although the cell's sensitivity
	varied over a range of 10(5). 8. The power spectrum of the fluctuations
	in dim steady light was predicted by assuming that a random series
	of quantal events occurred independently. 9. In brighter light the
	fluctuations were faster, and the response to an incremental flash
	was reduced in size and duration. The power spectrum could be predicted
	by assuming random superposition of events with the shape of the
	incremental flash response.},
}

@INPROCEEDINGS{bichsel94,
  author = {Bichsel, Martin},
  title = {Illumination invariant motion segmentation of simply connected objects},
  booktitle = {Proceedings of the 5th British Machine Vision Conference {BMVC--1994}},
  year = {1994},
  pages = {459--468},
  address = {York, UK.},
  month = {13--16, September},
  abstract = {A new segmentation algorithm exploits local image quantities which
	are invariant to changing illumination. Local object--background
	probability estimates are obtained by comparing illumination invariant
	quantities in an actual image with the corresponding quantities
	in a reference image. The objects' simply connectedness is included
	directly into the probability estimates and leads to an iterative
	optimization procedure that is implemented efficiently. This new
	approach avoids early thresholding, explicit edge detection, motion
	analysis, and grouping.},
  key = {bich93},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\illumination-invariant-motion-segmentation.pdf},
}

@ARTICLE{bichsel94b,
  author = {Bichsel, Martin},
  title = {Segmenting Simply Connected Moving Objects in a Static Scene},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {1994},
  volume = {16},
  pages = {1138--1142},
  number = {11},
  month = {November},
  abstract = {A new segmentation algorithm is derived, based on an object-background
	probability estimate exploting the experimental fact that the statistics
	of local image derivatives show a Laplacian distribution. The objects'
	simple connectedness is included directly into the probability estimate
	and leads to an iterative optimization approach that can be implemented
	efficiently. This new approach avoids early thresholding, explicit
	edge detection, motion analysis, and grouping.},
  doi = {10.1109/34.334396},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\Simply
	connected (Bichsel).pdf},
}

@BOOK{bovik00,
  title = {Handbook of Image and Video Processing},
  publisher = {Academic Press},
  year = {2000},
  editor = {Bovik, Al},
  author = {Bovik, Al},
  series = {ISBN: 0--12--119790--5},
  address = {San Diego (CA), USA and London, UK.},
  edition = {First Edition},
  key = {bovi00},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\libros\Image
	& Video Processing\Handbook of Image and Video Processing (Al Bovik)
	Academic Press - 2000 .pdf},
}

@INPROCEEDINGS{brostow01,
  author = {Brostow, Gabriel J. and Essa, Irfan},
  title = {Image--Based Motion Blur for Stop Motion Animation},
  booktitle = {Proceedings of the 28th Annual Conference on Computer Graphics and
	Interactive Techniques, SIGGRAPH'01},
  year = {2001},
  pages = {561--566},
  address = {Los Angeles, (CA), USA},
  month = {August},
  abstract = {Stop motion animation is a well--established technique where still
	pictures of static scenes are taken and then played at film speeds
	to show motion. A major limitation of this method appears when fast
	motions are desired; most motion appears to have sharp edges and
	there is no visible motion blur. Appearance of motion blur is a
	strong perceptual cue, which is automatically present in live--action
	films, and synthetically generated in animated sequences. In this
	paper, we present an approach for automatically simulating motion
	blur. Ours is wholly a post-process, and uses image sequences, both
	stop motion or raw video, as input. First we track the frame--to--frame
	motion of the objects within the image plane. We then integrate
	the scene's appearance as it changed over a period of time. This
	period of time corresponds to shutter speed in live-action filming,
	and gives us interactive control over the extent of the induced
	blur. We demonstrate a simple implementation of our approach as
	it applies to footage of different motions and to scenes of varying
	complexity. Our photorealistic renderings of these input sequences
	approximate the effect of capturing moving objects on film that
	is exposed for finite periods of time.},
  doi = {10.1145/383259.383325},
}

@ARTICLE{bruni04,
  author = {Bruni, Vittoria and Vitulano, Domenico},
  title = {A Generalized Model for Scratch Detection},
  journal = {IEEE Transactions on Image Processing},
  year = {2004},
  volume = {13},
  pages = {44--50},
  number = {1},
  month = {January},
  abstract = {This paper presents a generalization of Kokaram's model for scratch
	lines detection on digital film materials. It is based on the assumption
	that scratch is not purely additive on a given image but shows also
	a destroying effect. This result allows us to design a more efficacious
	scratch detector which performs on a hierarchical representation
	of a degraded image, i.e., on its cross section local extrema. Thanks
	to Weber's law, the proposed detector even works well on slight
	scratches resulting completely automatic, except for the scratch
	color (black or white). The experimental results show that the proposed
	detector works better in terms of good detection and false alarms
	rejection with a lower computing time.},
  doi = {10.1109/TIP.2003.817231},
}

@ARTICLE{bruzzone02,
  author = {Bruzzone, Lorenzo and Fern\'andez Prieto, Diego},
  title = {An adaptive semiparametric and context--based approach to unsupervised
	change detection in multitemporal remote--sensing images},
  journal = {IEEE Transactions on Image Processing},
  year = {2002},
  volume = {11},
  pages = {452--466},
  number = {4},
  month = {April},
  abstract = {A novel automatic approach to the unsupervised identification of changes
	in multitemporal remote-sensing images is proposed. This approach,
	unlike classical ones, is based on the formulation of the unsupervised
	change-detection problem in terms of the Bayesian decision theory.
	In this context, an adaptive semiparametric technique for the unsupervised
	estimation of the statistical terms associated with the gray levels
	of changed and unchanged pixels in a difference image is presented.
	Such a technique exploits the effectivenesses of two theoretically
	well-founded estimation procedures: the reduced Parzen estimate
	(RPE) procedure and the expectation-maximization (EM) algorithm.
	Then, thanks to the resulting estimates and to a Markov random field
	(MRF) approach used to model the spatial-contextual information
	contained in the multitemporal images considered, a change detection
	map is generated. The adaptive semiparametric nature of the proposed
	technique allows its application to different kinds of remote-sensing
	images. Experimental results, obtained on two sets of multitemporal
	remote-sensing images acquired by two different sensors, confirm
	the validity of the proposed approach},
  doi = {10.1109/TIP.2002.999678},
  key = {bruz02},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\An
	adaptive semiparametric and context--based approach to unsupervised
	change detection (Bruzzone and Fernandez Prieto).pdf},
}

@INPROCEEDINGS{bruzzone99,
  author = {Bruzzone, Lorenzo and Fern\'andez Prieto, Diego},
  title = {An {MRF} approach to unsupervised change detection},
  booktitle = {Proceedings of the 1999 International Conference on Image Processing
	{(ICIP--1999)}},
  year = {1999},
  volume = {1},
  pages = {143--147},
  address = {Kobe, Japan.},
  month = {24--28, October},
  doi = {10.1109/ICIP.1999.821583},
  key = {bruz99},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\An
	MRF Approach to Unsupervised Change Detection.pdf},
}

@INPROCEEDINGS{cahill97,
  author = {Cahill, Lawrence W. and Deng, Guang},
  title = {An overview of logarithm--based image processing techniques for biomedical
	applications},
  booktitle = {Proceedings of the 13th International Conference on Digital Signal
	Processing {{DSP}--1997}},
  year = {1997},
  volume = {1},
  pages = {93--96},
  address = {Santorini, Greece.},
  month = {2--4, July},
  abstract = {Logarithm--based image processing methods are of interest since they
	have the capability to enhance low--contrast images. This paper
	presents an overview of the three logarithm--based image processing
	techniques: the multiplicative homomorfic system (MHS), the Log--ratio
	(LR) and the logarithmic image processing model (LIP). They are
	compared from physical, computational, and application point of
	views.},
  doi = {10.1109/ICDSP.1997.627976},
  keywords = {LIP},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\LIP\An
	overview of Logarithm-based Image processing techniques f.pdf},
}

@ARTICLE{canny86,
  author = {Canny, John},
  title = {A Computational Approach to Edge Detection},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {1986},
  volume = {8},
  pages = {679--698},
  number = {6},
  month = {November},
}

@INPROCEEDINGS{cavallaro02,
  author = {Cavallaro, Andrea and Gelasca, Elisa Drelie and Ebrahimi, Touradj},
  title = {Objective evaluation of segmentation quality using spatio--temporal
	context},
  booktitle = {Proceedings of the 2002 International Conference on Image Processing
	{(ICIP--2002)}},
  year = {2002},
  volume = {3},
  pages = {301---304},
  abstract = {In this paper, we propose an automatic method for the objective evaluation
	of segmentation results. The method is based on computing the deviation
	of the segmentation results from a reference segmentation. The discrepancy
	between two results is weighted based on spatial and temporal contextual
	information, by taking into account the way humans perceive visual
	information. The metric is useful for applications where the final
	judge of the quality is a human observer or the results of segmentation
	are otherwise processed in a human-like fashion. The proposed evaluation
	has been applied both to automatically provide a ranking among different
	segmentation algorithms and to optimally set the parameters of a
	given algorithm.},
  doi = {10.1109/ICIP.2002.1038965},
  key = {cava02},
}

@ARTICLE{comaniciu02,
  author = {Comaniciu, Dorin and Meer, Peter},
  title = {Mean Shift: A Robust Approach toward Feature Space Analysis},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {2002},
  volume = {24},
  pages = {603--619},
  number = {5},
  month = {May},
  abstract = {A general non--parametric technique is proposed for the analysis of
	a complex multimodal feature space and to delineate arbitrarily
	shaped clusters in it. The basic computational module of the technique
	is an old pattern recognition procedure: the mean shift. For discrete
	data, we prove the convergence of a recursive mean shift procedure
	to the nearest stationary point of the underlying density function
	and, thus, its utility in detecting the modes of the density. The
	relation of the mean shift procedure to the Nadaraya--Watson estimator
	from kernel regression and the robust M--estimators; of location
	is also established. Algorithms for two low--level vision tasks
	discontinuity--preserving smoothing and image segmentation --- are
	described as applications. In these algorithms, the only user-set
	parameter is the resolution of the analysis, and either gray--level
	or color images are accepted as input. Extensive experimental results
	illustrate their excellent performance.},
  doi = {10.1109/34.1000236},
  key = {coma02},
  keywords = {Mean Shift},
}

@INPROCEEDINGS{comaniciu97,
  author = {Comaniciu, Dorin and Meer, Peter},
  title = {Robust Analysis of Features Spaces: Color Image Segmentation},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition {{CVPR}--1997}},
  year = {1997},
  pages = {750--755},
  address = {San Juan, Puerto Rico.},
  month = {17--19, June},
  abstract = {A general technique for the recovery of significant image features
	is presented. The technique is based on the mean shift algorithm,
	a simple nonparametric procedure for estimating density gradients.
	Drawbacks of the current methods (including robust clustering) are
	avoided. Feature space of any nature can be processed, and as an
	example, color image segmentation is discussed. The segmentation
	is completely autonomous, only its class is chosen by the user.
	Thus, the same program can produce a high quality edge image, or
	provide, by extracting all the significant colors, a preprocessor
	for content-based query systems. A 512×512 color image is analyzed
	in less than 10 seconds on a standard workstation. Gray level images
	are handled as color images having only the lightness coordinate},
  doi = {10.1109/CVPR.1997.609410},
  key = {coma97},
}

@INPROCEEDINGS{comaniciu00,
  author = {Comaniciu, Dorin and Visvanathan, Ramesh and Meer, Peter},
  title = {Real--Time Tracking of Non--Rigid Objects using Mean Shift},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition {{CVPR}--2000}},
  year = {2000},
  volume = {2},
  pages = {142--149},
  address = {Hilton Head Island (SC), USA.},
  month = {13--15, June},
  note = {Best Paper Award},
  abstract = {A new method for real time tracking of non-rigid objects seen from
	a moving camera is proposed. The central computational module is
	based on the mean shift iterations and finds the most probable target
	position in the current frame. The dissimilarity between the target
	model (its color distribution) and the target candidates is expressed
	by a metric derived from the Bhattacharyya coefficient. The theoretical
	analysis of the approach shows that it relates to the Bayesian framework
	while providing a practical, fast and efficient solution. The capability
	of the tracker to handle in real time partial occlusions, significant
	clutter, and target scale variations, is demonstrated for several
	image sequences.},
  doi = {10.1109/CVPR.2000.854761},
  key = {coma00},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\mean
	shift\Real-Time Tracking of Non-Rigid Objects using Mean Shift (Comaniciu
	and Ramesh and Meer).pdf},
}

@ARTICLE{courbebaisse02,
  author = {Courbebaisse, Guy and Trunde, Frederic and Jourlin, Michel},
  title = {Wavelet Transform and LIP Model},
  journal = {Image Analysis and Stereology},
  year = {2002},
  volume = {21},
  pages = {121--125},
  number = {2},
  month = {June},
  abstract = {The Fourier transform is well suited to the study of stationary functions.
	Yet, it is superseded by the Wavelet transform for the powerful
	characterizations of function features such as singularities. On
	the other hand, the LIP (Logarithmic Image Processing) model is
	a mathematical framework developed by Jourlin and Pinoli, dedicated
	to the representation and processing of gray tones images called
	hereafter logarithmic images. This matematically well defined model,
	comprising a Fourier Transform "of its own", provides an effective
	tool for the representation of images obtained by transmitted light,
	such as microscope images. This paper presents a Wavelet transform
	within the LIP framework, with preservation of the classical Wavelet
	Transform properties. We show that the fast computation algorithm
	due to Mallat can be easily used. An application is given for the
	detection of crests.},
  keywords = {LIP, Logarithmic Wavelet Transform, Wavelet Transform},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\LIP\Wavelet
	transform and LIP model (G Courbebaisse, F Trunde and M Jourlin).pdf},
  url = {http://www.wise-t.com/ias/download.php?article_id=93},
}

@TECHREPORT{dawsonhowe96,
  author = {Dawson--Howe, Kenneth M.},
  title = {Active surveillance using dynamic background subtraction},
  institution = {Trinity College Dublin},
  year = {1996},
  type = {Technical Report},
  number = {TCD--CS--96--06},
  address = {Trinity College Dublin. Department of Computer Science. Computer
	Vision and Robotics Group.},
  month = {August},
  abstract = {A prototype active surveillance system is presented. The system has
	two cameras, one of which is rigidly fixed & has a wide angle lenses
	while the other is mounted on a pan--tilt head & has a zoomed lenses.
	The images from the wide angle camera are analyzed using dynamic
	background subtraction together with normalized cross correlation
	in order to identify moving people within the scene. An approximate
	mapping is determined (off--line) between the pan--tilt angles and
	the position of the zoomed image within the wide--angle view. This
	mapping is improved (for each frame) through 1--D image based correlation
	and hence moving people are located in the zoomed view. The system
	has been tested on a difficult real--world scene and image sequences
	from both cameras are presented. The potential of the system as
	an `intelligent' security device and the power of the dynamic background
	subtraction & correlation mechanism are clearly demonstrated.},
  key = {daws96},
  keywords = {Change Detection},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\background
	subtraction\dawson-howe96active.pdf},
  url = {ftp://ftp.cs.tcd.ie/pub/tcd/tech-reports/reports.96/TCD-CS-96-06.ps.gz},
}

@ARTICLE{delorme01,
  author = {Delorme, Arnaud and Thorpe, Simon J.},
  title = {Face Identification using One Spike per Neuron: Resistance to Image
	Degradations},
  journal = {Neural Networks},
  year = {2001},
  volume = {14},
  pages = {795--803},
  number = {6--7},
  month = {July--September},
  abstract = {The short response latencies of face selective neurons in the inferotemporal
	cortex impose major constraints on models of visual processing.
	It appears that visual information must essentially propagate in
	a feed-forward fashion with most neurons only having time to fire
	one spike. We hypothesize that flashed stimuli can be encoded by
	the order of firing of ganglion cells in the retina and propose
	a neuronal mechanism, that could be related to fast shunting inhibition,
	to decode such information. Based on these assumptions, we built
	a three-layered neural network of retino-topically organized neuronal
	maps. We showed, by using a learning rule involving spike timing
	dependant plasticity, that neuronal maps in the output layer can
	be trained to recognize natural photographs of faces. Not only was
	the model able to generalize to novel views of the same faces, it
	was also remarkably resistant to image noise and reductions in contrast.},
  doi = {10.1016/S0893-6080(01)00049-1},
  keywords = {Rank Order Coding},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\Rank
	Order Coding\Rank order coding Face_identification.pdf},
}

@ARTICLE{dempster77,
  author = {Dempster, A. and Laird, N. and Rubin, Donald B.},
  title = {Maximum likelihood from incomplete data via {EM} algorithm},
  journal = {Journal of the Royal Statistical Society},
  year = {1977},
  volume = {1},
  pages = {1--38},
  number = {39 (Series B)},
  key = {demp77},
}

@ARTICLE{deng93,
  author = {Deng, Guang and Cahill, Lawrence W.},
  title = {Multiscale image enhancement using the logarithmic image processing
	model},
  journal = {Electronics Letters},
  year = {1993},
  volume = {29},
  pages = {803--804},
  number = {9},
  month = {April},
  abstract = {A multiscale image decomposition and enhancement algorithm is presented.
	This algorithm is developed using a mathematical structure called
	the logarithmic image processing model. This algorithm is a novel
	approach to improving image contrast, yet at the same time achieving
	noise suppression},
  keywords = {LIP},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\LIP\Multiscale
	Image Enhancement using the logarithmic image pro.pdf},
  url = {http://ieeexplore.ieee.org/xpl/abs_free.jsp?arNumber=211279},
}

@INPROCEEDINGS{deng93b,
  author = {Deng, Guang and Cahill, Lawrence W.},
  title = {The logarithmic image processing model and its applications},
  booktitle = {Proceedings of the 1993 27th Asilomar Conference on Signal, Systems
	and Computers},
  year = {1993},
  volume = {2},
  pages = {1047-1051},
  address = {Pacific Grove (CA), USA.},
  month = {1--3, November},
  abstract = {This paper presents a summary of operations of the logarithmic image
	processing (LIP) model and its applications. The LIP model is a
	mathematical framework which provides a set of generalised version
	of addition, subtraction, multiplication, convolution and so on,
	for signal processing. First, we briefly describe the LIP model
	and point out its distinctive properties for image processing. Then
	we summarize the current applications of the LIP model. A novel
	image filtering algorithm and its extension to multiscale processing
	along with the LIP model based Sobel operator for edge detection
	are discussed in detail. Finally, we suggest further research area
	of the LIP model},
  doi = {10.1109/ACSSC.1993.342410},
  keywords = {LIP},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\LIP\The
	Logarithmic Image Processing Model and its Applications .pdf},
}

@ARTICLE{deng95,
  author = {Deng, Guang and Cahill, Lawrence W. and Tobin, Geoffrey Richard},
  title = {The Study of Logarithmic Image--Processing Model and Its Application
	to Image--Enhancement},
  journal = {IEEE Transactions on Image Processing},
  year = {1995},
  volume = {4},
  pages = {506--512},
  number = {4},
  month = {april},
  abstract = {Describes a new implementation of Lee's (1980) image enhancement algorithm.
	This approach, based on the logarithmic image processing (LIP) model,
	can simultaneously enhance the overall contrast and the sharpness
	of an image. A normalized complement transform has been proposed
	to simplify the analysis and the implementation of the LIP model-based
	algorithms. This new implementation has been compared with histogram
	equalization and Lee's original algorithm},
  doi = {http://dx.doi.org/10.1109/83.370681},
  keywords = {LIP},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\LIP\Study
	of Log Image processing for Image Enhancement (Deng, C.pdf},
}

@ARTICLE{deng98,
  author = {Deng, Guang and Pinoli, Jean--Charles},
  title = {Differentiation--Based Edge Detection using the Logarithmic Image
	Processing Model},
  journal = {Journal of Mathematical Imaging and Vision},
  year = {1998},
  volume = {8},
  pages = {161--180},
  number = {2},
  month = {March},
  abstract = {The logarithmic image processing (LIP) model is a mathematical framework
	which provides a specific set of algebraic and functional operations
	for the processing and analysis of intensity images valued in a
	bounded range. The LIP model has been proved to be physically justified
	by that it is consistent with the multiplicative transmittance and
	reflectance image formation models, and with some important laws
	and characteristics of human brightness perception. This article
	addresses the edge detection problem using the LIP-model based differentiation.
	First, the LIP model is introduced, in particular, for the gray
	tones and gray tone functions, which represent intensity values
	and intensity images, respectively. Then, an extension of these
	LIP model notions, respectively called gray tone vectors and gray
	tone vector functions, is studied. Third, the LIP-model based differential
	operators are presented, focusing on their distinctive properties
	for image processing. Emphasis is also placed on highlighting the
	main characteristics of the LIP-model based differentiation. Next,
	the LIP-Sobel based edge detection technique is studied and applied
	to edge detection, showing its robustness in locally small changes
	in scene illumination conditions and its performance in the presence
	of noise. Its theoretical and practical advantages over several
	well-known edge detection techniques, such as the techniques of
	Sobel, Canny, Johnson and Wallis, are shown through a general discussion
	and illustrated by simulation results on different real images.
	Finally, a discussion on the role of the LIP-model based differentiation
	in the current context of edge detection is presented.},
  doi = {10.1023/A:1008277328822},
  keywords = {LIP},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\LIP\Differentiation-based
	Edge detection using the Logarithmic Image Processing.pdf},
}

@ARTICLE{cheng95,
  author = {Deng, Yizong},
  title = {Mean Shift, Mode Seeking and Clustering},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {1995},
  volume = {17},
  pages = {790--799},
  number = {8},
  month = {August},
  abstract = {Mean shift, a simple interactive procedure that shifts each data point
	to the average of data points in its neighborhood is generalized
	and analyzed in the paper. This generalization makes some k--means
	like clustering algorithms its special cases. It is shown that mean
	shift is a mode--seeking process on the surface constructed with
	a “shadow” kernal. For Gaussian kernels, mean shift is a gradient
	mapping. Convergence is studied for mean shift iterations. Cluster
	analysis if treated as a deterministic problem of finding a fixed
	point of mean shift that characterizes the data. Applications in
	clustering and Hough transform are demonstrated. Mean shift is also
	considered as an evolutionary strategy that performs multistart
	global optimization.},
  doi = {10.1109/34.400568},
  key = {chen95},
  keywords = {Mean Shift},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\mean
	shift\Mean Shift, Mode Seeking and Clustering (Cheng) IEEE PAMI
	17(8), 790-800, 1995.pdf},
}

@PHDTHESIS{durucan-tesis,
  author = {Durucan, Emrullah},
  title = {Low Computational Cost Illumination Invariant Change Detection for
	Video Surveillance by Linear Independence},
  school = {\'Ecole Polyt\'echnique F\'ederale de Lausanne},
  year = {2001},
  type = {Doctoral Thesis (Number: 2454)},
  month = {December},
  abstract = {The thesis investigates the detection of changes between images for
	the low-level part of automated video--surveillance. Change detection
	for video--surveillance comprises the detection of moving objects
	in a scene. The change detector should be illumination--invariant
	as well as noise--robust, and should work in real--time. Thus, to
	detect and examine changes between two gray--value images, we model
	the reference and the current image as vector ensembles, where the
	vector components correspond to pixels. The main assumption of this
	thesis is that, regardless of illumination in the current image,
	pairs of reference and current vectors are linearly dependent. However,
	if an object in the current image changes, then these pairs are
	linearly independent. Linear algebra provides different theorems
	to determine when vectors are linearly dependent. We use these to
	develop algorithms for detecting object changes in the current image.
	This application of linear independence is an innovation. The proposed
	methods were successfully tested on an extensive surveillance image
	database. The results show that our algorithms detect object changes
	while remaining illumination--invariant. These new methods compare
	favorably with competing change detection methods, including the
	Shading Model, the Statistical Change Detection and the Derivative
	Model. A new adaptive threshold further improves object detection
	and noise suppression. We also analyze the numbers of arithmetic
	operations and memory accesses (computational costs) for the new
	change detection algorithms, using a hypothetical computer model.
	The execution times suggest that our algorithms are real--time implementable.
	Finally, we extend the concept of linear independence to detecting
	changes between multiple images and between multispectral images.
	These extensions are also innovations for image change detection.
	Future applications could include fast image segmentation, image
	database searches and missing data replacement in old video sequences.},
  key = {duruTES},
  keywords = {Change Detection},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\thesis\Durucan\thesis_durucan.pdf},
  url = {http://library.epfl.ch/en/theses/?nr=2454},
}

@INPROCEEDINGS{durucan03,
  author = {Durucan, Emrullah and Ebrahimi, Touradj},
  title = {Moving object detection between multiple and color images},
  booktitle = {Proceedings of the 2003 IEEE Conference on Advanced Video and Signal
	Based Surveillance {(AVSS--2003)}},
  year = {2003},
  pages = {243--251},
  month = {21--23, July},
  abstract = {There are several publications dedicated to the description and analysis
	of change detection between two gray--value images. This paper introduces
	new methods to detect moving objects between multiple images and
	to detect changes between color images or any type of multispectral
	images. We are not aware of methods giving the possibility of detecting
	color changes and changes between multiple frames. All the proposed
	change detectors are based on the Gramian determinant, which provides
	low computational cost and is easy to implement. These features
	are very important due to the additional complexity of change detection
	between multiple as well as color images.},
  doi = {10.1109/AVSS.2003.1217928},
  key = {duru03},
  keywords = {Change Detection},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\change
	detection\Moving object detection between multiple and color images
	(D.pdf},
}

@ARTICLE{durucan01,
  author = {Durucan, Emrullah and Ebrahimi, Touradj},
  title = {Change detection and background extraction by linear algebra},
  journal = {Proceedings of the IEEE},
  year = {2001},
  volume = {89},
  pages = {1368--1381},
  number = {10},
  month = {October},
  abstract = {Change detection plays a very important role in real--time image analysis,
	e.g., detection of intruders. One key issue is robustness to varying
	illumination conditions. We propose two techniques for change detection
	that have been developed to deal with variations in illumination
	and background, with real--time capabilities. The foundations of
	these techniques are based on a vector model of images and on the
	exploitation of the concepts of linear dependence and linear independence.
	Furthermore, the techniques are compatible with physical photometry.
	A detailed description of the proposed detector and three state--of--the
	art change detectors is also provided. For the purposes of comparison,
	an evaluation procedure is presented consisting of both objective
	and subjective parts. This evaluation procedure results in a final
	performance value for each detector analyzed},
  doi = {10.1109/5.959336},
  key = {duru01},
  keywords = {Change Detection},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\change
	detection\Change Detection and Background Extraction by Linear Algebra.pdf},
}

@INPROCEEDINGS{durucan01b,
  author = {Durucan, Emrullah and Ebrahimi, Touradj},
  title = {Change Detection by nonlinear Grammian},
  booktitle = {Proceedings of the 2001 Non--linear Signal and Image Processing {(NSIP--2001)}},
  year = {2001},
  month = {September},
  key = {duru01b},
  keywords = {Change Detection},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\change
	detection\Change Detection by Nonlinear Grammian (Durucan and Ebrahimi)
	NSIP 2001.pdf},
}

@INPROCEEDINGS{durucan01c,
  author = {Durucan, Emrullah and Ebrahimi, Touradj},
  title = {Improved Linear Dependence and Vector Model for illumination invariant
	Change Detection},
  booktitle = {Proceedings of the Real--time Imaging, SPIE's Photonics West 2001
	-- Electronic Imaging Conference},
  year = {2001},
  volume = {4303},
  pages = {107--114},
  month = {April},
  abstract = {Change detection generally is the difference between images. The differences
	or changes could be due to moving objects or a variation of illumination.
	In general the goal is to extract only changes due to moving object
	that occur int eh scene, and to ignore changes due to illumination.
	A requirement is that the detection has to be performed in real-time.
	The proposed change detection approach relies on a model assigning
	a vector to every pixel of the reference and the current image.
	Based on this model, linear independence is used to describe an
	operator for change detection. This previously published operator
	is based on the variance. The improved linear independence model
	consists in redefining the change detection operator to fulfill
	the real-time requirement and to improve the object detection performance.
	This model has been applied to surveillance and compared to the
	variance based linear independence detector. The operator proved
	to be robust to background and illumination changes and in the same
	time it detected object changes.},
  doi = {10.1117/12.424945},
  key = {duru01c},
  keywords = {Change Detection},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\change
	detection\Improved Linear Dependence and Vector Model for Illumination
	Invariant Change Detection (Durucan and Ebrahimi) spie 2001.pdf},
}

@INPROCEEDINGS{durucan00,
  author = {Durucan, Emrullah and Ebrahimi, Touradj},
  title = {Robust and Illumination invariant change detection based on Linear
	Dependence for Surveillance Application},
  booktitle = {Proceedings of the 10th. European Signal Processing Conference 2000
	{(EUSIPCO--2000)}},
  year = {2000},
  volume = {2},
  pages = {1141--1144},
  month = {September},
  abstract = {The subject of this paper is to provide an illumination invariant
	moving object detector for indoor surveillance applications. Furthermore
	we want to treat the illumination change as a mathematical/physical
	transformation procedure on images. Therefore the intention to this
	paper could also be defined as to provide an operator, which is
	invariant to transformations. The proposed detector relies on a
	model assigning a vector to every pixel location of the reference
	and the current image. The vector represents information on the
	neighborhood region of that pixel. Based on the above definition,
	the theorem of linear dependence of vectors is used to describe
	an operator for the detection of objects. For the purpose of an
	objective evaluation, the proposed technique is compared to the
	state-of-the-art Statistical Change Detection method. The proposed
	operator proved to be robust to noise as well as global illumination
	changes and local shadows and reflections.},
  key = {duru00},
  keywords = {Change Detection},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\change
	detection\Robust and Illumination invariant change detection based
	on Linear Dependence for Surveillance Application(durucan and ebrahimi).pdf},
  url = {http://www.eurasip.org/content/Eusipco/2000/sessions/WedPm/SS1/cr1505.pdf},
}

@INPROCEEDINGS{durucan99,
  author = {Durucan, Emrullah and Snoeckx, Joel and Weilenmann, Yves},
  title = {Illumination invariant Background Extraction},
  booktitle = {Proceedings of the 10th. International Conference on Image Analysis
	and Processing 1999 {(ICIAP--1999)}},
  year = {1999},
  pages = {1136--1139},
  address = {Venice, Italy.},
  month = {27--29, September},
  abstract = {This paper proposes a new method for the extraction of background
	objects, especially the extraction of randomly moving objects such
	as curtains and plants. For this purpose we use an optical flow
	method combined with a split-and-merge algorithm to avoid the mentioned
	background effects. The split-and-merge algorithm is based on the
	variance of regions and the optical flow method is implemented conform
	to the proposition of Horn and Schunck (1981). To further increase
	the robustness and utility in surveillance circumstances, illumination
	invariance has to be provided by the algorithm. Hence we combined
	the mentioned methods with an illumination-invariant change detector.
	Tests have been performed on indoor and outdoor surveillance sequences.
	Especially in indoor sequences the proposed method provided a very
	robust tool against illumination changes, reflections, shadows and
	randomly moving objects like curtains and plants. Nevertheless in
	all circumstances it detected the moving `semantic' objects such
	as persons},
  doi = {10.1109/ICIAP.1999.797755},
  key = {duru99},
  keywords = {Change Detection},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\change
	detection\Illumination invariant background extraction (Durucan,
	Snoec.pdf},
}

@INPROCEEDINGS{elgammal00,
  author = {Elgammal, Ahmed and Harwood, David and Davis, Larry S.},
  title = {Non--parametric model for background subtraction},
  booktitle = {Proceedings of the 6th European Conference on Computer Vision {ECCV
	'00}},
  year = {2000},
  editor = {Vernon, David},
  volume = {Lecture Notes in Computer Science; Vol. 1843},
  series = {Part II},
  pages = {751--767},
  address = {Trinity College Dublin, Ireland.},
  month = {26 June--1 July},
  abstract = {Background subtraction is a method typically used to segment moving
	regions in image sequences taken from a static camera by comparing
	each new frame to a model of the scene background. We present a
	novel non--parametric background model and a background subtraction
	approach. The model can handle situations where the background of
	the scene is cluttered and not completely static but contains small
	motions such as tree branches and bushes. The model estimates the
	probability of observing pixel intensity values based on a sample
	of intensity values for each pixel. The model adapts quickly to
	changes in the scene which enables very sensitive detection of moving
	targets. We also show how the model can use color information to
	suppress detection of shadows. The implementation of the model runs
	in real-time for both gray level and color imagery. Evaluation shows
	that this approach achieves very sensitive detection with very low
	false alarm rates.},
  key = {elga99},
  keywords = {Change Detection, Motion detection, Background Subtraction},
  url = {http://www.springerlink.com/link.asp?id=3mcvhnwfa8bj4ln5},
}

@INPROCEEDINGS{elgammal99,
  author = {Elgammal, Ahmed and Harwood, David and Davis, Larry S.},
  title = {Non--parametric Model for Background Subtraction},
  booktitle = {Proceedings of the FRAME--RATE WORKSHOP of the IEEE International
	Conference on Computer Vision {ICCV'99 FRAME--RATE Workshop}},
  year = {1999},
  abstract = {Background subtraction is a method typically used to segment moving
	regions in image sequences taken from a static camera by comparing
	each new frame to a model of the scene background. We present a
	novel non--parametric background model and a background subtraction
	approach. The model can handle situations where the background of
	the scene is cluttered and not completely static but contains small
	motions such as tree branches and bushes. The model estimates the
	probability of observing pixel intensity values based on a sample
	of intensity values for each pixel. The model adapts quickly to
	changes in the scene which enables very sensitive detection of moving
	targets. We also show how the model can use color information to
	suppress detection of shadows. The implementation of the model runs
	in real-time for both gray level and color imagery. Evaluation shows
	that this approach achieves very sensitive detection with very low
	false alarm rates.},
  keywords = {Background Subtraction, Change Detection, Motion detection},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\background
	subtraction\bgmodel.pdf},
  url = {http://www.vast.uccs.edu/~tboult/FRAME/Elgammal/bgmodel.html},
}

@TECHREPORT{erhardt-ferron00,
  author = {Erhardt--Ferron, Angelika},
  title = {Theory and Applications of Digital Image Processing},
  institution = {Hochschule f\"ur Technik und Wirtschaft},
  year = {2000},
  type = {Textbook},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\libros\Image
	& Video Processing\Theory and Applications of Digital Image Processing.pdf},
}

@ARTICLE{fabrethorpe98,
  author = {M. Fabre--Thorpe and G. Richard and S. Thorpe},
  title = {{Rapid Categorization of Natural Images by Rhesus Monkeys}},
  journal = {Neuroreport},
  year = {1998},
  volume = {9},
  pages = {303--308},
  number = {2},
  month = {January},
}

@TECHREPORT{fernandez96,
  author = {Fern\'andez Valdivia, Joaqu\'in},
  title = {Morfolog\'ia de Niveles de Gris},
  institution = {Depto. Ciencias de la Computaci\'on e Inteligencia Artificial --
	Universidad de Granada},
  year = {1996},
  key = {fern96},
}

@ARTICLE{foresti03,
  author = {Foresti, G.L. and Micheloni, C.},
  title = {A robust feature tracker for active surveillance of outdoor scenes},
  journal = {Electronics Letters on Computer Vision and Image Analysis {ELCVIA}},
  year = {2003},
  volume = {1},
  pages = {21--34},
  number = {1},
  key = {fore03},
}

@INPROCEEDINGS{friedman97,
  author = {Friedman, Nir and Russell, Stuart},
  title = {Image segmentation in video sequences: A probabilistic approach},
  booktitle = {Proceedings of the 13th Conference on Unvertainty in Artificial Intelligence
	{{UAI}--1997}},
  year = {1997},
  key = {frie97},
}

@BOOK{gallego01,
  title = {Fundamentos de Estad\'istica},
  publisher = {Copister\'ias Don Folio S.L.},
  year = {2001},
  author = {Gallego Segador, Arturo and Espejo Mohedano, Roberto},
  address = {ISBN: 84-930561-8-9},
  booktitle = {Fundamentos de Estad\'istica},
  key = {gall01},
}

@BOOK{garcia92,
  title = {\'Algebra lineal y geometr\'ia: Cuso Te\'orico--Pr\'actico},
  publisher = {Ed. Marfil S.A.},
  year = {1992},
  author = {Garc\'ia Garc\'ia, Jos\'e and L\'opez Pellicer, Manuel},
  address = {ISBN: 84-268-0269-9},
  booktitle = {\'Algebra lineal y geometr\'ia: Cuso Te\'orico--Pr\'actico},
  key = {garc92},
}

@INPROCEEDINGS{georgescu03,
  author = {Georgescu, Bogdan and Shimshoni, Ilan and Meer, Peter},
  title = {Mean Shift Based Clustering in High Dimensions: A Texture Classification
	Example},
  booktitle = {$9^{th}$ International Conference on Computer Vision {{ICCV}--2003}},
  year = {2003},
  pages = {456--463},
  address = {Nice, France.},
  month = {October},
  key = {geor03},
}

@INPROCEEDINGS{giusto02,
  author = {Giusto, D.D. and Massida, F. and Perra, C.},
  title = {A fast algorithm for video segmentation and object tracking},
  booktitle = {2002 IEEE International Conference on Digital Signal Processing {{DSP}--2002}},
  year = {2002},
  pages = {697--700},
  key = {gius02},
}

@PHDTHESIS{gonzalez-tesis,
  author = {Gonz\'alez Linares, Jos\'e Mar\'{\i}a},
  title = {Detecci\'on autom\'atica de objetos deformables},
  school = {Universidad de M\'alaga},
  year = {2000},
  key = {gonzTES},
}

@BOOK{gonzalez02,
  title = {Digital Image Processing},
  publisher = {Prentice--Hall, Inc.},
  year = {2002},
  author = {Gonzalez, Rafael C. and Woods, Richard E.},
  series = {ISBN: 0--201--18075--8},
  address = {Upper Saddle River (NJ), USA},
  edition = {Second},
  key = {gonz87},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\libros\Image
	& Video Processing\Digital Image Processing (Gonzalez) Prentice-Hall
	Ed, 2nd Edition 2002.pdf},
}

@BOOK{gordon97,
  title = {{Theories of Visual Perception}},
  publisher = Wiley,
  year = {1997},
  author = {I. E. Gordon},
}

@ARTICLE{gottesfeld92,
  author = {Gottesfeld Brown, Lisa},
  title = {A survey of image registration techniques},
  journal = {ACM Computer Surveys},
  year = {1992},
  volume = {24},
  pages = {325--376},
  number = {4},
  abstract = {Registration is a fundamental task in image processing used to match
	two or more pictures taken, for example, at different times, from
	different sensors, or from different viewpoints. Virtually all large
	systems which evaluate images require the registration of images,
	or a closely related operation, as an intermediate step. Specific
	examples of systems where image registration is a significant component
	include matching a target with a real-time image of a scene for
	target recognition, monitoring global land usage using satellite
	images, matching stereo images to recover shape for autonomous navigation,
	and aligning images from different medical modalities for diagnosis.
	Over the years, a broad range of techniques has been developed for
	various types of data and problems. These techniques have been independently
	studied for several different applications, resulting in a large
	body of research. This paper organizes this material by establishing
	the relationship between the variations in the images and the type
	of registration techniques which can most appropriately be applied.
	Three major types of variations are distinguished. The first type
	are the variations due to the differences in acquisition which cause
	the images to be misaligned. To register images, a spatial transformation
	is found which will remove these variations. The class of transformations
	which must be searched to find the optimal transformation is determined
	by knowledge about the variations of this type. The transformation
	class in turn influences the general technique that should be taken.
	The second type of variations are those which are also due to differences
	in acquisition, but cannot be modeled easily such as lighting and
	atmospheric conditions. This type usually effects intensity values,
	but they may also be spatial, such as perspective distortions. The
	third type of variations are differences in the images that are
	of interest such as object movements, growths, or other scene changes.
	Variations of the second and third type are not directly removed
	by registration, but they make registration more difficult since
	an exact match is no longer possible. In particular, it is critical
	that variations of the third type are not removed. Knowledge about
	the characteristics of each type of variation effect the choice
	of feature space, similarity measure, search space, and search strategy
	which will make up the final technique. All registration techniques
	can be viewed as different combinations of these choices. This framework
	is useful for understanding the merits and relationships between
	the wide variety of existing techniques and for assisting in the
	selection of the most suitable technique for a specific problem.},
  doi = {10.1145/146370.146374},
  key = {gott92},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\A survey
	of Image Registration Methods (Lisa Gottesfeld Brow.pdf},
}

@INPROCEEDINGS{guo99,
  author = {Guo, Ju and Kim, Jongwon and Jay Kuo, C.--C.},
  title = {Fast and robust moving object segmentation technique for MPEG--4
	object--based coding and functionality},
  booktitle = {Proceedings of SPIE},
  year = {1999},
  volume = {3653},
  pages = {1210--1221},
  month = {January},
  key = {guo99},
}

@ARTICLE{herrero03,
  author = {Herrero Jaraba, El\'ias and Orrite Uru{\~n}uela, Carlos and Senar,
	Jes\'us},
  title = {Detected motion classification with double--background and a neighborhood--based
	difference},
  journal = {Pattern Recognition Letters},
  year = {2003},
  volume = {24},
  pages = {2079--2092},
  key = {herr03},
}

@BOOK{horn86,
  title = {{Robot Vision}},
  publisher = MIT,
  year = {1986},
  author = {{B. K. P}. Horn},
}

@INPROCEEDINGS{horprasert99,
  author = {Horprasert, Thanarat and Harwood, David and Davis, Larry S.},
  title = {A statistical approach for real--time robust background subtraction
	and shadow detection},
  booktitle = {1999 IEEE International Conference on Computer Vision: Frame Rate
	Workshop {{ICCV}'99}},
  year = {1999},
  key = {horp99},
}

@ARTICLE{hsu84,
  author = {Hsu, Y.Z. and Nagel, H.-H. and Reckers, G.},
  title = {New likelihood test methods for change detection in image sequences},
  journal = {Computer Vision, Graphics and Image Processing},
  year = {1984},
  volume = {26},
  pages = {73--106},
  key = {hsu84},
}

@BOOK{hurvich66,
  title = {{The Perception of Brightness and Darkness}},
  publisher = Allyn,
  year = {1966},
  author = {L. W. Hurvich and D. Jameson},
}

@INPROCEEDINGS{huwer00,
  author = {Huwer, Stefan and \mbox{N}iemann, Heinrich},
  title = {Adaptive change detection for real--time surveillance applications},
  booktitle = {3rd IEEE International Workshop on Visual Surveillance {{VS}--2000}},
  year = {2000},
  pages = {37--45},
  address = {Dublin, Ireland},
  month = {July},
  key = {huwe00},
}

@ARTICLE{irani93,
  author = {Irani, Michal and Peleg, Shmuel},
  title = {Motion Analysis for Image Enhancement: Resolution, Occlusion and
	Transparency},
  journal = {Journal of Visual Communication and Image Representation},
  year = {1993},
  volume = {4},
  pages = {324--335},
  number = {4},
  month = {December},
  citeseerurl = {http://citeseer.ist.psu.edu/article/irani93motion.html},
  key = {iran93},
  keywords = {Optical Flow, Motion detection},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\change
	detection\Motion Analysis for Image Enhancement_Resolution, Occlusion
	and Transparency (Irani and Peleg) Journal VCIR,pp 324-335, 1993.pdf},
  url = {http://www.wisdom.weizmann.ac.il/~irani/PAPERS/sequence_enhnc.pdf},
}

@BOOK{jahne02,
  title = {Digital Image Processing},
  publisher = {Springer--Verlag, Berlin Heidelberg},
  year = {2002},
  author = {J\"ahne, Bernd},
  series = {ISBN: 3-540-67754-2},
  edition = {Fifth Edition},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\libros\Image
	& Video Processing\Digital Image Processing (Bernd Jahne) Springer-Verlag.pdf},
}

@BOOK{jain89,
  title = {{Fundamentals of Digital Image Processing}},
  publisher = PH,
  year = {1989},
  author = {A. K. Jain},
}

@ARTICLE{jourlin88,
  author = {Michel Jourlin and Jean--Charles Pinoli},
  title = {A Model for Logarithmic Image--Processing},
  journal = {Journal of Microscopy},
  year = {1988},
  volume = {149},
  pages = {21--35},
  number = {1},
  month = {January},
  keywords = {LIP},
}

@ARTICLE{jourlin87,
  author = {Michel Jourlin and Jean--Charles Pinoli},
  title = {Logarithmic Image Processing},
  journal = {Acta Stereologica},
  year = {1987},
  volume = {6},
  pages = {651--656},
  keywords = {LIP},
}

@INPROCEEDINGS{khan01,
  author = {Khan, Sohaib and Shah, Mubarak},
  title = {Object based segmentation of video using color, motion and spatial
	information},
  booktitle = {Proceedings of the 2001 IEEE International Conference on Imaging
	{{II}--2001}},
  year = {2001},
  pages = {746--751},
  key = {khan01},
}

@ARTICLE{kim02,
  author = {Kim, Changick and Hwang, Jenq--Neng},
  title = {Fast and automatic video object segmentation and tracking for content--based
	applications},
  journal = {IEEE Transactions on Circuits and Systems for Video Technology},
  year = {2002},
  volume = {12},
  pages = {122--129},
  number = {2},
  month = {February},
  key = {kim02},
}

@INPROCEEDINGS{kuhne01,
  author = {K{\"u}hne, Gerald and Richter, Stephan and Beier, Markus},
  title = {Motion--based segmentation and contour--based classification of video
	objects},
  booktitle = {Proceedings of the ACM Multimedia 2001},
  year = {2001},
  pages = {41--50},
  address = {Ottawa, Canada},
  month = {September},
  key = {k{\"u}hn01},
}

@INPROCEEDINGS{leclerc00b,
  author = {Leclerc, Yvan and Luong, Q.-Tuan and Fua, Pascal},
  title = {Measuring the Self--Consistency of Stereo Algorithms},
  booktitle = {Proceedings of the 2000 European Conference on Computer Vision {{ECCV}--2000}},
  year = {2000},
  address = {Dublin, Ireland Rep.},
  key = {lecl00b},
}

@INPROCEEDINGS{leclerc99a,
  author = {Leclerc, Yvan and Luong, Q.-Tuan and Fua, Pascal},
  title = {Self--Consistency: a Novel Approach to Characterizing the Accuracy
	and Reliability of Point Correspondence Algorithms},
  booktitle = {Proceedings of the One--day Workshop on Performance Characterisation
	and Benchmarking of Vision Systems},
  year = {1999},
  address = {Las Palmas de Gran Canaria, Canary Islands, Spain},
  key = {lecl99a},
}

@INPROCEEDINGS{leclerc99b,
  author = {Leclerc, Yvan and Luong, Q.-Tuan and Fua, Pascal},
  title = {Characterizing the Performance of Multiple--image Point--correspondence
	Algorithms using Self--Consistency},
  booktitle = {Proceedings of the 1999 International Conference on Computer Vision
	{{ICCV}--1999}},
  year = {1999},
  address = {Corfu, Greece},
  month = {September},
  key = {lecl99b},
}

@INPROCEEDINGS{leclerc00a,
  author = {Leclerc, Yvan and Luong, Q.-Tuan and Fua, Pascal and Miyajima, Koji},
  title = {Detecting changes in 3D shape using Self-Consistency},
  booktitle = {Proceedings of the Computer Vision and Pattern Recognition 2000 {{CVPR}--2000}},
  year = {2000},
  key = {lecl00a},
}

@ARTICLE{leclerc03,
  author = {Leclerc, Yvan G. and Luong, Q-Tuan and Fua, Pascal V.},
  title = {Self--consistency and MDL: a Paradigm for Evaluating Point Correspondence
	Algorithms and Detecting Change},
  journal = {International Journal of Computer Vision},
  year = {2003},
  volume = {51},
  pages = {63--83},
  number = {1},
  key = {lecl03},
}

@ARTICLE{lievin04,
  author = {M. Lievin and F. Luthon},
  title = {{Nonlinear Color Space and Spatiotemporal MRF for Hierarchical Segmentation
	of Face Features in Video}},
  journal = {IEEE Transactions on Image Processing},
  year = {2004},
  volume = {13},
  pages = {63--71},
  number = {1},
  month = {January},
}

@ARTICLE{lillestrand72,
  author = {Lillestrand, R.},
  title = {Techniques for change detection},
  journal = {IEEE Transactions on Computers},
  year = {1972},
  volume = {21},
  pages = {654--659},
  number = {7},
  key = {lill72},
}

@ARTICLE{liu98,
  author = {Liu, Sze--Chu and Fu, Chang--Wu and Chang, Shyang},
  title = {Statistical change detection with moments under time--varying illumination},
  journal = {IEEE Transactions on Image Processing},
  year = {1998},
  volume = {7},
  pages = {1258--1268},
  number = {9},
  month = {September},
  key = {liu98},
}

@ARTICLE{marr80,
  author = {David Marr and E Hildreth},
  title = {{Theory of Edge--Detection}},
  journal = {Proceedings of the Royal Society of London Series B -- Biological
	Sciences},
  year = {1980},
  volume = {207},
  pages = {187--217},
  number = {1167},
}

@INPROCEEDINGS{mcivor00,
  author = {McIvor, Alan M.},
  title = {Background Subtraction Techniques},
  booktitle = {Conference on Image and Vision Computing New Zealand {IVCNZ00}},
  year = {2000},
  key = {mciv00},
}

@ARTICLE{mech98,
  author = {Mech, Roland and Wollborn, Michael},
  title = {A noise robust method for 2D shape estimation of moving objects in
	video sequences considering a moving camera},
  journal = {Signal Processing},
  year = {1998},
  volume = {66},
  pages = {203--217},
  number = {2},
  key = {mech98},
}

@ARTICLE{murat02,
  author = {Murat Bagci, A. and Yardimci, Yasemin and Enis {\c{C}}etin, A.},
  title = {Moving object detection using adaptive subband decomposition and
	fractional low--order statistics in video sequences},
  journal = {Signal Processing},
  year = {2002},
  volume = {82},
  pages = {1941--1947},
  key = {mura02},
}

@ARTICLE{neri98,
  author = {Neri, A. and Colonnese, S. and Russo, G. and Talone, P.},
  title = {Automatic moving object and background separation},
  journal = {Signal Processing},
  year = {1998},
  volume = {66},
  pages = {219--232},
  number = {2},
  key = {neri98},
}

@ARTICLE{oppenheim69,
  author = {Oppenheim, Alan V.},
  title = {Speech analysis--synthesis system based on homomorphic filtering},
  journal = {Journal of Acoustic Society of America},
  year = {1969},
  volume = {45},
  pages = {458--465},
  number = {2},
  month = {February},
  abstract = {A digital speech analysis--synthesis system based on a recently proposed
	approach to the deconvolution of speech is presented. The analyzer
	is based on a computation of the cepstrum considered as the inverse
	Fourier transform of the log magnitude of the Fourier transform.
	The transmitted parameters represent pitch and voice--unvoiced information
	and the low--time portion of the cepstrum representing an approximation
	to the cepstrum of the vocal--tract impulse response. In the synthesis,
	the low--time cepstral information is transformed to an impulse
	response function, which is then convolved with a train of impulses
	during voiced portions or a noise waveform during unvoiced portions
	to reconstruct the speech. Since no phase information is retained
	in the analysis, phase must be regenerated during synthesis. Either
	a zero--phase or minimum--phase characteristic can be obtained by
	simple weighting of the cepstrum before transformation.},
  key = {oppe69},
  keywords = {Homomorphic Filtering},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\Homomorphic
	filtering\speechanaly_1969.pdf},
  url = {http://www.rle.mit.edu/dspg/documents/speechanaly_1969.pdf},
}

@ARTICLE{oppenheim68,
  author = {Oppenheim, Alan V. and Schafer, Ronald W. and Stockham JR., Thomas
	G.},
  title = {Nonlinear Filtering of Multiplied and Convolved Signals},
  journal = {IEEE Transactions on Audio and Electroacoustics},
  year = {1968},
  volume = {AU--16},
  pages = {437--466},
  number = {3},
  month = {September},
  abstract = {An approach to some nonlinear filtering problems through a generalized
	notion of superposition has proven useful. In this paper this approach
	is investigated for the nonlinear filtering of signals which can
	be expressed as products or as convolutions of components. The applications
	of this approach in audio dynamic range compression and expansion,
	image enhancement with applications to bandwidth reduction, echo
	removal, and speech waveform processing are presented.},
  keywords = {Homomorphic Filtering},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\Homomorphic
	filtering\nonnlinearfiltering_1968.pdf},
  url = {http://www.rle.mit.edu/dspg/documents/nonnlinearfiltering_1968.pdf},
}

@INPROCEEDINGS{palomares05a,
  author = {Palomares, Jos\'e M. and Gonz\'alez, Jes\'us and Ros, Eduardo},
  title = {Designing a fast convolution under the {LIP} paradigm applied to
	edge detection},
  booktitle = {Proceedings of the III International Conference on Advances in Pattern
	Recognition {ICAPR 2005}},
  year = {2005},
  editor = {Sameer {Singh et al.}},
  volume = {3},
  series = {Lecture Notes in Computer Science -- {LNCS 3687}},
  pages = {560--569},
  address = {Bath, UK.},
  month = {22--25, August},
  abstract = {The Logarithmic Image Processing model (LIP) is a robust mathematical
	framework for the processing of transmitted and reflected images.
	It follows many visual, physical and psychophysical laws. This works
	presents a new formulation of a 2D--convolution of separable kernels
	using the LIP paradigm. A previously stated LIP--Sobel edge detector
	is redefined with the new proposed formulation, and the performance
	of the edge detectors programmed following the two formulations
	(the previous one and the new one proposed) is compared. Another
	operator, Laplacian of Gaussian, is also stated under the LIP paradigm.
	The experiments show that both methods obtain same results although
	our proposed method is much faster than the previous one.},
  doi = {10.1007/11552499_62},
  keywords = {LIP},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\Mis artículos\2005\congresos\icapr05\36870560.pdf},
}

@INPROCEEDINGS{palomares05b,
  author = {Palomares, Jos\'e M. and Gonz\'alez, Jes\'us and Ros, Eduardo},
  title = {Detecci\'on de Bordes en Im\'agenes con Sombras mediante LIP--Canny},
  booktitle = {AERFAI 2005},
  year = {2005},
  abstract = {En el presente trabajo, se presenta una nueva técnica que unifica
	el conocido método de Canny para la obtención de bordes con un paradigma
	de procesamiento de imágenes conocido como LIP, que tiene un comportamiento
	logarítmico parecido al del ojo humano. Se ha observado que el método
	de Canny no detecta bien los bordes en zonas de baja iluminación
	y que el paradigma LIP permite trabajar en zonas de iluminación
	pobre. Esta nueva técnica (LIP--Canny) se compara con Canny, mostrando
	que LIP--Canny es capaz de detectar bordes en zonas de baja iluminación.
	También se compara con otra técnica, en la que se realiza un filtrado
	homomórfico previo al método de Canny, obteniéndose unos resultados
	visuales similares, pero LIP--Canny obtiene dichos resultados más
	rápidamente y con un ajuste de umbral menos sensible y, por tanto,
	mucho más sencillo.},
}

@ARTICLE{palomares06,
  author = {Palomares, Jos\'e M. and Gonz\'alez, Jes\'us and Ros, Eduardo and
	Prieto, Alberto},
  title = {General Logarithmic Image Processing Convolution},
  journal = {IEEE Transactions on Image Processing},
  year = {2006},
  volume = {Accepted for Publication.},
  pages = {1--6},
  abstract = {The Logarithmic Image Processing model (LIP) is a robust mathematical
	framework, which, among other benefits, behaves invariantly to illumination
	changes. This paper presents, for the first time, two general formulations
	of the 2D-convolution of separable kernels under LIP paradigm. Although
	both formulations are mathematically equivalent, one of them has
	been designed avoiding the operations which are computationally
	expensive in current computers. Therefore, this fast LIP convolution
	method allows to obtain significant speedups and it is more adequate
	for real-time processing. To support these statements, some experimental
	results are shown in section V.},
}

@INPROCEEDINGS{patrascu03,
  author = {Patrascu, Vasile},
  title = {Color Image Enhancement Using the Support Fuzzification},
  booktitle = {Proceedings of the 10th International Fuzzy Systems Association World
	Congress {IFSA--2003}},
  year = {2003},
  editor = {T. {Bilgi\c{c} et al.}},
  series = {Lecture Notes in Computer Sciences -- {LNCS 2715}},
  pages = {412--419},
  address = {Istanbul, Turkey.},
  month = {30 June -- 2 July},
  publisher = {Springer--Verlag, Berlin Heidelberg},
  abstract = {Simple and efficient methods for image enhancement can be obtained
	through affine transforms, defined by the logarithmic operations.
	Generally, a single affine transform is calculated for the whole
	image. A better quality is possible to obtain if a fuzzy partition
	is defined on the image support and then, for each element of the
	partition an affine transform is determined. Finally the enhanced
	image is computed by summing up in a weight way the images obtained
	for the fuzzy partition elements.},
  keywords = {LIP},
  optpublisher = {#Springer#},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\LIP\Color
	image using the support fuzzification (V Patrascu).pdf},
  url = {http://springerlink.metapress.com/link.asp?id=vpkenhk3d5uf95g0},
}

@ARTICLE{petrovic04,
  author = {Ana Petrovic and Oscar {Divorra Escoda} and Pierre Vandergheynst},
  title = {{Multiresolution Segmentation of Natural Images: From Linear to Nonlinear
	Scale--Space Representations}},
  journal = {IEEE Transactions on Image Processing},
  year = {2004},
  volume = {13},
  pages = {1104--1114},
  number = {8},
  month = {August},
}

@ARTICLE{pinoli97,
  author = {Jean--Charles Pinoli},
  title = {A General Comparative Study of the Multiplicative Homomorphic, Log--Ratio
	and Logarithmic Image Processing Approaches},
  journal = {Signal Processing},
  year = {1997},
  volume = {58},
  pages = {11--45},
  number = {1},
  month = {April},
  abstract = {This article presents a comparative study of the multiplicative homomorphic
	image processing (MHIP), the log-ratio image processing (LRIP) and
	the logarithmic image processing (LIP). These three image processing
	approaches are based on abstract linear mathematics and provide
	specific operations and structures that have opened up new pathways
	to the development of image processing techniques. The MHIP approach
	was designed for the processing of multiplied images, the LRIP approach
	was introduced to overcome the out-of-range problem associated with
	many image processing techniques, while the LIP approach was developed
	for the processing of images valued in a bounded intensity range.
	First, it is claimed that an image processing framework must be
	physically relevant, mathematically consistent, computationally
	tractable and practically fruitful. It is also pointed out that
	the classical linear image processing (CLIP) is not adapted to non-linear
	and/or bounded range images or imaging systems, such as transmitted
	light images, practical digital images or the human brightness perception
	system. Then, the importance and usefulness of several mathematical
	fields, such as abstract linear algebra and abstract analysis, for
	image representation and processing within such image settings are
	discussed. Third, the MHIP, LRIP and LIP approaches are presented,
	focusing on their distinctive ideas, structures and properties for
	image representation and processing, rather than an in-depth review.
	Next, a study of the relationships and differences between their
	image representations and basic algebraic operations is detailed.
	Finally, a general comparative discussion is developed, showing
	the main physical, mathematical, computational and practical characteristics
	of these three abstract-linear-mathematics-based image processing
	approaches, and summarizing their respective advantages and disadvantages.
	It is concluded and highlighted through real application examples
	in both image enhancement and edge detection areas that the LIP
	approach surpasses the two other approaches, although, from a strictly
	practical point of view, a detailed quantitative comparative study
	on real applications is now necessary.},
  doi = {10.1016/S0165-1684(97)00011-X},
  keywords = {LIP, Logarithmic image processing, abstract linear mathematics, human
	brightness perception, image processing, image representation, log--ratio
	image processing, multiplicative homomorphic image processing, reflected
	light images, transmitted light images},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\LIP\A
	general comparative study of the multiplicative homomorphic, log-ratio
	and logarithmic image processing approaches (JC Pinoli) Signal Proc
	58 (1) pp 11-45 (1997).pdf},
}

@ARTICLE{pinoli97b,
  author = {Jean--Charles Pinoli},
  title = {The Logarithmic Image Processing Model: Connections with Human Brightness
	Perception and Contrast Estimators},
  journal = {Journal of Mathematical Imaging and Vision},
  year = {1997},
  volume = {7},
  pages = {341--358},
  number = {4},
  abstract = {The logarithmic image processing (LIP) model is a mathematical framework
	based on abstract linear mathematics which provides a set of specific
	algebraic and functional operations that can be applied to the processing
	of intensity images valued in a bounded range. The LIP model has
	been proved to be physically justified in the setting of transmitted
	light and to be consistent with several laws and characteristics
	of the human visual system. Successful application examples have
	also been reported in several image processing areas, e.g., image
	enhancement, image restoration, three-dimensional image reconstruction,
	edge detection and image segmentation. The aim of this article is
	to show that the LIP model is a tractable mathematical framework
	for image processing which is consistent with several laws and characteristics
	of human brightness perception. This is a survey article in the
	sense that it presents (almost) previously published results in
	a revised, refined and self-contained form. First, an introduction
	to the LIP model is exposed. Emphasis will be especially placed
	on the initial motivation and goal, and on the scope of the model.
	Then, an introductory summary of mathematical fundamentals of the
	LIP model is detailed. Next, the article aims at surveying the connections
	of the LIP model with several laws and characteristics of human
	brightness perception, namely the brightness scale inversion, saturation
	characteristic, Weber‘s and Fechner‘s laws, and the psychophysical
	contrast notion. Finally, it is shown that the LIP model is a powerful
	and tractable framework for handling the contrast notion. This is
	done through a survey of several LIP-model-based contrast estimators
	associated with special subparts (point, pair of points, boundary,
	region) of intensity images, that are justified both from a physical
	and mathematical point of view.},
  doi = {http://dx.doi.org/10.1023/A:1008259212169},
  keywords = {LIP},
  owner = {Jose Manuel},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\LIP\The
	Logarithmic Image Processing Model (JC Pinoli) J. Math. .pdf},
  timestamp = {13/10/2005},
}

@INPROCEEDINGS{potmesil83,
  author = {M. Potmesil and I. Chakravarty},
  title = {{Modeling Motion Blur in Computer--Generated Images}},
  booktitle = {Proceedings of the 10th Annual Conference on Computer Graphics and
	Interactive Techniques, SIGGRAPH'83},
  year = {1983},
  pages = {389--399},
  address = {Detroit (MI), USA},
  month = {July},
  optpublisher = {#ACM#},
}

@INPROCEEDINGS{powell82,
  author = {P. G. Powell and B. E. Bayer},
  title = {{A Method for the Digital Enhancement of Unsharp, Grainy Photographic
	Images}},
  booktitle = {Proceedings of the IEEE International Conference on Electronic Image
	Processing},
  year = {1982},
  pages = {179--183},
  month = {July},
}

@BOOK{pratt01,
  title = {Digital Image Processing: {PIKS} Inside},
  publisher = {John Wiley \& Sons, Inc.},
  year = {2001},
  author = {Pratt, William K.},
  series = {ISBN: 0--471--22132--5},
  address = {New York City (NY), USA.},
  edition = {Third Edition},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\libros\Image
	& Video Processing\Digital Image Processing (William K. Pratt) Ed.
	Wiley - 3rd Ed.pdf},
}

@BOOK{pratt91,
  title = {Digital Image Processing},
  publisher = {John Wiley \& Sons, Inc.},
  year = {1991},
  author = {Pratt, William K.},
  edition = {Second Edition},
}

@ARTICLE{radke05,
  author = {Radke, Richard J. and Andra, Srinivas and Al--Kafahi, Omar and Roysam,
	Badrinath},
  title = {Image change detection algorithms: a systematic survey},
  journal = {IEEE Transactions on Image Processing},
  year = {2005},
  volume = {14},
  pages = {294--307},
  number = {3},
  month = {March},
  abstract = {Detecting regions of change in multiple images of the same scene taken
	at different times is of widespread interest due to a large number
	of applications in diverse disciplines, including remote sensing,
	surveillance, medical diagnosis and treatment, civil infrastructure,
	and underwater sensing. This paper presents a systematic survey
	of the common processing steps and core decision rules in modern
	change detection algorithms, including significance and hypothesis
	testing, predictive models, the shading model, and background modeling.
	We also discuss important preprocessing methods, approaches to enforcing
	the consistency of the change mask, and principles for evaluating
	and comparing the performance of change detection algorithms. It
	is hoped that our classification of algorithms into a relatively
	small number of categories will provide useful guidance to the algorithm
	designer.},
  doi = {10.1109/TIP.2004.838698},
  key = {andr03},
  keywords = {Change Detection},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\change
	detection\Image Change Detection Algorithms_A Systematic Survey
	(Radke et al.).pdf},
}

@ARTICLE{radke03,
  author = {Radke, Richard J. and Andra, Srinivas and Al--Kafahi, Omar and Roysam,
	Badrinath},
  title = {Image change detection algorithms: a systematic survey (DRAFT)},
  journal = {IEEE Transactions on Image Processing},
  year = {2003},
  volume = {N/A},
  pages = {1--30},
  keywords = {Change Detection},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\change
	detection\radketip03.pdf},
}

@ARTICLE{ramponi98,
  author = {Giovanni Ramponi},
  title = {{A Cubic Unsharp Masking Technique for Contrast Enhancement}},
  journal = {Signal Processing},
  year = {1998},
  volume = {67},
  pages = {211--222},
  number = {2},
  month = {June},
  abstract = {The cubic unsharp masking method is introduced in this paper. It is
	demonstrated, through both a statistical study and some computer
	simulations, that the proposed method has a much reduced noise sensitivity
	with respect to the linear unsharp masking technique and it permits
	to obtain perceptually pleasant results. The proposed operator also
	compares favourably with other algorithms which recently have been
	studied to improve the behaviour of the unsharp masking approach.},
  doi = {http://dx.doi.org/10.1016/S0165-1684(98)00038-3},
  keywords = {image enhancement, image processing, nonlinear filtering, unsharp
	masking},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\LIP\A
	cubic unsharp masking technique for contrast enhancenment (G Ramponi).pdf},
}

@INPROCEEDINGS{rosin98,
  author = {Rosin, Paul},
  title = {Thresholding for change detection},
  booktitle = {Proceedings of International Conference on Computer Vision {{ICCV}--1998}},
  year = {1998},
  pages = {274--279},
  key = {rosi98},
}

@ARTICLE{rosin03,
  author = {Rosin, Paul and Ioannidis, Efstathios},
  title = {Evaluation of global image thresholding for change detection},
  journal = {Pattern Recognition Letters},
  year = {2003},
  volume = {24},
  pages = {2345--2356},
  key = {rosi03},
}

@BOOK{rudin70,
  title = {Real and Complex Analysis},
  publisher = {McGraw--Hill, Inc.},
  year = {1970},
  author = {Rudin, Walter},
  series = {Higher Mathematical Series},
  address = {Ljubljana, Slovenja.},
  edition = {International Student Edition.},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\libros\matematicas\Real
	And Complex Analysis (Rudin).pdf},
}

@ARTICLE{vanrullen01,
  author = {R. Van Rullen and S. Thorpe},
  title = {{Rate Coding Versus Temporal Order Coding: What the retinal Ganglion
	Cells tell the Visual Cortex}},
  journal = {Neural Computation},
  year = {2001},
  volume = {13},
  pages = {1255--1283},
  number = {6},
  month = {June},
}

@ARTICLE{shvayster87,
  author = {Shvayster, Haim and Peleg, Shmuel},
  title = {Inversion of picture operators},
  journal = {Pattern Recognition Letters},
  year = {1987},
  volume = {5},
  pages = {49--61},
  number = {1},
  month = {January},
  abstract = {Inversion of operators on picturesnext term is shown to be an important
	part of classical image restoration techniques. A method is presented
	for nonlinear previous terminversion of operatorsnext term that
	enables nonlinear restoration. The problem of out of range values
	is handled by introducing a new definition for operations on previous
	termpicturesnext term such that the set of all previous termpicturesnext
	term is a vector space. It is empirically shown that the Conjugate
	Gradients algorithm converges quickly in this vector space and enables
	previous terminversion of operatorsnext term on big previous termpicturesnext
	term with relatively little computation. Examples are given for
	applications of this method to linear and nonlinear previous termoperators.next
	term},
  doi = {10.1016/0167-8655(87)90025-0},
  keywords = {LRIP},
}

@INPROCEEDINGS{shvayster83,
  author = {Shvayster, Haim and Peleg, Shmuel},
  title = {Pictures as elements in a vector space},
  booktitle = {Proceedings of the 1983 IEEE Conference on Computer Vision and Pattern
	Recognition},
  year = {1983},
  volume = {1},
  pages = {442--446},
  address = {Washington, USA.},
  month = {June},
  keywords = {LRIP},
}

@ARTICLE{skifstad89,
  author = {Skifstad, Kurt and Jain, Ramesh},
  title = {Illumination independent Change Detection for real world image sequences},
  journal = {Computer Vision, Graphics and Image Processing},
  year = {1989},
  volume = {46},
  pages = {387--399},
  number = {3},
  month = {June},
  key = {skif89},
}

@ARTICLE{stockham72,
  author = {Stockham JR., Thomas G.},
  title = {Image Processing in the context of a visual model},
  journal = {Proceedings of the IEEE},
  year = {1972},
  volume = {60},
  pages = {828--842},
  month = {July},
  key = {stoc72},
}

@ARTICLE{thorpe01,
  author = {S. Thorpe and A. Delorme and R. Van Rullen},
  title = {{Spike--Based Strategies for Rapid Processing}},
  journal = {Neural Networks},
  year = {2001},
  volume = {14},
  pages = {715--725},
  number = {6-7},
  month = {July--September},
  note = {Special Issue.},
}

@INPROCEEDINGS{thorpe00,
  author = {S. Thorpe and A. Delorme and R. Van Rullen and W. Paquier},
  title = {{Reverse Engineering of the Visual System using Networks of Spiking
	Neurons}},
  booktitle = {Proceedings of the IEEE International Symposium on Circuits and Systems,
	ISCAS'2000},
  year = {2000},
  volume = {4},
  pages = {405--408},
  address = {Geneva, Switzerland},
  month = {April},
}

@ARTICLE{thorpe96,
  author = {S. Thorpe and D. Fize and C. Marlot},
  title = {{Speed of Processing in the Human Visual System}},
  journal = {Nature},
  year = {1996},
  volume = {6582},
  pages = {520--522},
  number = {381},
  month = {June},
}

@INPROCEEDINGS{toth00,
  author = {Toth, Daniel and Aach, Til and Metzler, Volker},
  title = {Illumination--Invariant Change Detection},
  booktitle = {Proceedings of the 4th IEEE Southwest Symposium on Image Analysis
	and Interpretation, SSIAI'00},
  year = {2000},
  pages = {3--7},
  address = {Austin, Texas, USA},
  month = {April},
  isbn = {0-7695-0595-3},
  keywords = {Change Detection, Homomorphic Filtering},
}

@INPROCEEDINGS{toth00b,
  author = {Toth, Daniel and Aach, Til and Metzler, Volker},
  title = {Bayesian Spatio--Temporal Motion Detection under Varying Illumination},
  booktitle = {Proceedings of European Signal Processing Conference 2000 {{EUSIPCO}--2000}},
  year = {2000},
  pages = {2081--2084},
  address = {Tampere, Finland},
  month = {September},
  keywords = {Change Detection, Homomorphic Filtering},
  pdf = {C:\Documents and Settings\Jose Manuel\Mis documentos\articulos\change
	detection\Bayesian Spatio--Temporal Motion Detection under Varying
	Illumination (Toth, Aach and Metzler) EUPSICO-00, 2081--2084.pdf},
}

@ARTICLE{vargas03,
  author = {Vargas--Martin, Fernando},
  title = {A free--cost visual field expander for peripheral vision loss},
  journal = {Journal of Vision},
  year = {2003},
  volume = {3},
  pages = {40--40},
  number = {12},
  month = {December},
  abstract = {Reversed Galilean telescopes have been used for rehabilitation of
	peripheral visual field loss and are commercially available with
	a magnification up to x0.5. A more cost effective visual field expander
	is constructed by making very minor modifications to off-the-shelf
	photographic viewfinders from cheap, disposable cameras. These devices
	can be mounted as spectacles either centrally or peripherally (e.g.
	bioptic). Optical properties are analyzed objectively with a high
	resolution web cam. Additionally, expansion of the visual field
	in subjects is demonstrated by perimetry. Several different types
	of viewfinders were tested although most of the viewfinders used
	in this study had a 20 degree field of view with x0.5 magnification.
	Comments on the ease of using the visual field expander as well
	as the advantages and disadvantages between different types of viewfinders
	are presented. Since creating low cost devices is one of the major
	goals in low vision aid design (especially in underdeveloped countries),
	the proposed viewfinders could be a cheaper and more practical solution
	for visual field expanders.},
  url = {http://journalofvision.org/3/12/40/},
}

@BOOK{vernon91,
  title = {{Machine Vision --- Automated Visual Inspection and Robot Vision}},
  publisher = {Prentice--Hall, Inc.},
  year = {1991},
  author = {D. Vernon},
}

@ARTICLE{wang94,
  author = {Wang, John Y.A. and Adelson, Edward H.},
  title = {Representing moving Images with layers},
  journal = {IEE Transactions on Image Processing},
  year = {1994},
  volume = {3},
  pages = {625--638},
  number = {5},
  month = {September},
  key = {wang94},
}

@BOOK{watt91,
  title = {{Understanding Vision}},
  publisher = AcadPress,
  year = {1991},
  author = {R. Watt},
}

@INPROCEEDINGS{witkin83,
  author = {A.P. Witkin},
  title = {{Scale--Space Filtering}},
  booktitle = {Proceedings of the International Joint Conference on Artificial Intelligence
	{IJCAI}},
  year = {1983},
  pages = {1019--1022},
  address = {Karlsruhe, Germany},
}

@ARTICLE{wu02,
  author = {Quen--Zong Wu and Bor--Shen Jeng},
  title = {{Background Subtraction based on Logarithmic Intensities}},
  journal = {Pattern Recognition Letters},
  year = {2002},
  volume = {23},
  pages = {1529--1536},
  number = {13},
  doi = {10.1016/S0167-8655(02)00116-2},
  issn = {0167--8655},
}

@ARTICLE{xu04,
  author = {Xiaoyin Xu and Eric Miller and Dongbin Chen and Mansoor Sarhadi},
  title = {{Adaptive Two--Pass Rank Order Filter to Remove Impulse Noise in
	Highly Corrupted Images}},
  journal = {IEEE Transactions on Image Processing},
  year = {2004},
  volume = {13},
  pages = {238--247},
  number = {2},
  optdoi = {http://dx.doi.org/10.1109/TIP.2004.823827},
}

@INPROCEEDINGS{zaharescu2005,
  author = {Zaharescu, E.},
  title = {Medical Image Enhancement using Logarithmic Image Processing},
  booktitle = {Proceeding of the 2005 Visualization, Imaging, and Image Processing
	{VIIP 2005}},
  year = {2005},
  editor = {J.J. Villanueva},
  volume = {1},
  number = {1},
  address = {Benidorm, Spain.},
  month = {7--9, September},
  abstract = {The logarithmic image processing theory is a mathematical framework
	that provides a set of specific algebraic and functional operations
	and structures that are well adapted to the representation and processing
	of non linear images, and more generally of non-linear signals,
	valued in a bounded intensity range. The purpose of this paper is
	to introduce a new mathematical LIP model focused on theoretical
	and practical aspects concerning the enhancement of the transmitted
	medical images and the physical absorption/transmission laws expressed
	within LIP mathematical framework. First of all the bounded interval
	(-1,1) is considered as the set of gray levels and we define two
	operations: addition <+> and real scalar multiplication <x>. With
	these operations, the set of gray levels becomes a real vector space.
	Then, defining the scalar product (.|.) and the norm || .|| , we
	obtain an Euclidean space of the gray levels. Secondly, we extend
	these operations and functions for color images. Finally, the experimental
	results, shown as enhanced medical images, reveal that this method
	has wide potential areas of impact which may include: Digital X
	ray, Digital Mammography, Computer Tomography Scans, Nuclear Magnetic
	Resonance Imagery and Telemedicine Applications.},
  keywords = {LIP},
  url = {http://www.actapress.com/PaperInfo.aspx?PaperID=21719},
}

@INPROCEEDINGS{zhong97,
  author = {Zhong, D. and Chang, S.--F.},
  title = {Video Object Model and Segmentation for Content--Based Video Indexing},
  booktitle = {IEEE International Symposium on Circuits and Systems},
  year = {1997},
  pages = {1492--1495},
  address = {Hong Kong},
  month = {June},
  key = {zhon97},
}

@MISC{itu-t_p800,
  author = {{ITU-T}},
  title = {{Methods for subjective determination of transmissions quality}},
  howpublished = {Recommendation P.800},
  year = {1996},
}

@MISC{webMEC_bancoImg,
  author = {{Ministerio de Educación y Ciencia de Espa\~na}},
  title = {Banco de Im\'agenes},
  howpublished = {{[Online] http://recursos.cnice.mec.es/bancoimagenes2 /buscador/index.php}},
  month = {April},
  year = {2005},
  url = {http://recursos.cnice.mec.es/bancoimagenes2 /buscador/index.php},
}

@BOOK{mclachlan97,
  title = {The EM algorithm and Extensions},
  publisher = {Wiley Interscience},
  year = {1997},
  editor = {McLachlan, G.J. and Krishnan, T.},
  key = {mcla97},
}

@BOOK{matlabImageProcessingToolbox,
  title = {Image Processing Toolbox User's Guide for Matlab},
  publisher = {The Mathworks, Inc.},
  year = {1993--2002},
  editor = {The Mathworks, Inc.},
  edition = {July 2002, revised for Version 3.2 (Release 13)},
  key = {matl02},
}

@comment{jabref-meta: selector_journal:Acta Stereologica;Electronics L
etters;IEEE Transactions on Audio and Electroacoustics;IEEE Transacti
ons on Computers;IEEE Transactions on Image Processing;IEEE Transacti
ons on Pattern Analysis and Machine Intelligence;Image Analysis and S
tereology;Journal of Electronic Imaging;Journal of Mathematical Imagi
ng and Vision;Journal of Microscopy;Journal of Physiology;Journal of 
Vision;Nature;Neural Computation;Neural Networks;Neuroreport;Pattern 
Recognition;Pattern Recognition Letters;Proceedings of the IEEE;Proce
edings of the Royal Society of London Series B -- Biological Sciences
;Signal Processing;}

@comment{jabref-meta: selector_author:Aach, Til;Abidi, Besma;Abidi, Mo
ngi;Al--Kafahi, Omar;Andra, Srinivas;Baylor, D. A.;Bichsel, Martin;Bo
vik, Al;Brostow, Gabriel J.;Bruni, Vittoria;Bruzzone, Lorenzo;Cahill,
 Lawrence W.;Canny, John;Cavallaro, Andrea;Comaniciu, Dorin;Courbebai
sse, Guy;Davis, Larry S.;Dawson--Howe, Kenneth M.;Delorme, Arnaud;Den
g, Guang;Deng, Yizong;Durucan, Emrullah;Ebrahimi, Touradj;Elgammal, A
hmed;Erhardt--Ferron, Angelika;Essa, Irfan;Fern\\'andez Prieto, Diego
;Gelasca, Elisa Drelie;Gonz\\'alez, Jes\\'us;Gonzalez, Rafael C.;Gott
esfeld Brown, Lisa;Harwood, David;J\\"ahne, Bernd;Jeng, Bor--Shen;Jou
rlin, Michel;Kaup, Andr{\\'e};Lamb, T.D.;Liang, Jimin;Marr, David;Mee
r, Peter;Mester, Rudolf;Metzler, Volker;Mitckes, Mark;Oppenheim, Alan
 V.;Palomares, Jos\\'e M.;Patrascu, Vasile;Peleg, Shmuel;Pinoli, Jean
--Charles;Pratt, William K.;Prieto, Alberto;Radke, Richard J.;Ramponi
, Giovanni;Ros, Eduardo;Rosin, Paul;Roysam, Badrinath;Rubin, Donald B
.;Rudin, Walter;Schafer, Ronald W.;Shvayster, Haim;Snoeckx, Joel;Stoc
kham JR., Thomas G.;Thorpe, Simon J.;Tobin, Geoffrey Richard;Toth, Da
niel;Trunde, Frederic;Vargas--Martin, Fernando;Visvanathan, Ramesh;Vi
tulano, Domenico;Weilenmann, Yves;Woods, Richard E.;Wu, Quen--Zong;Ya
u, K.W.;Zaharescu, E.;}

@comment{jabref-meta: selector_keywords:Background Subtraction;Change 
Detection;Gibbs Random Fields;Homomorphic Filtering;LIP;Logarithmic W
avelet Transform;LRIP;Mean Shift;Motion detection;Optical Flow;Rank O
rder Coding;Wavelet Transform;}

@comment{jabref-meta: selector_publisher:Academic Press;John Wiley & S
ons, Inc.;McGraw--Hill, Inc.;Prentice--Hall, Inc.;Springer--Verlag, B
erlin Heidelberg;}

@comment{jabref-meta: groupsversion:3;}

@comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 ExplicitGroup:Automatically created groups\;2\;;
2 KeywordGroup:Logarithmic Wavelet Transform\;0\;keywords\;Logarithmic
 Wavelet Transform\;0\;0\;;
2 KeywordGroup:nonlinear filtering\;0\;keywords\;nonlinear filtering\;
0\;0\;;
2 KeywordGroup:image enhancement\;0\;keywords\;image enhancement\;0\;0
\;;
2 KeywordGroup:LIP\;0\;keywords\;LIP\;0\;0\;;
2 KeywordGroup:Mean Shift\;0\;keywords\;Mean Shift\;0\;0\;;
2 KeywordGroup:reflected light images\;0\;keywords\;reflected light im
ages\;0\;0\;;
2 KeywordGroup:transmitted light images\;0\;keywords\;transmitted ligh
t images\;0\;0\;;
2 KeywordGroup:log--ratio image processing\;0\;keywords\;log--ratio im
age processing\;0\;0\;;
2 KeywordGroup:Rank Order Coding\;0\;keywords\;Rank Order Coding\;0\;0
\;;
2 KeywordGroup:Change Detection\;0\;keywords\;Change Detection\;0\;0\;
;
2 KeywordGroup:abstract linear mathematics\;0\;keywords\;abstract line
ar mathematics\;0\;0\;;
2 KeywordGroup:human brightness perception\;0\;keywords\;human brightn
ess perception\;0\;0\;;
2 KeywordGroup:Logarithmic image processing\;0\;keywords\;Logarithmic 
image processing\;0\;0\;;
2 KeywordGroup:Wavelet Transform\;0\;keywords\;Wavelet Transform\;0\;0
\;;
2 KeywordGroup:Gibbs Random Fields\;0\;keywords\;Gibbs Random Fields\;
0\;0\;;
2 KeywordGroup:multiplicative homomorphic image processing\;0\;keyword
s\;multiplicative homomorphic image processing\;0\;0\;;
2 KeywordGroup:image processing\;0\;keywords\;image processing\;0\;0\;
;
2 KeywordGroup:unsharp masking\;0\;keywords\;unsharp masking\;0\;0\;;
2 KeywordGroup:image representation\;0\;keywords\;image representation
\;0\;0\;;
}

