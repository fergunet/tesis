% This file was created with JabRef 2.5.
% Encoding: Cp1252

@INBOOK{konrad00,
  chapter = {3.10},
  pages = {207--225},
  title = {Motion Detection and Estimation},
  publisher = {Academic Press},
  year = {2000},
  author = {Konrad, Janusz},
  type = {Chapter},
  crossref = {bovik00},
  key = {konr00},
  language = {english}
}

@INBOOK{murat00,
  chapter = {4.8},
  pages = {383--399},
  title = {Video Segmentation},
  publisher = {Academic Press},
  year = {2000},
  author = {Murat Tekalp, A.},
  type = {Chapter},
  crossref = {bovik00},
  key = {mura00},
  language = {english}
}

@MISC{szalai07,
  author = {Georg Szalai (Reuters)},
  title = {Video game industry growth still strong: study},
  month = jun,
  year = {2007},
  language = {english},
  owner = {jose},
  timestamp = {2010.07.29},
  url = {http://www.reuters.com/article/idUSN2132172920070621}
}

@INPROCEEDINGS{aach93,
  author = {Aach, Til and Kaup, Andr{\'e} and Mester, Rudolf},
  title = {Change detection in image sequences using Gibbs Random Fields: A
	Bayesian approach},
  booktitle = {International Workshop on Intelligent Signal Processing and Communication
	Systems {{ISPACS}--1993}},
  year = {1993},
  pages = {56--61},
  address = {Sendai, Japan},
  month = oct,
  abstract = {Conventional nonadaptive methods for change detection suffer from
	the dilemma of either causing lots of false alarms or missing considerable
	parts of nonstationary areas. This contribution presents a way out
	of this dilemma by viewing change detection as an inverse, ill--posed
	problem. As such, the problem can be solved using prior knowledge
	about typical properties of change masks. This reasoning leads to
	a Bayesian formulation of change detection, where the prior knowledge
	is brought to bear by appropriately specified a priori probabilities.
	Based on this approach, a new, adaptive algorithm for change detection
	with drastically improved performance is derived. The algorithm requires
	only a single raster scan per picture, thus increasing the computational
	load only slightly in comparison to conventional nonadaptive techniques.},
  file = {Change Detection in Image Sequences Using Gibbs Random Fields_A Bayesian Approach (T. Aach, A. Kaup and R. Mester).pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\change detection\\Change Detection in Image Sequences Using Gibbs Random Fields_A Bayesian Approach (T. Aach, A. Kaup and R. Mester).pdf:PDF},
  key = {Aach93},
  keywords = {Change Detection, Gibbs Random Fields},
  language = {english}
}

@INPROCEEDINGS{abdou86,
  author = {Abdou, Ikram E. and Dusaussoy, Nicolas J.},
  title = {Survey of Image Measurements},
  booktitle = {Proceedings of the 1986 ACM Fall Joint Computer Conference},
  year = {1986},
  pages = {71--78},
  address = {Dallas, TX, USA},
  publisher = {IEEE Computer Society Press},
  file = {p71-abdou.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\nuevos\\p71-abdou.pdf:PDF},
  keywords = {Image Quality},
  language = {english},
  url = {http://portal.acm.org/ft\_gateway.cfm?id=324546&type=pdf&coll=&dl=ACM&CFID=15151515&CFTOKEN=6184618}
}

@ARTICLE{abidi04,
  author = {Abidi, Besma and Liang, Jimin and Mitckes, Mark and Abidi, Mongi},
  title = {Improving the Detection of Low--Density Weapons in X--Ray Luggage
	Scans using Image Enhancement and Novel Scene--Decluttering Techniques},
  journal = {Journal of Electronic Imaging},
  year = {2004},
  volume = {13},
  pages = {523--538},
  number = {3},
  month = jul,
  abstract = {Very few image processing applications have dealt with x-ray luggage
	scenes in the past. Concealed threats in general, and low--density
	items in particular, pose a major challenge to airport screeners.
	A simple enhancement method for data decluttering is introduced.
	Initially, the method is applied using manually selected thresholds
	to progressively generate decluttered slices. Further automation
	of the algorithm, using a novel metric based on the Radon transform,
	is conducted to determine the optimum number and values of thresholds
	and to generate a single optimum slice for screener interpretation.
	A comparison of the newly developed metric to other known metrics
	demonstrates the merits of the new approach. On--site quantitative
	and qualitative evaluations of the various decluttered images by
	airport screeners further establishes that the single slice from
	the image hashing algorithm outperforms traditional enhancement techniques
	with a noted increase of 58% in low--density threat detection rates.},
  doi = {10.1117/1.1760571},
  file = {Improving the detection of low-density weapons in x-ray etc (B Abidi et al).pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\LIP\\Improving the detection of low-density weapons in x-ray etc (B Abidi et al).pdf:PDF},
  keywords = {LIP},
  language = {english}
}

@BOOK{alviramartin04,
  title = {La Encuesta: Una perspectiva general metodológica.},
  publisher = {Ed. Centro de Investigaciones Sociológicas},
  year = {2004},
  author = {Alvira--Martín, F.},
  keywords = {Questionnaires},
  language = {spanish},
  owner = {Jose Manuel},
  timestamp = {2009.05.09}
}

@ARTICLE{apfelbaum05,
  author = {Apfelbaum, H. and Apfelbaum, D. and Woods, R. and Peli, Eli},
  title = {The effect of edge filtering on vision multiplexing},
  journal = {SID Digest},
  year = {2005},
  volume = {1},
  pages = {5},
  language = {english},
  owner = {jose},
  timestamp = {2007.08.14}
}

@BOOK{argimonpallas05,
  title = {Métodos de investigación clínica y epidemiológica},
  publisher = {Elsevier},
  year = {2005},
  author = {Argimon--Pallás, J.M. and Jiménez--Villa, J.},
  edition = {3},
  keywords = {Questionnaires},
  language = {spanish},
  owner = {Jose Manuel},
  timestamp = {2009.05.11}
}

@MISC{bajavisionWEB,
  author = {{Baja Visi\'on Angel Bara\~nano}},
  title = {?`{Qu\'e} es la Baja Visi\'on?},
  howpublished = {Website},
  month = aug,
  year = {2007},
  language = {spanish},
  owner = {jose},
  timestamp = {2007.08.08},
  url = {http://www.baja-vision.org/bajavision.htm}
}

@TECHREPORT{dossierBajaVision,
  author = {{Baja Visi\'on Angel Bara\~nano}},
  title = {Dossier sobre la Baja Visi\'on},
  institution = {BVAB.},
  year = {2007},
  file = {dossierBajaVision.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\Low-Vision\\dossierBajaVision.pdf:PDF},
  language = {spanish},
  owner = {jose},
  timestamp = {2007.08.08},
  url = {http://www.baja-vision.org/dossier.pdf}
}

@ARTICLE{baylor79,
  author = {Baylor, D. A. and Lamb, T.D. and Yau, K.W.},
  title = {Responses of retinal rods to single photons},
  journal = {Journal of Physiology},
  year = {1979},
  volume = {288},
  pages = {613--634},
  number = {1},
  month = mar,
  abstract = {1. A suction electrode was used to record the membrane current of
	single rod outer segments in pieces of toad retina. During dim illumination
	the membrane current showed pronounced fluctuations. 2. Amplitude
	histograms of responses to dim flashes of fixed intensity exhibited
	two discrete peaks, one at 0 pA and one near 1 pA, suggesting that
	the response was quantized. By setting a criterion amplitude level,
	flash responses could be classed as 'failures' (no response) or as
	'successes' (at least one quantal event). 3. The variation of fraction
	of successes with flash intensity was consistent with the hypothesis
	that each quantal electrical event resulted from a single photoisomerization.
	4. The quantal event had a mean amplitude of about 1 pA (5% of the
	standing dark current) and a standard deviation of 0.2 pA. Dispersion
	in the event amplitude prevented identification of histogram peaks
	corresponding to two or more photoisomerizations. 5. Individual quantal
	responses exhibited a smooth shape very similar to that of the average
	quantal response. This suggests that a single photoisomerization
	releases many particles of transmitter and that radial diffusion
	of internal transmitter is not a major source of delay in the light
	response. 6. The 'quantum efficiency' with which an absorbed photon
	generated an electrical event was measured as 0.5 +/- 0.1 (S.E. of
	mean, n = 4). This is slightly lower than the quantum efficiency
	of photoisomerization obtained previously for rhodopsin in solution.
	7. At wavelengths between 420 and 700 nm the quantal event was invariant
	in size, although the cell's sensitivity varied over a range of 10(5).
	8. The power spectrum of the fluctuations in dim steady light was
	predicted by assuming that a random series of quantal events occurred
	independently. 9. In brighter light the fluctuations were faster,
	and the response to an incremental flash was reduced in size and
	duration. The power spectrum could be predicted by assuming random
	superposition of events with the shape of the incremental flash response.},
  language = {english}
}

@ARTICLE{baylor84,
  author = {Baylor, D. A. and Nunn, B.J. and Schnapf, J.L.},
  title = {The photocurrent, noise and spectral sensitivity of rods of the monkey
	macaca fascicularis.},
  journal = {Journal of Physiology},
  year = {1984},
  volume = {347},
  pages = {575--607},
  number = {1},
  month = dec,
  abstract = {1. Visual transduction in rods of the cynomolgus monkey, Macaca fascicularis,
	was studied by recording membrane current from single outer segments
	projecting from
	
	small pieces of retina. 
	
	2. Light flashes evoked transient outward-going photocurrents with
	saturating amplitudes of up to 34 pA. A flash causing twenty to fifty
	photoisomerizations gave a response of half the saturating amplitude.
	The response-stimulus relation was of the form 1-e-x where x is flash
	strength.
	
	3. The response to a dim flash usually had a time to peak of 150-250
	ms and resembled the impulse response of a series of six low-pass
	filters.
	
	4. From the average spectral sensitivity of ten rods the rhodopsin
	was estimated to have a peak absorption near 491 nm.
	
	5. The spectral sensitivity of the rods was in good agreement with
	the average human scotopic visibility curve determined by Crawford
	(1949), when the human curve was corrected for lens absorption and
	self-screening of rhodopsin.
	
	6. Fluctuations in the photocurrent evoked by dim lights were consistent
	with a quantal event about 0-7 pA in peak amplitude.
	
	7. A steady light causing about 100 photoisomerizations s-1 reduced
	the flash sensitivity to half the dark-adapted value. At higher background
	levels the rod rapidly saturated. These results support the idea
	that dim background light desensitizes human scotopic vision by a
	mechanism central to the rod outer segments while scotopic saturation
	may occur within the outer segments. 
	
	8. Recovery of the photocurrent after bright flashes was marked by
	quantized step-like events. The events had the properties expected
	if bleached rhodopsin in the disks occasionally caused an abrupt
	blockage of the dark current over about one-twentieth of the length
	of the outer segment. It is suggested that superposition of these
	events after bleaching may contribute to the threshold elevation
	measured psychophysically.
	
	9. The current in darkness showed random fluctuations which disappeared
	in bright light. The continuous component of the noise had a variance
	of about 0-03 pA2 and a power spectrum that fell to half near 3 Hz.
	A second component, consisting of discrete events resembling single-photon
	responses, was estimated to occur at a rate of 0-006 s-1. It is suggested
	that the continuous component of the noise may be removed from scotopic
	vision by a thresholding operation near the rod output.},
  language = {english},
  owner = {jose},
  timestamp = {2009.07.24}
}

@ARTICLE{bergman92,
  author = {Bergman, B and Sj\"ostrand, J},
  title = {Vision and visual disability in the daily life of a representative
	population sample aged 82 years},
  journal = {Acta Ophthalmologica},
  year = {1992},
  volume = {70},
  pages = {33--43},
  language = {english},
  owner = {jose},
  timestamp = {2008.10.02}
}

@ARTICLE{bernth81,
  author = {Bernth-Petersen, P.},
  title = {Visual functioning in cataract patients: {Methods} of measuring and
	results},
  journal = {Acta Opthalmologica},
  year = {1981},
  volume = {59},
  pages = {198--205},
  language = {english},
  owner = {jose},
  timestamp = {2008.10.02}
}

@INPROCEEDINGS{bichsel94,
  author = {Bichsel, Martin},
  title = {Illumination invariant motion segmentation of simply connected objects},
  booktitle = {Proceedings of the 5th British Machine Vision Conference {BMVC--1994}},
  year = {1994},
  pages = {459--468},
  address = {York, UK.},
  month = {13--16, September},
  abstract = {A new segmentation algorithm exploits local image quantities which
	are invariant to changing illumination. Local object--background
	probability estimates are obtained by comparing illumination invariant
	quantities in an actual image with the corresponding quantities in
	a reference image. The objects' simply connectedness is included
	directly into the probability estimates and leads to an iterative
	optimization procedure that is implemented efficiently. This new
	approach avoids early thresholding, explicit edge detection, motion
	analysis, and grouping.},
  file = {illumination-invariant-motion-segmentation.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\illumination-invariant-motion-segmentation.pdf:PDF},
  key = {bich93},
  language = {english}
}

@ARTICLE{bichsel94b,
  author = {Bichsel, Martin},
  title = {Segmenting simply connected moving objects in a static scene},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {1994},
  volume = {16},
  pages = {1138--1142},
  number = {11},
  month = nov,
  abstract = {A new segmentation algorithm is derived, based on an object-background
	probability estimate exploting the experimental fact that the statistics
	of local image derivatives show a Laplacian distribution. The objects'
	simple connectedness is included directly into the probability estimate
	and leads to an iterative optimization approach that can be implemented
	efficiently. This new approach avoids early thresholding, explicit
	edge detection, motion analysis, and grouping.},
  doi = {10.1109/34.334396},
  file = {Simply connected (Bichsel).pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\Simply connected (Bichsel).pdf:PDF},
  language = {english}
}

@TECHREPORT{bikson81,
  author = {Bikson, TH and Bikson, TK},
  title = {Functional problems of the visually impaired: a research approach},
  institution = {Santa Monica, CA, Rand Corporation},
  year = {1981},
  type = {Rand Paper Series, P-6648},
  language = {english},
  owner = {jose},
  timestamp = {2008.10.02}
}

@ARTICLE{bolter07,
  author = {Bolter, {Jay David} and Macintyre, Blair},
  title = {Is it live or is it {AR}?},
  journal = {IEEE Spectrum (INT)},
  year = {2007},
  volume = {44},
  pages = {24-29},
  number = {8},
  month = aug,
  language = {english},
  owner = {jose},
  timestamp = {2007.08.14}
}

@BOOK{bradburn04,
  title = {Asking questions: the definitive guide to questionnaire design ---
	for market research, political polls, and social and health questionnaires},
  publisher = {John Wiley \& Sons, Inc.},
  year = {2004},
  author = {Bradburn, Norman M. and Wansink, Brian and Sudman, Seymour},
  series = {ISBN: 0--7879--7088--3},
  address = {San Francisco, USA.},
  edition = {1},
  file = {Jossey Bass - Asking Questions The Definitive Guide To Questionnaire Design.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\libros\\encuestas\\Jossey Bass - Asking Questions The Definitive Guide To Questionnaire Design.pdf:PDF},
  keywords = {Questionnaires},
  language = {english}
}

@ARTICLE{brenner93,
  author = {Brenner, MH and Curbow, B and Javitt, JC},
  title = {Vision change and quality of life in the elderly. Response to cataract
	surgery and treatment of other chronic ocular conditions},
  journal = {Arch Ophthalmol},
  year = {1993},
  volume = {111},
  pages = {680--685},
  language = {english},
  owner = {jose},
  timestamp = {2008.10.02}
}

@ARTICLE{bringier08,
  author = {Bringier, B. and Quintard, L. and Larabi, M.--C.},
  title = {Quality assessement for {CRT} and {LCD} color reproduction using
	a blind metric},
  journal = {Electronic Letters on Computer Vision and Image Analysis},
  year = {2008},
  volume = {7},
  pages = {23--25},
  number = {3},
  language = {english},
  owner = {Jose Manuel},
  timestamp = {2009.04.26}
}

@INPROCEEDINGS{brostow01,
  author = {Brostow, Gabriel J. and Essa, Irfan},
  title = {Image--based motion blur for stop motion animation},
  booktitle = {Proceedings of the 28th Annual Conference on Computer Graphics and
	Interactive Techniques, SIGGRAPH'01},
  year = {2001},
  pages = {561--566},
  address = {Los Angeles, (CA), USA},
  month = aug,
  abstract = {Stop motion animation is a well--established technique where still
	pictures of static scenes are taken and then played at film speeds
	to show motion. A major limitation of this method appears when fast
	motions are desired; most motion appears to have sharp edges and
	there is no visible motion blur. Appearance of motion blur is a strong
	perceptual cue, which is automatically present in live--action films,
	and synthetically generated in animated sequences. In this paper,
	we present an approach for automatically simulating motion blur.
	Ours is wholly a post-process, and uses image sequences, both stop
	motion or raw video, as input. First we track the frame--to--frame
	motion of the objects within the image plane. We then integrate the
	scene's appearance as it changed over a period of time. This period
	of time corresponds to shutter speed in live-action filming, and
	gives us interactive control over the extent of the induced blur.
	We demonstrate a simple implementation of our approach as it applies
	to footage of different motions and to scenes of varying complexity.
	Our photorealistic renderings of these input sequences approximate
	the effect of capturing moving objects on film that is exposed for
	finite periods of time.},
  doi = {10.1145/383259.383325},
  language = {english}
}

@ARTICLE{bruni04,
  author = {Bruni, Vittoria and Vitulano, Domenico},
  title = {A generalized model for scratch detection},
  journal = {IEEE Transactions on Image Processing},
  year = {2004},
  volume = {13},
  pages = {44--50},
  number = {1},
  month = jan,
  abstract = {This paper presents a generalization of Kokaram's model for scratch
	lines detection on digital film materials. It is based on the assumption
	that scratch is not purely additive on a given image but shows also
	a destroying effect. This result allows us to design a more efficacious
	scratch detector which performs on a hierarchical representation
	of a degraded image, i.e., on its cross section local extrema. Thanks
	to Weber's law, the proposed detector even works well on slight scratches
	resulting completely automatic, except for the scratch color (black
	or white). The experimental results show that the proposed detector
	works better in terms of good detection and false alarms rejection
	with a lower computing time.},
  doi = {10.1109/TIP.2003.817231},
  language = {english}
}

@ARTICLE{bruzzone02,
  author = {Bruzzone, Lorenzo and Fern\'andez Prieto, Diego},
  title = {An adaptive semiparametric and context--based approach to unsupervised
	change detection in multitemporal remote--sensing images},
  journal = {IEEE Transactions on Image Processing},
  year = {2002},
  volume = {11},
  pages = {452--466},
  number = {4},
  month = apr,
  abstract = {A novel automatic approach to the unsupervised identification of changes
	in multitemporal remote-sensing images is proposed. This approach,
	unlike classical ones, is based on the formulation of the unsupervised
	change-detection problem in terms of the Bayesian decision theory.
	In this context, an adaptive semiparametric technique for the unsupervised
	estimation of the statistical terms associated with the gray levels
	of changed and unchanged pixels in a difference image is presented.
	Such a technique exploits the effectivenesses of two theoretically
	well-founded estimation procedures: the reduced Parzen estimate (RPE)
	procedure and the expectation-maximization (EM) algorithm. Then,
	thanks to the resulting estimates and to a Markov random field (MRF)
	approach used to model the spatial-contextual information contained
	in the multitemporal images considered, a change detection map is
	generated. The adaptive semiparametric nature of the proposed technique
	allows its application to different kinds of remote-sensing images.
	Experimental results, obtained on two sets of multitemporal remote-sensing
	images acquired by two different sensors, confirm the validity of
	the proposed approach},
  doi = {10.1109/TIP.2002.999678},
  file = {An adaptive semiparametric and context--based approach to unsupervised change detection (Bruzzone and Fernandez Prieto).pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\An adaptive semiparametric and context--based approach to unsupervised change detection (Bruzzone and Fernandez Prieto).pdf:PDF},
  key = {bruz02},
  language = {english}
}

@INPROCEEDINGS{bruzzone99,
  author = {Bruzzone, Lorenzo and Fern\'andez Prieto, Diego},
  title = {An {MRF} approach to unsupervised change detection},
  booktitle = {Proceedings of the 1999 International Conference on Image Processing
	{(ICIP--1999)}},
  year = {1999},
  volume = {1},
  pages = {143--147},
  address = {Kobe, Japan.},
  month = {24--28, October},
  doi = {10.1109/ICIP.1999.821583},
  file = {An MRF Approach to Unsupervised Change Detection.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\An MRF Approach to Unsupervised Change Detection.pdf:PDF},
  key = {bruz99},
  language = {english}
}

@TECHREPORT{burgess01,
  author = {Burgess, Thomas F.},
  title = {A general introduction to the design of questionnaires for survey
	research},
  institution = {University of Leeds},
  year = {2001},
  month = may,
  file = {A general introduction to the design of questionnaires for survey research (Burgess) Univ Leeds 2001.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\libros\\encuestas\\A general introduction to the design of questionnaires for survey research (Burgess) Univ Leeds 2001.pdf:PDF},
  keywords = {Questionnaires},
  language = {english}
}

@INPROCEEDINGS{cahill97,
  author = {Cahill, Lawrence W. and Deng, Guang},
  title = {An overview of logarithm--based image processing techniques for biomedical
	applications},
  booktitle = {Proceedings of the 13th International Conference on Digital Signal
	Processing {{DSP}--1997}},
  year = {1997},
  volume = {1},
  pages = {93--96},
  address = {Santorini, Greece.},
  month = {2--4, July},
  abstract = {Logarithm--based image processing methods are of interest since they
	have the capability to enhance low--contrast images. This paper presents
	an overview of the three logarithm--based image processing techniques:
	the multiplicative homomorfic system (MHS), the Log--ratio (LR) and
	the logarithmic image processing model (LIP). They are compared from
	physical, computational, and application point of views.},
  doi = {10.1109/ICDSP.1997.627976},
  file = {An overview of Logarithm-based Image processing techniques f.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\LIP\\An overview of Logarithm-based Image processing techniques f.pdf:PDF},
  keywords = {LIP},
  language = {english}
}

@ARTICLE{canny86,
  author = {Canny, John},
  title = {A computational approach to edge detection},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {1986},
  volume = {8},
  pages = {679--698},
  number = {6},
  month = nov,
  language = {english}
}

@INPROCEEDINGS{carnec03,
  author = {Carnec, M. and Le Callet, P. and Barba, D.},
  title = {Full reference and reduced reference metrics for image quality assessment},
  booktitle = {Signal Processing and Its Applications, 2003. Proceedings. Seventh
	International Symposium on},
  year = {2003},
  volume = {1},
  pages = {477-480 vol.1},
  month = jul,
  abstract = {In this paper, we propose efficient full reference and reduced reference
	image quality assessment metrics. These two metrics are based on
	human visual system properties to get the best correspondence with
	human judgments. The full reference metric is generic (independent
	from image distortion type) and convenient for image coding schemes
	comparison. From this metric, we have derived a reduced reference
	metric suitable for quality of service monitoring in a broadcasting
	purpose. The two metrics share common processings. The main difference
	between them comes from the selection of information in order to
	get a high-level representation of images for a reduced reference
	metric. If limited to a specific type of image coding scheme, the
	two metrics achieve similar performances.},
  doi = {10.1109/ISSPA.2003.1224743},
  keywords = {broadcasting, image coding, image representation, quality of service
	full reference metric, high-level image representation, human visual
	system property, image broadcasting purpose, image coding scheme,
	image distortion, image quality assessment, quality of service monitoring,
	reduced reference metric},
  language = {english},
  owner = {Jose Manuel},
  timestamp = {2009.04.10}
}

@INPROCEEDINGS{cavallaro02,
  author = {Cavallaro, Andrea and Drelie Gelasca, Elisa and Ebrahimi, Touradj},
  title = {Objective evaluation of segmentation quality using spatio--temporal
	context},
  booktitle = {Proceedings of the 2002 International Conference on Image Processing
	{(ICIP--2002)}},
  year = {2002},
  volume = {3},
  pages = {301---304},
  abstract = {In this paper, we propose an automatic method for the objective evaluation
	of segmentation results. The method is based on computing the deviation
	of the segmentation results from a reference segmentation. The discrepancy
	between two results is weighted based on spatial and temporal contextual
	information, by taking into account the way humans perceive visual
	information. The metric is useful for applications where the final
	judge of the quality is a human observer or the results of segmentation
	are otherwise processed in a human-like fashion. The proposed evaluation
	has been applied both to automatically provide a ranking among different
	segmentation algorithms and to optimally set the parameters of a
	given algorithm.},
  doi = {10.1109/ICIP.2002.1038965},
  key = {cava02},
  language = {english}
}

@MISC{ccir90,
  author = {{CCIR}},
  title = {{Test pictures and sequences for subjective assessments of digital
	codecs}},
  howpublished = {Report 1213},
  year = {1990},
  note = {Anex to Volume IX, Part 1.},
  language = {english},
  owner = {jose},
  timestamp = {2006.11.01}
}

@BOOK{ceadancona04,
  title = {Métodos de encuesta. {Teoría} y práctica, errores y mejora.},
  publisher = {Ed. Síntesis},
  year = {2004},
  author = {Cea D'{}ancona, M.A.},
  address = {Madrid},
  keywords = {Questionnaires},
  language = {spanish},
  owner = {Jose Manuel},
  timestamp = {2009.05.08}
}

@ARTICLE{cinque94,
  author = {L. Cinque and C. Guerra and S. Levialdi},
  title = {On the paper by {R. M. Haralick}},
  journal = {CVGIP: Image Understanding},
  year = {1994},
  volume = {60},
  pages = {250 - 252},
  number = {2},
  doi = {DOI: 10.1006/ciun.1994.1051},
  issn = {1049-9660},
  language = {english},
  owner = {jose},
  timestamp = {2008.12.29},
  url = {http://www.sciencedirect.com/science/article/B6WDD-45P0W80-P/2/ef2fb5d1b32b45e4da95d4e50b676406}
}

@MISC{clarityCompany,
  author = {Clarity},
  title = {Products},
  howpublished = {Website},
  month = mar,
  year = {2009},
  language = {english},
  owner = {Jose Manuel},
  timestamp = {2009.03.20},
  url = {http://www.clarityusa.com/index.php?option=com_content&task=view&id=17&Itemid=35}
}

@ARTICLE{cohen58,
  author = {Walter Cohen},
  title = {Color--perception in the chromatic {Ganzfeld}},
  journal = {The American Journal of Psychology},
  year = {1958},
  volume = {71},
  pages = {390--394},
  number = {2},
  month = jun,
  language = {english},
  owner = {Jose Manuel},
  timestamp = {2009.04.16}
}

@ARTICLE{comaniciu02,
  author = {Comaniciu, Dorin and Meer, Peter},
  title = {{Mean Shift}: A robust approach toward feature space analysis},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {2002},
  volume = {24},
  pages = {603--619},
  number = {5},
  month = may,
  abstract = {A general non--parametric technique is proposed for the analysis of
	a complex multimodal feature space and to delineate arbitrarily shaped
	clusters in it. The basic computational module of the technique is
	an old pattern recognition procedure: the mean shift. For discrete
	data, we prove the convergence of a recursive mean shift procedure
	to the nearest stationary point of the underlying density function
	and, thus, its utility in detecting the modes of the density. The
	relation of the mean shift procedure to the Nadaraya--Watson estimator
	from kernel regression and the robust M--estimators; of location
	is also established. Algorithms for two low--level vision tasks discontinuity--preserving
	smoothing and image segmentation --- are described as applications.
	In these algorithms, the only user-set parameter is the resolution
	of the analysis, and either gray--level or color images are accepted
	as input. Extensive experimental results illustrate their excellent
	performance.},
  doi = {10.1109/34.1000236},
  key = {coma02},
  keywords = {Mean Shift},
  language = {english}
}

@INPROCEEDINGS{comaniciu97,
  author = {Comaniciu, Dorin and Meer, Peter},
  title = {Robust analysis of features spaces: color image segmentation},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition {{CVPR}--1997}},
  year = {1997},
  pages = {750--755},
  address = {San Juan, Puerto Rico.},
  month = {17--19, June},
  abstract = {A general technique for the recovery of significant image features
	is presented. The technique is based on the mean shift algorithm,
	a simple nonparametric procedure for estimating density gradients.
	Drawbacks of the current methods (including robust clustering) are
	avoided. Feature space of any nature can be processed, and as an
	example, color image segmentation is discussed. The segmentation
	is completely autonomous, only its class is chosen by the user. Thus,
	the same program can produce a high quality edge image, or provide,
	by extracting all the significant colors, a preprocessor for content-based
	query systems. A 512×512 color image is analyzed in less than 10
	seconds on a standard workstation. Gray level images are handled
	as color images having only the lightness coordinate},
  doi = {10.1109/CVPR.1997.609410},
  key = {coma97},
  language = {english}
}

@INPROCEEDINGS{comaniciu00,
  author = {Comaniciu, Dorin and Visvanathan, Ramesh and Meer, Peter},
  title = {Real--time tracking of non--rigid objects using {Mean Shift}},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition {{CVPR}--2000}},
  year = {2000},
  volume = {2},
  pages = {142--149},
  address = {Hilton Head Island (SC), USA.},
  month = {13--15, June},
  note = {Best Paper Award},
  abstract = {A new method for real time tracking of non-rigid objects seen from
	a moving camera is proposed. The central computational module is
	based on the mean shift iterations and finds the most probable target
	position in the current frame. The dissimilarity between the target
	model (its color distribution) and the target candidates is expressed
	by a metric derived from the Bhattacharyya coefficient. The theoretical
	analysis of the approach shows that it relates to the Bayesian framework
	while providing a practical, fast and efficient solution. The capability
	of the tracker to handle in real time partial occlusions, significant
	clutter, and target scale variations, is demonstrated for several
	image sequences.},
  doi = {10.1109/CVPR.2000.854761},
  file = {Real-Time Tracking of Non-Rigid Objects using Mean Shift (Comaniciu and Ramesh and Meer).pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\mean shift\\Real-Time Tracking of Non-Rigid Objects using Mean Shift (Comaniciu and Ramesh and Meer).pdf:PDF},
  key = {coma00},
  language = {english}
}

@MISC{CAO-web,
  author = {{Consejo Argentino de Oftalmolog\'{\i}a}},
  title = {Cuestionario de Calidad Visual ({CCV-07}) auto evaluativo--asistido},
  howpublished = {Website},
  month = jun,
  year = {2008},
  abstract = {A continuaci\'on encontrar\'a un cuerstionario en el que podr\'a evaluar
	la capacidad--calidad visual en ambos ojos de una persona con capacidad
	residual Menor a Una D\'ecima en la Escala de Snellen (MUDES) en
	su mejor ojo. Es un cuestionario asistido o sea que deber\'a ser
	guiado por personas capacitadas con buena agudeza visual. Se basa
	en 8 preguntas sencillas con 3 respuestas posibles cada una. Deber\'a
	tomar nota del puntaje correspondiente a la respuesta correcta, y
	al finalizar el test sumar todos los puntajes. Score m\'as favorable:
	37 Score m\'as desfavorable: 111 Al completar este cuestionario antes
	de comenzar un tratamiento de rehabilitaci\'on y al cabo de 3, 6
	o m\'as meses posteriores a \'este podr\'a evaluar los cambios sufridos
	y los beneficios obtenidos de dicho tratamiento. Si Ud. ha completado
	este cuestionario env\'{\i}e los resultados obtenidos. A vuelta de
	correo recibir\'a de parte nuestra la posibilidad de consultar un
	oftalm\'ologo especialista en baja visi\'on.},
  file = {CAO - Baja Visión.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\Low-Vision\\CAO - Baja Visión.pdf:PDF},
  language = {spanish},
  owner = {jose},
  timestamp = {2008.07.27},
  url = {http://www.bajavision.org.ar/pacientes/evalue\_calidad.html}
}

@BOOK{coren98,
  title = {Sensation and Perception},
  publisher = {Hartcourt Brace},
  year = {1998},
  author = {Coren and Ward and Enns},
  edition = {5},
  language = {english},
  owner = {Jose Manuel},
  timestamp = {2009.04.16}
}

@ARTICLE{coren87,
  author = {Coren, S and Hakstian, R},
  title = {Visual screening without the use of technical equipment: preliminary
	development of a behaviorally validated questionnaire},
  journal = {Journal of Applied Optics},
  year = {1987},
  volume = {26},
  pages = {1468--1472},
  language = {english},
  owner = {jose},
  timestamp = {2008.10.02}
}

@MISC{cost211quat,
  author = {{COST 211quat}},
  title = {{Call for Analysis Model Comparisons}},
  howpublished = {Website},
  year = {2001},
  language = {english},
  owner = {jose},
  timestamp = {2006.11.02},
  url = {http://www.iva.cs.tut.fi/COST211/Call/Call.htm}
}

@ARTICLE{courbebaisse02,
  author = {Courbebaisse, Guy and Trunde, Frederic and Jourlin, Michel},
  title = {Wavelet Transform and {LIP} Model},
  journal = {Image Analysis and Stereology},
  year = {2002},
  volume = {21},
  pages = {121--125},
  number = {2},
  month = jun,
  abstract = {The Fourier transform is well suited to the study of stationary functions.
	Yet, it is superseded by the Wavelet transform for the powerful characterizations
	of function features such as singularities. On the other hand, the
	LIP (Logarithmic Image Processing) model is a mathematical framework
	developed by Jourlin and Pinoli, dedicated to the representation
	and processing of gray tones images called hereafter logarithmic
	images. This matematically well defined model, comprising a Fourier
	Transform "of its own", provides an effective tool for the representation
	of images obtained by transmitted light, such as microscope images.
	This paper presents a Wavelet transform within the LIP framework,
	with preservation of the classical Wavelet Transform properties.
	We show that the fast computation algorithm due to Mallat can be
	easily used. An application is given for the detection of crests.},
  file = {Wavelet transform and LIP model (G Courbebaisse, F Trunde and M Jourlin).pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\LIP\\Wavelet transform and LIP model (G Courbebaisse, F Trunde and M Jourlin).pdf:PDF},
  keywords = {LIP, Logarithmic Wavelet Transform, Wavelet Transform},
  language = {english},
  url = {http://www.wise-t.com/ias/download.php?article\_id=93}
}

@MISC{grandchallenge,
  author = {DARPA},
  title = {Grand Challenge},
  howpublished = {Website},
  language = {english},
  owner = {jose},
  timestamp = {2008.10.17},
  url = {http://www.darpa.mil/grandchallenge/}
}

@TECHREPORT{dawsonhowe96,
  author = {Dawson--Howe, Kenneth M.},
  title = {Active surveillance using dynamic background subtraction},
  institution = {Trinity College Dublin},
  year = {1996},
  type = {Technical Report},
  number = {TCD--CS--96--06},
  address = {Trinity College Dublin. Department of Computer Science. Computer
	Vision and Robotics Group.},
  month = aug,
  abstract = {A prototype active surveillance system is presented. The system has
	two cameras, one of which is rigidly fixed & has a wide angle lenses
	while the other is mounted on a pan--tilt head & has a zoomed lenses.
	The images from the wide angle camera are analyzed using dynamic
	background subtraction together with normalized cross correlation
	in order to identify moving people within the scene. An approximate
	mapping is determined (off--line) between the pan--tilt angles and
	the position of the zoomed image within the wide--angle view. This
	mapping is improved (for each frame) through 1--D image based correlation
	and hence moving people are located in the zoomed view. The system
	has been tested on a difficult real--world scene and image sequences
	from both cameras are presented. The potential of the system as an
	`intelligent' security device and the power of the dynamic background
	subtraction & correlation mechanism are clearly demonstrated.},
  file = {dawson-howe96active.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\background subtraction\\dawson-howe96active.pdf:PDF},
  key = {daws96},
  keywords = {Change Detection},
  language = {english},
  url = {ftp://ftp.cs.tcd.ie/pub/tcd/tech-reports/reports.96/TCD-CS-96-06.ps.gz}
}

@ARTICLE{debayle09,
  author = {Debayle, Johan and Pinoli, Jean--Charles},
  title = {General Adaptive Neighborhood Choquet Image Filtering},
  journal = {Journal of Mathematical Imaging and Vision},
  year = {2009},
  volume = {35},
  pages = {173--185},
  number = {3},
  doi = {10.1007/s10851-009-0163-0},
  language = {english},
  owner = {jose},
  timestamp = {2010.11.13}
}

@ARTICLE{delorme01,
  author = {Delorme, Arnaud and Thorpe, Simon J.},
  title = {Face Identification using One Spike per Neuron: Resistance to Image
	Degradations},
  journal = {Neural Networks},
  year = {2001},
  volume = {14},
  pages = {795--803},
  number = {6--7},
  month = {July--September},
  abstract = {The short response latencies of face selective neurons in the inferotemporal
	cortex impose major constraints on models of visual processing. It
	appears that visual information must essentially propagate in a feed-forward
	fashion with most neurons only having time to fire one spike. We
	hypothesize that flashed stimuli can be encoded by the order of firing
	of ganglion cells in the retina and propose a neuronal mechanism,
	that could be related to fast shunting inhibition, to decode such
	information. Based on these assumptions, we built a three-layered
	neural network of retino-topically organized neuronal maps. We showed,
	by using a learning rule involving spike timing dependant plasticity,
	that neuronal maps in the output layer can be trained to recognize
	natural photographs of faces. Not only was the model able to generalize
	to novel views of the same faces, it was also remarkably resistant
	to image noise and reductions in contrast.},
  doi = {10.1016/S0893-6080(01)00049-1},
  file = {Rank order coding Face_identification.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\Rank Order Coding\\Rank order coding Face_identification.pdf:PDF},
  keywords = {Rank Order Coding},
  language = {english}
}

@ARTICLE{dempster77,
  author = {Dempster, A. and Laird, N. and Rubin, Donald B.},
  title = {Maximum likelihood from incomplete data via {EM} algorithm},
  journal = {Journal of the Royal Statistical Society},
  year = {1977},
  volume = {1},
  pages = {1--38},
  number = {39 (Series B)},
  key = {demp77},
  language = {english}
}

@ARTICLE{deng93,
  author = {Deng, Guang and Cahill, Lawrence W.},
  title = {Multiscale image enhancement using the logarithmic image processing
	model},
  journal = {Electronics Letters},
  year = {1993},
  volume = {29},
  pages = {803--804},
  number = {9},
  month = apr,
  abstract = {A multiscale image decomposition and enhancement algorithm is presented.
	This algorithm is developed using a mathematical structure called
	the logarithmic image processing model. This algorithm is a novel
	approach to improving image contrast, yet at the same time achieving
	noise suppression},
  file = {Multiscale Image Enhancement using the logarithmic image pro.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\LIP\\Multiscale Image Enhancement using the logarithmic image pro.pdf:PDF},
  keywords = {LIP},
  language = {english},
  url = {http://ieeexplore.ieee.org/xpl/abs\_free.jsp?arNumber=211279}
}

@INPROCEEDINGS{deng93b,
  author = {Deng, Guang and Cahill, Lawrence W.},
  title = {The logarithmic image processing model and its applications},
  booktitle = {Proceedings of the 1993 27th Asilomar Conference on Signal, Systems
	and Computers},
  year = {1993},
  volume = {2},
  pages = {1047-1051},
  address = {Pacific Grove (CA), USA.},
  month = {1--3, November},
  abstract = {This paper presents a summary of operations of the logarithmic image
	processing (LIP) model and its applications. The LIP model is a mathematical
	framework which provides a set of generalised version of addition,
	subtraction, multiplication, convolution and so on, for signal processing.
	First, we briefly describe the LIP model and point out its distinctive
	properties for image processing. Then we summarize the current applications
	of the LIP model. A novel image filtering algorithm and its extension
	to multiscale processing along with the LIP model based Sobel operator
	for edge detection are discussed in detail. Finally, we suggest further
	research area of the LIP model},
  doi = {10.1109/ACSSC.1993.342410},
  file = {The Logarithmic Image Processing Model and its Applications .pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\LIP\\The Logarithmic Image Processing Model and its Applications .pdf:PDF},
  keywords = {LIP},
  language = {english}
}

@ARTICLE{deng95,
  author = {Deng, Guang and Cahill, Lawrence W. and Tobin, Geoffrey Richard},
  title = {The Study of Logarithmic Image--Processing Model and Its Application
	to Image--Enhancement},
  journal = {IEEE Transactions on Image Processing},
  year = {1995},
  volume = {4},
  pages = {506--512},
  number = {4},
  month = apr,
  abstract = {Describes a new implementation of Lee's (1980) image enhancement algorithm.
	This approach, based on the logarithmic image processing (LIP) model,
	can simultaneously enhance the overall contrast and the sharpness
	of an image. A normalized complement transform has been proposed
	to simplify the analysis and the implementation of the LIP model-based
	algorithms. This new implementation has been compared with histogram
	equalization and Lee's original algorithm},
  doi = {http://dx.doi.org/10.1109/83.370681},
  file = {Study of Log Image processing for Image Enhancement (Deng, C.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\LIP\\Study of Log Image processing for Image Enhancement (Deng, C.pdf:PDF},
  keywords = {LIP},
  language = {english}
}

@ARTICLE{deng98,
  author = {Deng, Guang and Pinoli, Jean--Charles},
  title = {Differentiation--Based Edge Detection using the Logarithmic Image
	Processing Model},
  journal = {Journal of Mathematical Imaging and Vision},
  year = {1998},
  volume = {8},
  pages = {161--180},
  number = {2},
  month = mar,
  abstract = {The logarithmic image processing (LIP) model is a mathematical framework
	which provides a specific set of algebraic and functional operations
	for the processing and analysis of intensity images valued in a bounded
	range. The LIP model has been proved to be physically justified by
	that it is consistent with the multiplicative transmittance and reflectance
	image formation models, and with some important laws and characteristics
	of human brightness perception. This article addresses the edge detection
	problem using the LIP-model based differentiation. First, the LIP
	model is introduced, in particular, for the gray tones and gray tone
	functions, which represent intensity values and intensity images,
	respectively. Then, an extension of these LIP model notions, respectively
	called gray tone vectors and gray tone vector functions, is studied.
	Third, the LIP-model based differential operators are presented,
	focusing on their distinctive properties for image processing. Emphasis
	is also placed on highlighting the main characteristics of the LIP-model
	based differentiation. Next, the LIP-Sobel based edge detection technique
	is studied and applied to edge detection, showing its robustness
	in locally small changes in scene illumination conditions and its
	performance in the presence of noise. Its theoretical and practical
	advantages over several well-known edge detection techniques, such
	as the techniques of Sobel, Canny, Johnson and Wallis, are shown
	through a general discussion and illustrated by simulation results
	on different real images. Finally, a discussion on the role of the
	LIP-model based differentiation in the current context of edge detection
	is presented.},
  doi = {10.1023/A:1008277328822},
  file = {Differentiation-based Edge detection using the Logarithmic Image Processing.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\LIP\\Differentiation-based Edge detection using the Logarithmic Image Processing.pdf:PDF},
  keywords = {LIP},
  language = {english}
}

@ARTICLE{cheng95,
  author = {Deng, Yizong},
  title = {Mean Shift, Mode Seeking and Clustering},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {1995},
  volume = {17},
  pages = {790--799},
  number = {8},
  month = aug,
  abstract = {Mean shift, a simple interactive procedure that shifts each data point
	to the average of data points in its neighborhood is generalized
	and analyzed in the paper. This generalization makes some k--means
	like clustering algorithms its special cases. It is shown that mean
	shift is a mode--seeking process on the surface constructed with
	a “shadow” kernal. For Gaussian kernels, mean shift is a gradient
	mapping. Convergence is studied for mean shift iterations. Cluster
	analysis if treated as a deterministic problem of finding a fixed
	point of mean shift that characterizes the data. Applications in
	clustering and Hough transform are demonstrated. Mean shift is also
	considered as an evolutionary strategy that performs multistart global
	optimization.},
  doi = {10.1109/34.400568},
  file = {Mean Shift, Mode Seeking and Clustering (Cheng) IEEE PAMI 17(8), 790-800, 1995.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\mean shift\\Mean Shift, Mode Seeking and Clustering (Cheng) IEEE PAMI 17(8), 790-800, 1995.pdf:PDF},
  key = {chen95},
  keywords = {Mean Shift},
  language = {english}
}

@ARTICLE{draper94,
  author = {B. A. Draper and J. R. Beveridge},
  title = {Response to } # Performance # Characterization # in # Computer #
	Vision,
  journal = {CVGIP: Image Understanding},
  year = {1994},
  volume = {60},
  pages = {262 - 263},
  number = {2},
  doi = {DOI: 10.1006/ciun.1994.1055},
  issn = {1049-9660},
  language = {english},
  owner = {jose},
  timestamp = {2008.12.29},
  url = {http://www.sciencedirect.com/science/article/B6WDD-45P0W80-V/2/a444f46a942e796fc96a5170be384e00}
}

@PHDTHESIS{gelascaPhTh,
  author = {Drelie Gelasca, Elisa},
  title = {Full--Reference Objective Quality Metrics for Video Watermarking,
	Video Segmentation and 3D Model Watermarking},
  school = {\'Ecole Polytechnique F\'ed\'erale de Lausanne},
  year = {2005},
  language = {english},
  owner = {jose},
  timestamp = {2010.03.11}
}

@PHDTHESIS{durucan-tesis,
  author = {Durucan, Emrullah},
  title = {Low Computational Cost Illumination Invariant Change Detection for
	Video Surveillance by Linear Independence},
  school = {\'Ecole Polyt\'echnique F\'ederale de Lausanne},
  year = {2001},
  type = {Doctoral Thesis (Number: 2454)},
  month = dec,
  abstract = {The thesis investigates the detection of changes between images for
	the low-level part of automated video--surveillance. Change detection
	for video--surveillance comprises the detection of moving objects
	in a scene. The change detector should be illumination--invariant
	as well as noise--robust, and should work in real--time. Thus, to
	detect and examine changes between two gray--value images, we model
	the reference and the current image as vector ensembles, where the
	vector components correspond to pixels. The main assumption of this
	thesis is that, regardless of illumination in the current image,
	pairs of reference and current vectors are linearly dependent. However,
	if an object in the current image changes, then these pairs are linearly
	independent. Linear algebra provides different theorems to determine
	when vectors are linearly dependent. We use these to develop algorithms
	for detecting object changes in the current image. This application
	of linear independence is an innovation. The proposed methods were
	successfully tested on an extensive surveillance image database.
	The results show that our algorithms detect object changes while
	remaining illumination--invariant. These new methods compare favorably
	with competing change detection methods, including the Shading Model,
	the Statistical Change Detection and the Derivative Model. A new
	adaptive threshold further improves object detection and noise suppression.
	We also analyze the numbers of arithmetic operations and memory accesses
	(computational costs) for the new change detection algorithms, using
	a hypothetical computer model. The execution times suggest that our
	algorithms are real--time implementable. Finally, we extend the concept
	of linear independence to detecting changes between multiple images
	and between multispectral images. These extensions are also innovations
	for image change detection. Future applications could include fast
	image segmentation, image database searches and missing data replacement
	in old video sequences.},
  file = {thesis_durucan.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\thesis\\Durucan\\thesis_durucan.pdf:PDF},
  key = {duruTES},
  keywords = {Change Detection},
  language = {english},
  url = {http://library.epfl.ch/en/theses/?nr=2454}
}

@INPROCEEDINGS{durucan03,
  author = {Durucan, Emrullah and Ebrahimi, Touradj},
  title = {Moving object detection between multiple and color images},
  booktitle = {Proceedings of the 2003 IEEE Conference on Advanced Video and Signal
	Based Surveillance {(AVSS--2003)}},
  year = {2003},
  pages = {243--251},
  month = {21--23, July},
  abstract = {There are several publications dedicated to the description and analysis
	of change detection between two gray--value images. This paper introduces
	new methods to detect moving objects between multiple images and
	to detect changes between color images or any type of multispectral
	images. We are not aware of methods giving the possibility of detecting
	color changes and changes between multiple frames. All the proposed
	change detectors are based on the Gramian determinant, which provides
	low computational cost and is easy to implement. These features are
	very important due to the additional complexity of change detection
	between multiple as well as color images.},
  doi = {10.1109/AVSS.2003.1217928},
  file = {Moving object detection between multiple and color images (D.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\change detection\\Moving object detection between multiple and color images (D.pdf:PDF},
  key = {duru03},
  keywords = {Change Detection},
  language = {english}
}

@ARTICLE{durucan01,
  author = {Durucan, Emrullah and Ebrahimi, Touradj},
  title = {Change detection and background extraction by linear algebra},
  journal = {Proceedings of the IEEE},
  year = {2001},
  volume = {89},
  pages = {1368--1381},
  number = {10},
  month = oct,
  abstract = {Change detection plays a very important role in real--time image analysis,
	e.g., detection of intruders. One key issue is robustness to varying
	illumination conditions. We propose two techniques for change detection
	that have been developed to deal with variations in illumination
	and background, with real--time capabilities. The foundations of
	these techniques are based on a vector model of images and on the
	exploitation of the concepts of linear dependence and linear independence.
	Furthermore, the techniques are compatible with physical photometry.
	A detailed description of the proposed detector and three state--of--the
	art change detectors is also provided. For the purposes of comparison,
	an evaluation procedure is presented consisting of both objective
	and subjective parts. This evaluation procedure results in a final
	performance value for each detector analyzed},
  doi = {10.1109/5.959336},
  file = {Change Detection and Background Extraction by Linear Algebra.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\change detection\\Change Detection and Background Extraction by Linear Algebra.pdf:PDF},
  key = {duru01},
  keywords = {Change Detection},
  language = {english}
}

@INPROCEEDINGS{durucan01b,
  author = {Durucan, Emrullah and Ebrahimi, Touradj},
  title = {Change Detection by nonlinear Grammian},
  booktitle = {Proceedings of the 2001 Non--linear Signal and Image Processing {(NSIP--2001)}},
  year = {2001},
  month = sep,
  file = {Change Detection by Nonlinear Grammian (Durucan and Ebrahimi) NSIP 2001.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\change detection\\Change Detection by Nonlinear Grammian (Durucan and Ebrahimi) NSIP 2001.pdf:PDF},
  key = {duru01b},
  keywords = {Change Detection},
  language = {english}
}

@INPROCEEDINGS{durucan01c,
  author = {Durucan, Emrullah and Ebrahimi, Touradj},
  title = {Improved Linear Dependence and Vector Model for illumination invariant
	Change Detection},
  booktitle = {Proceedings of the Real--time Imaging, SPIE's Photonics West 2001
	-- Electronic Imaging Conference},
  year = {2001},
  volume = {4303},
  pages = {107--114},
  month = apr,
  abstract = {Change detection generally is the difference between images. The differences
	or changes could be due to moving objects or a variation of illumination.
	In general the goal is to extract only changes due to moving object
	that occur int eh scene, and to ignore changes due to illumination.
	A requirement is that the detection has to be performed in real-time.
	The proposed change detection approach relies on a model assigning
	a vector to every pixel of the reference and the current image. Based
	on this model, linear independence is used to describe an operator
	for change detection. This previously published operator is based
	on the variance. The improved linear independence model consists
	in redefining the change detection operator to fulfill the real-time
	requirement and to improve the object detection performance. This
	model has been applied to surveillance and compared to the variance
	based linear independence detector. The operator proved to be robust
	to background and illumination changes and in the same time it detected
	object changes.},
  doi = {10.1117/12.424945},
  file = {Improved Linear Dependence and Vector Model for Illumination Invariant Change Detection (Durucan and Ebrahimi) spie 2001.pdf:C\:\\Documents and Settings\\Jose Manuel\\Mis documentos\\articulos\\change detection\\Improved Linear Dependence and Vector Model for Illumination Invariant Change Detection (Durucan and Ebrahimi) spie 2001.pdf:PDF},
  key = {duru01c},
  keywords = {Change Detection},
  language = {english}
}

@INPROCEEDINGS{durucan00,
  author = {Durucan, Emrullah and Ebrahimi, Touradj},
  title = {Robust and Illumination invariant change detection based on Linear
	Dependence for Surveillance Application},
  booktitle = {Proceedings of the 10th. European Signal Processing Conference 2000
	{(EUSIPCO--2000)}},
  year = {2000},
  volume = {2},
  pages = {1141--1144},
  month = sep,
  abstract = {The subject of this paper is to provide an illumination invariant
	moving object detector for indoor surveillance applications. Furthermore
	we want to treat the illumination change as a mathematical/physical
	transformation procedure on images. Therefore the intention to this
	paper could also be defined as to provide an operator, which is invariant
	to transformations. The proposed detector relies on a model assigning
	a vector to every pixel location of the reference and the current
	image. The vector represents information on the neighborhood region
	of that pixel. Based on the above definition, the theorem of linear
	dependence of vectors is used to describe an operator for the detection
	of objects. For the purpose of an objective evaluation, the proposed
	technique is compared to the state-of-the-art Statistical Change
	Detection method. The proposed operator proved to be robust to noise
	as well as global illumination changes and local shadows and reflections.},
  file = {Robust and Illumination invariant change detection based on Linear Dependence for Surveillance Application(durucan and ebrahimi).pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\change detection\\Robust and Illumination invariant change detection based on Linear Dependence for Surveillance Application(durucan and ebrahimi).pdf:PDF},
  key = {duru00},
  keywords = {Change Detection},
  language = {english},
  url = {http://www.eurasip.org/content/Eusipco/2000/sessions/WedPm/SS1/cr1505.pdf}
}

@INPROCEEDINGS{durucan99,
  author = {Durucan, Emrullah and Snoeckx, Joel and Weilenmann, Yves},
  title = {Illumination invariant Background Extraction},
  booktitle = {Proceedings of the 10th. International Conference on Image Analysis
	and Processing 1999 {(ICIAP--1999)}},
  year = {1999},
  pages = {1136--1139},
  address = {Venice, Italy.},
  month = {27--29, September},
  abstract = {This paper proposes a new method for the extraction of background
	objects, especially the extraction of randomly moving objects such
	as curtains and plants. For this purpose we use an optical flow method
	combined with a split-and-merge algorithm to avoid the mentioned
	background effects. The split-and-merge algorithm is based on the
	variance of regions and the optical flow method is implemented conform
	to the proposition of Horn and Schunck (1981). To further increase
	the robustness and utility in surveillance circumstances, illumination
	invariance has to be provided by the algorithm. Hence we combined
	the mentioned methods with an illumination-invariant change detector.
	Tests have been performed on indoor and outdoor surveillance sequences.
	Especially in indoor sequences the proposed method provided a very
	robust tool against illumination changes, reflections, shadows and
	randomly moving objects like curtains and plants. Nevertheless in
	all circumstances it detected the moving `semantic' objects such
	as persons},
  doi = {10.1109/ICIAP.1999.797755},
  file = {Illumination invariant background extraction (Durucan, Snoec.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\change detection\\Illumination invariant background extraction (Durucan, Snoec.pdf:PDF},
  key = {duru99},
  keywords = {Change Detection},
  language = {english}
}

@INPROCEEDINGS{elgammal99,
  author = {Elgammal, Ahmed and Harwood, David and Davis, Larry S.},
  title = {Non--parametric Model for Background Subtraction},
  booktitle = {Proceedings of the FRAME--RATE WORKSHOP of the IEEE International
	Conference on Computer Vision {ICCV'99 FRAME--RATE Workshop}},
  year = {1999},
  abstract = {Background subtraction is a method typically used to segment moving
	regions in image sequences taken from a static camera by comparing
	each new frame to a model of the scene background. We present a novel
	non--parametric background model and a background subtraction approach.
	The model can handle situations where the background of the scene
	is cluttered and not completely static but contains small motions
	such as tree branches and bushes. The model estimates the probability
	of observing pixel intensity values based on a sample of intensity
	values for each pixel. The model adapts quickly to changes in the
	scene which enables very sensitive detection of moving targets. We
	also show how the model can use color information to suppress detection
	of shadows. The implementation of the model runs in real-time for
	both gray level and color imagery. Evaluation shows that this approach
	achieves very sensitive detection with very low false alarm rates.},
  comment = {http://www.springerlink.com/link.asp?id=3mcvhnwfa8bj4ln5},
  file = {bgmodel.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\background subtraction\\bgmodel.pdf:PDF},
  keywords = {Background Subtraction, Change Detection, Motion detection},
  language = {english},
  url = {http://www.vast.uccs.edu/~tboult/FRAME/Elgammal/bgmodel.html}
}

@ARTICLE{elliott90,
  author = {Elliott, DB and Hurst, MA and Weatherill, J},
  title = {Comparing clinical tests of visual function in cataract with the
	patients perceived visual disability},
  journal = {Eye},
  year = {1990},
  volume = {4},
  pages = {712--717},
  language = {english},
  owner = {jose},
  timestamp = {2008.10.02}
}

@BOOK{ellwein01,
  title = {Quality of life outcome measures},
  publisher = {AFB Press},
  year = {2001},
  editor = {Massof, RW and Lidoff, L},
  author = {Ellwein, LB},
  series = {Issues in Low Vision Rehabilitation: Service Delivery, Policy, and
	Funding},
  address = {New York, USA},
  note = {pp. 143--158},
  language = {english},
  owner = {jose},
  timestamp = {2008.10.02}
}

@TECHREPORT{erhardt-ferron00,
  author = {Erhardt--Ferron, Angelika},
  title = {Theory and Applications of Digital Image Processing},
  institution = {Hochschule f\"ur Technik und Wirtschaft},
  year = {2000},
  type = {Textbook},
  file = {Theory and Applications of Digital Image Processing.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\libros\\Image & Video Processing\\Theory and Applications of Digital Image Processing.pdf:PDF},
  language = {english}
}

@ARTICLE{esteve06,
  author = {Esteve, M. and Palau, C.E. and Catarci, T.},
  title = {A flexible video streaming system for urban traffic control},
  journal = {IEEE Multimedia},
  year = {2006},
  volume = {13},
  pages = {78--83},
  number = {1},
  month = {january--march},
  abstract = {This article discusses an innovative system for traffic management
	that is presently under installation in the city of Valencia. Key
	features of the system are to exploit open source software components
	and use MPEG-4 video streaming over an Internet protocol. The video
	streaming management is particularly sophisticated, resulting in
	a flexible, efficient, and reliable service. Another important element
	is the communication network design. In this case, the main issues
	to address were flexibility, scalability, and fault tolerance. The
	authors successfully addressed these issues by using a hierarchical
	network structure, with physical redundancy, based on spanning tree
	protocols. The overall system is specifically for urban traffic control,
	but some of its characteristics could make it easily reconfigurable
	to different contexts and environments.},
  language = {english},
  owner = {jose},
  timestamp = {2008.10.17},
  url = {http://ieeexplore.ieee.org/search/wrapper.jsp?arnumber=1580436}
}

@MISC{VIIProgramaMarco,
  author = {{European Commission}},
  title = {Work Programme for the ICT - Information and Communication Technologies
	theme of the VII Framework Programme},
  howpublished = {Website},
  month = jun,
  year = {2007},
  language = {english},
  owner = {jose},
  timestamp = {2008.09.19},
  url = {ftp://ftp.cordis.europa.eu/pub/fp7/ict/docs/ict-wp-2007-08_en.pdf}
}

@ARTICLE{fam05,
  author = {F.A.M.},
  title = {Cibersoldado Espa\~nol},
  journal = {Fuerzas Armadas del Mundo},
  year = {2005},
  volume = {05},
  pages = {10},
  number = {5},
  month = may,
  language = {spanish},
  owner = {jose},
  timestamp = {2006.10.31}
}

@ARTICLE{fabrethorpe98,
  author = {M. Fabre--Thorpe and G. Richard and S. Thorpe},
  title = {{Rapid Categorization of Natural Images by Rhesus Monkeys}},
  journal = {Neuroreport},
  year = {1998},
  volume = {9},
  pages = {303--308},
  number = {2},
  month = jan,
  language = {english}
}

@TECHREPORT{fernandez96,
  author = {Fern\'andez Valdivia, Joaqu\'in},
  title = {Morfolog\'ia de Niveles de Gris},
  institution = {Depto. Ciencias de la Computaci\'on e Inteligencia Artificial --
	Universidad de Granada},
  year = {1996},
  key = {fern96},
  language = {spanish}
}

@ARTICLE{fdezgarcia08,
  author = {Fern\'andez-Garc\'{\i}a, {Nicol\'as L.} and Carmona-Poyato, A. and
	Medina-Carnicer, Rafael and Madrid-Cuevas, Francisco J.},
  title = {Automatic generation of consensus ground truth for the comparison
	of edge detection techniques},
  journal = {Image and Vision Computing},
  year = {2008},
  volume = {26},
  pages = {496--511},
  number = {4},
  month = apr,
  abstract = {Two new methods are proposed to automatically generate consensus ground
	truth for real images: Minimean and Minimax methods. These methods
	and a version of the Yitzhaky and Peli method have been used to provide
	ground truth for the comparison of edge detection techniques. The
	developed experiments have revealed that the Minimean consensus method
	is suitable for the comparison of edge detectors because its results
	are equivalent to those obtained with artificial or manual ground
	truth.},
  doi = {10.1016/j.imavis.2007.06.009},
  file = {Automatic generation of consensus ground truth for the comparison of edge detection techniques (N.Fernandez, A.Carmona, R.Medina, and F.Madrid) IVC 26 pp 496-511- 2008.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\Evaluation\\Automatic generation of consensus ground truth for the comparison of edge detection techniques (N.Fernandez, A.Carmona, R.Medina, and F.Madrid) IVC 26 pp 496-511- 2008.pdf:PDF},
  keywords = {Evaluation},
  language = {english},
  owner = {jose},
  timestamp = {2008.07.28}
}

@ARTICLE{foresti03,
  author = {Foresti, G.L. and Micheloni, C.},
  title = {A robust feature tracker for active surveillance of outdoor scenes},
  journal = {Electronics Letters on Computer Vision and Image Analysis {ELCVIA}},
  year = {2003},
  volume = {1},
  pages = {21--34},
  number = {1},
  key = {fore03},
  language = {english}
}

@ARTICLE{fram75,
  author = {Fram, Jerry R. and Deutsch, Edward S.},
  title = {On the quantitative evaluation of edge detection schemes and their
	comparison with human performance},
  journal = {IEEE Transactions on Computers},
  year = {1975},
  volume = {C--24},
  pages = {616--628},
  number = {6},
  month = jun,
  abstract = {A technique for the quantitative evaluation of edge detection schemes
	is presented. It is used to assess the performance of three such
	schemes using a specially-generated set of images containing noise.
	The ability of human subjects to distinguish the edges in the presence
	of noise is also measured and compared with that of the edge detection
	schemes. The edge detection schemes are used on a high--resolution
	satellite photograph with varying degrees of noise added in order
	to relate the quantitative comparison to real--life imagery.},
  file = {on the quantitative evaluation of edge detection schemes and their comparison with human performance.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\Evaluation\\on the quantitative evaluation of edge detection schemes and their comparison with human performance.pdf:PDF},
  keywords = {Evaluation},
  language = {english},
  owner = {jose},
  timestamp = {2008.07.28}
}

@ARTICLE{frei77,
  author = {Frei, W. and Chen, C.C.},
  title = {Fast Boundary Detection: A Generalization and a New Algorithm},
  journal = {IEEE Transactions on Computers},
  year = {1977},
  volume = {C-26},
  pages = {988--998},
  number = {10},
  language = {english},
  owner = {jose},
  timestamp = {2009.08.22}
}

@INPROCEEDINGS{friedman97,
  author = {Friedman, Nir and Russell, Stuart},
  title = {Image segmentation in video sequences: A probabilistic approach},
  booktitle = {Proceedings of the 13th Conference on Unvertainty in Artificial Intelligence
	{{UAI}--1997}},
  year = {1997},
  key = {frie97},
  language = {english}
}

@ARTICLE{frost98,
  author = {Frost, NA and Sparrow, JM and Durant, JS},
  title = {Development of a questionnaire for measurement of vision--related
	quality of life},
  journal = {Ophthalmic Epidemiol},
  year = {1998},
  volume = {5},
  pages = {185--210},
  language = {english},
  owner = {jose},
  timestamp = {2008.10.02}
}

@BOOK{gallego01,
  title = {Fundamentos de Estad\'{\i}stica},
  publisher = {Copister\'ias Don Folio S.L.},
  year = {2001},
  author = {Gallego Segador, Arturo and Espejo Mohedano, Roberto},
  address = {ISBN: 84-930561-8-9},
  booktitle = {Fundamentos de Estad\'{\i}stica},
  key = {gall01},
  language = {spanish}
}

@BOOK{garcia92,
  title = {\'Algebra lineal y geometr\'ia: Cuso Te\'orico--Pr\'actico},
  publisher = {Ed. Marfil S.A.},
  year = {1992},
  author = {Garc\'ia Garc\'ia, Jos\'e and L\'opez Pellicer, Manuel},
  address = {ISBN: 84-268-0269-9},
  booktitle = {\'Algebra lineal y geometr\'ia: Cuso Te\'orico--Pr\'actico},
  key = {garc92},
  language = {spanish}
}

@INPROCEEDINGS{georgescu03,
  author = {Georgescu, Bogdan and Shimshoni, Ilan and Meer, Peter},
  title = {Mean Shift Based Clustering in High Dimensions: A Texture Classification
	Example},
  booktitle = {$9^{th}$ International Conference on Computer Vision {{ICCV}--2003}},
  year = {2003},
  pages = {456--463},
  address = {Nice, France.},
  month = oct,
  key = {geor03},
  language = {english}
}

@INPROCEEDINGS{giusto02,
  author = {Giusto, D.D. and Massida, F. and Perra, C.},
  title = {A fast algorithm for video segmentation and object tracking},
  booktitle = {2002 IEEE International Conference on Digital Signal Processing {{DSP}--2002}},
  year = {2002},
  pages = {697--700},
  key = {gius02},
  language = {english}
}

@PHDTHESIS{gonzalez-tesis,
  author = {{Gonz\'alez Linares}, Jos\'e Mar\'{\i}a},
  title = {Detecci\'on autom\'atica de objetos deformables},
  school = {Universidad de M\'alaga},
  year = {2000},
  key = {gonzTES},
  language = {spanish}
}

@BOOK{gonzalez02,
  title = {Digital Image Processing},
  publisher = {Prentice--Hall, Inc.},
  year = {2002},
  author = {Gonzalez, Rafael C. and Woods, Richard E.},
  series = {ISBN: 0--201--18075--8},
  address = {Upper Saddle River (NJ), USA},
  edition = {2},
  file = {Digital Image Processing (Gonzalez) Prentice-Hall Ed, 2nd Edition 2002.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\libros\\Image & Video Processing\\Digital Image Processing (Gonzalez) Prentice-Hall Ed, 2nd Edition 2002.pdf:PDF},
  key = {gonz87},
  language = {english}
}

@BOOK{gordon97,
  title = {{Theories of Visual Perception}},
  publisher = {Wiley},
  year = {1997},
  author = {I. E. Gordon},
  language = {english}
}

@ARTICLE{gottesfeld92,
  author = {Gottesfeld Brown, Lisa},
  title = {A survey of image registration techniques},
  journal = {ACM Computer Surveys},
  year = {1992},
  volume = {24},
  pages = {325--376},
  number = {4},
  abstract = {Registration is a fundamental task in image processing used to match
	two or more pictures taken, for example, at different times, from
	different sensors, or from different viewpoints. Virtually all large
	systems which evaluate images require the registration of images,
	or a closely related operation, as an intermediate step. Specific
	examples of systems where image registration is a significant component
	include matching a target with a real-time image of a scene for target
	recognition, monitoring global land usage using satellite images,
	matching stereo images to recover shape for autonomous navigation,
	and aligning images from different medical modalities for diagnosis.
	Over the years, a broad range of techniques has been developed for
	various types of data and problems. These techniques have been independently
	studied for several different applications, resulting in a large
	body of research. This paper organizes this material by establishing
	the relationship between the variations in the images and the type
	of registration techniques which can most appropriately be applied.
	Three major types of variations are distinguished. The first type
	are the variations due to the differences in acquisition which cause
	the images to be misaligned. To register images, a spatial transformation
	is found which will remove these variations. The class of transformations
	which must be searched to find the optimal transformation is determined
	by knowledge about the variations of this type. The transformation
	class in turn influences the general technique that should be taken.
	The second type of variations are those which are also due to differences
	in acquisition, but cannot be modeled easily such as lighting and
	atmospheric conditions. This type usually effects intensity values,
	but they may also be spatial, such as perspective distortions. The
	third type of variations are differences in the images that are of
	interest such as object movements, growths, or other scene changes.
	Variations of the second and third type are not directly removed
	by registration, but they make registration more difficult since
	an exact match is no longer possible. In particular, it is critical
	that variations of the third type are not removed. Knowledge about
	the characteristics of each type of variation effect the choice of
	feature space, similarity measure, search space, and search strategy
	which will make up the final technique. All registration techniques
	can be viewed as different combinations of these choices. This framework
	is useful for understanding the merits and relationships between
	the wide variety of existing techniques and for assisting in the
	selection of the most suitable technique for a specific problem.},
  doi = {10.1145/146370.146374},
  file = {A survey of Image Registration Methods (Lisa Gottesfeld Brow.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\A survey of Image Registration Methods (Lisa Gottesfeld Brow.pdf:PDF},
  key = {gott92},
  language = {english}
}

@ARTICLE{grubb69,
  author = {Grubb, Frank},
  title = {Procedures for Detecting Outlying Observations in Samples},
  journal = {Technometrics},
  year = {1969},
  volume = {11},
  pages = {1--21},
  number = {1},
  month = {Feb.},
  language = {english},
  owner = {jose},
  timestamp = {2010.05.28}
}

@INPROCEEDINGS{guo99,
  author = {Guo, Ju and Kim, Jongwon and Jay Kuo, C.--C.},
  title = {Fast and robust moving object segmentation technique for {MPEG--4}
	object--based coding and functionality},
  booktitle = {Proceedings of SPIE},
  year = {1999},
  volume = {3653},
  pages = {1210--1221},
  month = jan,
  key = {guo99},
  language = {english}
}

@ARTICLE{haralick94,
  author = {R. M. Haralick},
  title = {Comments on Performance Characterization Replies},
  journal = {CVGIP: Image Understanding},
  year = {1994},
  volume = {60},
  pages = {264 - 265},
  number = {2},
  doi = {DOI: 10.1006/ciun.1994.1056},
  issn = {1049-9660},
  language = {english},
  owner = {jose},
  timestamp = {2008.12.29},
  url = {http://www.sciencedirect.com/science/article/B6WDD-45P0W80-W/2/abeb49265a5f42a4f42181e7aa1150fb}
}

@ARTICLE{haralick94a,
  author = {R. M. Haralick},
  title = {Performance Characterization in Computer Vision},
  journal = {CVGIP: Image Understanding},
  year = {1994},
  volume = {60},
  pages = {245 - 249},
  number = {2},
  doi = {DOI: 10.1006/ciun.1994.1050},
  issn = {1049-9660},
  language = {english},
  owner = {jose},
  timestamp = {2008.12.29},
  url = {http://www.sciencedirect.com/science/article/B6WDD-45P0W80-N/2/7a2bf890faf7ccf5d15fe614e471bc07}
}

@BOOK{hayes99,
  title = {C\'omo medir la satisfacci\'on del cliente. Dise\~no de encuestas,
	uso y m\'etodos de an\'alisis estad\'istico},
  publisher = {Oxford University Press},
  year = {1999},
  author = {Hayes, Bob E.},
  address = {M\'exico},
  edition = {2},
  keywords = {Questionnaires},
  language = {spanish}
}

@MASTERSTHESIS{heathMTh,
  author = {Heath, Michael D.},
  title = {A robust visual method for assessing the relative performance of
	edge--detection algorithms},
  school = {Graduate School. University of South Florida. Tampa, Florida},
  year = {1996},
  month = sep,
  file = {Master-thesis-Heath.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\thesis\\M Heath\\Master-thesis-Heath.pdf:PDF},
  language = {english},
  owner = {jose},
  timestamp = {2008.07.30},
  url = {ftp://figment.csee.usf.edu/pub/Edge_Comparison/Edge_Comparison_thesis.ps.gz}
}

@ARTICLE{heath98,
  author = {Heath, Michael D. and Sarkar, Sudeep and Sanocki, Thomas and Bowyer,
	Kevin W.},
  title = {Comparison of Edge Detectors: A Methodology and Initial Study},
  journal = {Computer Vision and Image Understanding},
  year = {1998},
  volume = {69},
  pages = {38--54},
  number = {1},
  month = jan,
  doi = {10.1006/cviu.1997.0587},
  file = {Comparison of Edge detectors_ a methodology and initial study [LONG] (M.Heath, S.Sarkar, T.Sanocki, and K.Bowyer) CVIU 69(1) pp 38-54, Jan 1998.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\Evaluation\\Comparison of Edge detectors_ a methodology and initial study [LONG] (M.Heath, S.Sarkar, T.Sanocki, and K.Bowyer) CVIU 69(1) pp 38-54, Jan 1998.pdf:PDF},
  keywords = {Evaluation, Questionnaires},
  language = {english},
  owner = {jose},
  timestamp = {2008.07.28}
}

@ARTICLE{heath97,
  author = {Heath, Michael D. and Sarkar, Sudeep and Sanocki, Thomas and Bowyer,
	Kevin W.},
  title = {A Robust Visual Method for Assessing the Relative Performance of
	Edge--Detection Algorithms},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {1997},
  volume = {19},
  pages = {1338--1359},
  number = {12},
  month = dec,
  abstract = {A new method for evaluating edge detection algorithms is presented
	and applied to measure the relative performance of algorithms by
	Canny, Nalwa--Binford, Iverson--Zucker, Bergholm, and Rothwell. The
	basic measure of performance is a visual rating score which indicates
	the perceived quality of the edges for identifying an object. The
	process of evaluating edge detection algorithms with this performance
	measure requires the collection of a set of gray--scale images, optimizing
	the input parameters for each algorithm, conducting visual evaluation
	experiments and applying statistical analysis methods. The novel
	aspect of this work is the use of a visual task and real images of
	complex scenes in evaluating edge detectors. The method is appealing
	because, by definition, the results agree with visual evaluations
	of the edge images.},
  doi = {10.1109/34.643893},
  file = {A robust visual method for assesing the relative performance of edge-detection algorithms (M.Heath, S.Sarkar,T.Sanocki, and K.Bowyer) IEEE PAMI 19(12)1338-1360, 1997.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\Evaluation\\A robust visual method for assesing the relative performance of edge-detection algorithms (M.Heath, S.Sarkar,T.Sanocki, and K.Bowyer) IEEE PAMI 19(12)1338-1360, 1997.pdf:PDF},
  keywords = {Evaluation, Questionnaires},
  language = {english},
  owner = {jose},
  timestamp = {2008.07.27}
}

@INPROCEEDINGS{heath96,
  author = {Heath, Michael D. and Sarkar, Sudeep and Sanocki, Thomas and Bowyer,
	Kevin W.},
  title = {Comparison of edge detectors: a methodology and initial study},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
  year = {1996},
  pages = {143--148},
  address = {San Francisco, USA},
  month = jun,
  doi = {10.1109/CVPR.1996.517066},
  file = {Comparison of Edge detectors_ a methodology and initial study (M.Heath, S.Sarkar, T.Sanocki, and K.Bowyer) Proceedings CVPR'96 143-148, San Francisco, USA, June 1996.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\Evaluation\\Comparison of Edge detectors_ a methodology and initial study (M.Heath, S.Sarkar, T.Sanocki, and K.Bowyer) Proceedings CVPR'96 143-148, San Francisco, USA, June 1996.pdf:PDF},
  keywords = {Evaluation, Questionnaires},
  language = {english},
  owner = {jose},
  timestamp = {2008.07.29}
}

@ARTICLE{herrero03,
  author = {Herrero Jaraba, El\'ias and Orrite Uru{\~n}uela, Carlos and Senar,
	Jes\'us},
  title = {Detected motion classification with double--background and a neighborhood--based
	difference},
  journal = {Pattern Recognition Letters},
  year = {2003},
  volume = {24},
  pages = {2079--2092},
  key = {herr03},
  language = {english}
}

@INPROCEEDINGS{hoover95,
  author = {Hoover, A. and Jean-Baptiste, G. and Jiang, X. and Flynn, P. J. and
	Bunke, H. and Goldgof, D. and Bowyer, Kevin W.},
  title = {Range image segmentation: The user{'}s dilemma},
  booktitle = {International Symposium on Computer Vision},
  year = {1995},
  pages = {323--328},
  language = {english},
  owner = {jose},
  timestamp = {2008.07.28}
}

@BOOK{horn86,
  title = {{Robot Vision}},
  publisher = MIT,
  year = {1986},
  author = {{B. K. P}. Horn},
  language = {english}
}

@INPROCEEDINGS{horprasert99,
  author = {Horprasert, Thanarat and Harwood, David and Davis, Larry S.},
  title = {A statistical approach for real--time robust background subtraction
	and shadow detection},
  booktitle = {1999 IEEE International Conference on Computer Vision: Frame Rate
	Workshop {{ICCV}'99}},
  year = {1999},
  key = {horp99},
  language = {english}
}

@ARTICLE{hsu84,
  author = {Hsu, Y.Z. and Nagel, H.-H. and Reckers, G.},
  title = {New likelihood test methods for change detection in image sequences},
  journal = {Computer Vision, Graphics and Image Processing},
  year = {1984},
  volume = {26},
  pages = {73--106},
  key = {hsu84},
  language = {english}
}

@BOOK{hurvich66,
  title = {{The Perception of Brightness and Darkness}},
  publisher = Allyn,
  year = {1966},
  author = {L. W. Hurvich and D. Jameson},
  language = {english}
}

@INPROCEEDINGS{huwer00,
  author = {Huwer, Stefan and \mbox{N}iemann, Heinrich},
  title = {Adaptive change detection for real--time surveillance applications},
  booktitle = {3rd IEEE International Workshop on Visual Surveillance {{VS}--2000}},
  year = {2000},
  pages = {37--45},
  address = {Dublin, Ireland},
  month = jul,
  key = {huwe00},
  language = {english}
}

@ARTICLE{irani93,
  author = {Irani, Michal and Peleg, Shmuel},
  title = {Motion Analysis for Image Enhancement: Resolution, Occlusion and
	Transparency},
  journal = {Journal of Visual Communication and Image Representation},
  year = {1993},
  volume = {4},
  pages = {324--335},
  number = {4},
  month = dec,
  citeseerurl = {http://citeseer.ist.psu.edu/article/irani93motion.html},
  file = {Motion Analysis for Image Enhancement_Resolution, Occlusion and Transparency (Irani and Peleg) Journal VCIR,pp 324-335, 1993.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\change detection\\Motion Analysis for Image Enhancement_Resolution, Occlusion and Transparency (Irani and Peleg) Journal VCIR,pp 324-335, 1993.pdf:PDF},
  key = {iran93},
  keywords = {Optical Flow, Motion detection},
  language = {english},
  url = {http://www.wisdom.weizmann.ac.il/~irani/PAPERS/sequence\_enhnc.pdf}
}

@MISC{itu-r_bt500-6,
  author = {{ITU--R}},
  title = {Methodology for the Subjective Assessment of the Quality of Television
	Pictures},
  howpublished = {Recommendation BT.500--6},
  year = {1994},
  keywords = {Questionnaires},
  language = {english},
  owner = {jose},
  timestamp = {2006.11.01}
}

@MISC{itu-t_p800,
  author = {{ITU--T}},
  title = {{Methods for subjective determination of transmissions quality}},
  howpublished = {Recommendation P.800},
  year = {1996},
  keywords = {Questionnaires},
  language = {english}
}

@MISC{itu-t_p910,
  author = {{ITU--T}},
  title = {{Methods for subjective determination of video quality for multimedia
	applications}},
  howpublished = {Recommendation P.910},
  month = aug,
  year = {1996},
  keywords = {Questionnaires},
  language = {english},
  owner = {jose},
  timestamp = {2006.10.30}
}

@MISC{itu-t_p930,
  author = {{ITU--T}},
  title = {{Principles of a reference impairment system for video}},
  howpublished = {Recommendation P.930},
  month = aug,
  year = {1996},
  keywords = {Questionnaires},
  language = {english},
  owner = {jose},
  timestamp = {2006.10.30}
}

@BOOK{jahne02,
  title = {Digital Image Processing},
  publisher = {Springer--Verlag, Berlin Heidelberg},
  year = {2002},
  author = {J\"ahne, Bernd},
  series = {ISBN: 3-540-67754-2},
  edition = {5},
  file = {Digital Image Processing (Bernd Jahne) Springer-Verlag.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\libros\\Image & Video Processing\\Digital Image Processing (Bernd Jahne) Springer-Verlag.pdf:PDF},
  language = {english}
}

@BOOK{jain89,
  title = {{Fundamentals of Digital Image Processing}},
  publisher = PH,
  year = {1989},
  author = {A. K. Jain},
  language = {english}
}

@CONFERENCE{jin08,
  author = {Jin, S.M. and Lee, I.B. and Han, J.M.},
  title = {Context-based pixelization model for the artificial retina using
	saliency map and skin color detection algorithm},
  booktitle = {Human Vision and Electronic Imaging XIII - Proc. SPIE},
  year = {2008},
  volume = {6806},
  address = {San Jose, CA, USA},
  month = jan,
  publisher = {SPIE Press},
  abstract = {A key problem of artificial visual prosthesis is the low resolution
	due to the limited number of electrodes. Various methods such as
	edge detection, contrast enhancement have been studied as the solutions
	of the low resolution problem and these methods have been performed
	to face or object recognition in the close-up image. In this paper,
	we proposed the region-of-interest detection method using a context-based
	model, which is appropriate for real situations. The visually-salient
	region was detected by combining the saliency map with color information.
	In experiment, to evaluate the proposed model, gaze was estimated
	using an eye tracker when subjects watch the original image and two
	types of 10 × 10 pixelized images produced by conventional and saliency
	based method, respectively. Each gaze of pixelized images was compared
	with the gaze of the original image. The experiment showed that the
	gaze using the proposed context based model much more correlates
	with the gaze of the original image than that of conventional model.},
  doi = {10.1117/12.766312},
  language = {english},
  owner = {jose},
  timestamp = {2008.10.17}
}

@INPROCEEDINGS{johnson58,
  author = {John Johnson},
  title = {Analysis of image forming systems},
  booktitle = {Image Intensifier Symposium},
  year = {1958},
  pages = {244-273},
  address = {U.S. Army Research and Development Laboratories, Ft. Belvoir, Va.},
  month = jan,
  organization = {Warfare Electrical Engineering Department},
  language = {english},
  owner = {jose},
  timestamp = {2008.12.30}
}

@ARTICLE{jourlin88,
  author = {Michel Jourlin and Jean--Charles Pinoli},
  title = {A Model for Logarithmic Image--Processing},
  journal = {Journal of Microscopy},
  year = {1988},
  volume = {149},
  pages = {21--35},
  number = {1},
  month = jan,
  keywords = {LIP},
  language = {english}
}

@ARTICLE{jourlin87,
  author = {Michel Jourlin and Jean--Charles Pinoli},
  title = {Logarithmic Image Processing},
  journal = {Acta Stereologica},
  year = {1987},
  volume = {6},
  pages = {651--656},
  keywords = {LIP},
  language = {english}
}

@INPROCEEDINGS{khan01,
  author = {Khan, Sohaib and Shah, Mubarak},
  title = {Object based segmentation of video using color, motion and spatial
	information},
  booktitle = {Proceedings of the 2001 IEEE International Conference on Imaging
	{{II}--2001}},
  year = {2001},
  pages = {746--751},
  key = {khan01},
  language = {english}
}

@ARTICLE{kim02,
  author = {Kim, Changick and Hwang, Jenq--Neng},
  title = {Fast and automatic video object segmentation and tracking for content--based
	applications},
  journal = {IEEE Transactions on Circuits and Systems for Video Technology},
  year = {2002},
  volume = {12},
  pages = {122--129},
  number = {2},
  month = feb,
  key = {kim02},
  language = {english}
}

@ARTICLE{kitchen81,
  author = {Les Kitchen and Azriel Rosenfeld},
  title = {Edge evaluation using local edge coherence},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  year = {1981},
  volume = {SMC-11},
  pages = {597--605},
  number = {9},
  month = sep,
  language = {english},
  owner = {jose},
  timestamp = {2008.12.28}
}

@ARTICLE{kosnik88,
  author = {Kosnik, W and Winslow, L and Kline, D},
  title = {Visual changes in daily life throughout adulthood},
  journal = {Journal of Gerontology},
  year = {1988},
  volume = {43},
  pages = {63--70},
  language = {english},
  owner = {jose},
  timestamp = {2008.10.02}
}

@INPROCEEDINGS{kuhne01,
  author = {K{\"u}hne, Gerald and Richter, Stephan and Beier, Markus},
  title = {Motion--based segmentation and contour--based classification of video
	objects},
  booktitle = {Proceedings of the ACM Multimedia 2001},
  year = {2001},
  pages = {41--50},
  address = {Ottawa, Canada},
  month = sep,
  key = {k{\"u}hn01},
  language = {english}
}

@MISC{estadisticaURL,
  author = {Lagares Barreiro, Paula and Puerto Albandoz, Justo},
  title = {Poblaci\'on y Muestra. {T\'ecnicas de muestreos}},
  year = {2001},
  keywords = {Questionnaires},
  language = {spanish},
  owner = {jose},
  timestamp = {2007.06.18},
  url = {http://optimierung.mathematik.uni-kl.de/mamaeusch/index.php?content=ver\_texte}
}

@MISC{lanierURL,
  author = {Lanier, Jaron},
  title = {Brief Biography of {Jaron Lanier}},
  howpublished = {Webpage.},
  language = {english},
  owner = {jose},
  timestamp = {2007.10.03},
  url = {http://www.jaronlanier.com/general.html}
}

@MISC{layarWeb,
  author = {{Layar Inc.}},
  title = {Augmented reality -- Layar Reality Browser},
  month = sep,
  year = {2010},
  language = {english},
  owner = {jose},
  timestamp = {2010.09.21},
  url = {http://www.layar.com}
}

@INPROCEEDINGS{leclerc00b,
  author = {Leclerc, Yvan and Luong, Q.-Tuan and Fua, Pascal},
  title = {Measuring the Self--Consistency of Stereo Algorithms},
  booktitle = {Proceedings of the 2000 European Conference on Computer Vision {{ECCV}--2000}},
  year = {2000},
  address = {Dublin, Ireland Rep.},
  key = {lecl00b},
  language = {english}
}

@INPROCEEDINGS{leclerc99a,
  author = {Leclerc, Yvan and Luong, Q.-Tuan and Fua, Pascal},
  title = {Self--Consistency: a Novel Approach to Characterizing the Accuracy
	and Reliability of Point Correspondence Algorithms},
  booktitle = {Proceedings of the One--day Workshop on Performance Characterisation
	and Benchmarking of Vision Systems},
  year = {1999},
  address = {Las Palmas de Gran Canaria, Canary Islands, Spain},
  key = {lecl99a},
  language = {english}
}

@INPROCEEDINGS{leclerc99b,
  author = {Leclerc, Yvan and Luong, Q.-Tuan and Fua, Pascal},
  title = {Characterizing the Performance of Multiple--image Point--correspondence
	Algorithms using Self--Consistency},
  booktitle = {Proceedings of the 1999 International Conference on Computer Vision
	{{ICCV}--1999}},
  year = {1999},
  address = {Corfu, Greece},
  month = sep,
  key = {lecl99b},
  language = {english}
}

@INPROCEEDINGS{leclerc00a,
  author = {Leclerc, Yvan and Luong, Q.-Tuan and Fua, Pascal and Miyajima, Koji},
  title = {Detecting changes in {3D} shape using Self-Consistency},
  booktitle = {Proceedings of the Computer Vision and Pattern Recognition 2000 {{CVPR}--2000}},
  year = {2000},
  key = {lecl00a},
  language = {english}
}

@ARTICLE{leclerc03,
  author = {Leclerc, Yvan G. and Luong, Q-Tuan and Fua, Pascal V.},
  title = {Self--consistency and MDL: a Paradigm for Evaluating Point Correspondence
	Algorithms and Detecting Change},
  journal = {International Journal of Computer Vision},
  year = {2003},
  volume = {51},
  pages = {63--83},
  number = {1},
  key = {lecl03},
  language = {english}
}

@ARTICLE{lievin04,
  author = {M. Lievin and F. Luthon},
  title = {{Nonlinear Color Space and Spatiotemporal MRF for Hierarchical Segmentation
	of Face Features in Video}},
  journal = {IEEE Transactions on Image Processing},
  year = {2004},
  volume = {13},
  pages = {63--71},
  number = {1},
  month = jan,
  language = {english}
}

@ARTICLE{lillestrand72,
  author = {Lillestrand, R.},
  title = {Techniques for change detection},
  journal = {IEEE Transactions on Computers},
  year = {1972},
  volume = {21},
  pages = {654--659},
  number = {7},
  key = {lill72},
  language = {english}
}

@ARTICLE{liu98,
  author = {Liu, Sze--Chu and Fu, Chang--Wu and Chang, Shyang},
  title = {Statistical change detection with moments under time--varying illumination},
  journal = {IEEE Transactions on Image Processing},
  year = {1998},
  volume = {7},
  pages = {1258--1268},
  number = {9},
  month = sep,
  key = {liu98},
  language = {english}
}

@INPROCEEDINGS{luo07,
  author = {Luo, Gang and Lichtenstein, Lee and Peli, Eli},
  title = {Collision judgement when viewing minified images through a HMD visual
	field expander},
  booktitle = {Proceedings of the SPIE},
  year = {2007},
  volume = {6426},
  number = {XVII},
  series = {Ofthalmic Technologies},
  pages = {64261Z},
  file = {:home/jose/Documentos/articulos/Low-Vision/CE-HMD BiOS07 submission.pdf:PDF},
  keywords = {Low Vision},
  language = {english},
  owner = {jose},
  timestamp = {2009.10.22}
}

@ARTICLE{luo04,
  author = {Luo, Gang and Peli, Eli},
  title = {Kinematics of Visual Search by Tunnel Vision Patients with Augmented
	Vision See-Through {HMD}},
  journal = {SID Digest},
  year = {2004},
  volume = {?},
  pages = {1578--1581},
  language = {english},
  owner = {jose},
  timestamp = {2007.08.11}
}

@BOOK{mack98,
  title = {Unattentional Blindness},
  publisher = {{MIT Press}/{Bradford Books} series in {Cognitive Psychology}},
  year = {1998},
  author = {Mack, A. and Rock, I.},
  language = {english},
  owner = {jose},
  timestamp = {2007.08.14}
}

@ARTICLE{mangione92,
  author = {Mangione, CM and Phillips, RS and Seddon, JM},
  title = {Development of the Activities of Daily Vision Scale. A measure of
	visual functional status},
  journal = {Medical Care},
  year = {1992},
  volume = {30},
  pages = {1111--1126},
  language = {english},
  owner = {jose},
  timestamp = {2008.10.02}
}

@ARTICLE{marr80,
  author = {David Marr and E Hildreth},
  title = {{Theory of Edge--Detection}},
  journal = {Proceedings of the Royal Society of London Series B -- Biological
	Sciences},
  year = {1980},
  volume = {207},
  pages = {187--217},
  number = {1167},
  language = {english}
}

@ARTICLE{massof01,
  author = {Robert W. Massof and Gary S. Rubin},
  title = {Visual Function Assessement Questionnaires},
  journal = {Survey of Ophthalmology},
  year = {2001},
  volume = {45},
  pages = {531--548},
  number = {6},
  month = jun,
  abstract = {With increased emphasis on functional outcomes in ophthalmology, third--party
	health care payers and research funding agencies have turned their
	attention to the development and use of visual
	
	function questionnaires. Since 1980, more than a dozen such self-report
	visual function questionnaires have been developed. All of these
	instruments include items that ask about specific daily activities;
	
	patients must respond with a rating that represents the level of difficulty
	that they experience with the activity described. This article reviews
	all of the known instruments, with special attention paid to their
	
	validity and reliability. Most validation studies have reported high
	response consistency across items and significant correlations of
	instrument scores with visual impairment measures. Only two studies
	
	have measured test--retest reliability. The developers of visual function
	questionnaires typically divide the items into several different
	subscales, suggesting that different variables are being measured.
	
	Although the items are very similar for the different instruments,
	there is little agreement among instruments on the definition of
	subscales. All instruments are scored as the average of the ordinal
	
	patient ratings across items for each subscale and/or for the total
	instrument. Measurement issues underlying the scoring of ordinal
	patient ratings are discussed. It is argued that unless the instruments
	
	can be converted to interval scales, the averaging of patient ratings
	does not yield true measurements. The three visual function questionnaires
	that were calibrated with a statistical item response model, which
	
	estimates interval scales, are reviewed. It is concluded that future
	research and development should devote additional attention to the
	measurement properties of functional assessment instruments.},
  file = {visual function assessment questionnaires.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\Low-Vision\\visual function assessment questionnaires.pdf:PDF},
  keywords = {Questionnaires, Low Vision},
  language = {english},
  owner = {jose},
  timestamp = {2008.07.20}
}

@BOOK{1993--2002,
  title = {{Image Processing Toolbox} User's Guide for {Matlab}},
  publisher = {The Mathworks, Inc.},
  year = {1993--2002},
  author = {{Mathworks Inc.}},
  edition = {July 2002, revised for Version 3.2 (Release 13)},
  key = {matl02},
  language = {english}
}

@BOOK{matlin96,
  title = {Sensaci\'on y Percepci\'on},
  publisher = {Prentice--Hall, Inc.},
  year = {1996},
  author = {Matlin, Margaret W. and Foley, Hugh J.},
  address = {Mexico D.F.},
  edition = {3},
  note = {ISBN: 968--880--677--3},
  language = {spanish},
  owner = {jose},
  timestamp = {2006.10.31}
}

@ARTICLE{mcgraw96,
  author = {McGraw, Kenneth O. and Wong, S.P.},
  title = {Forming inferences about some intraclass correlation coefficients},
  journal = {Psychological Methods},
  year = {1996},
  volume = {1},
  pages = {30--46},
  number = {1},
  language = {english},
  owner = {jose},
  timestamp = {2010.05.09}
}

@INPROCEEDINGS{mcivor00,
  author = {McIvor, Alan M.},
  title = {Background Subtraction Techniques},
  booktitle = {Conference on Image and Vision Computing New Zealand {IVCNZ00}},
  year = {2000},
  key = {mciv00},
  language = {english}
}

@INPROCEEDINGS{mckoen00,
  author = {McKoen, Kevin and { N}avarro--Prieto, Raquel and Duc, Benoit and
	Durucan, Emrullah and Ziliani, Francesco and Ebrahimi, Touradj},
  title = {Evaluation of Video Segmentation Methods for Surveillance Applications},
  booktitle = {Eusipco, X European Signal Processing Conference},
  year = {2000},
  volume = {2},
  pages = {1--4},
  month = {September 4--8},
  keywords = {Change Detection, Questionnaires, Evaluation},
  language = {english},
  owner = {jose},
  timestamp = {2006.11.02}
}

@ARTICLE{mech98,
  author = {Mech, Roland and Wollborn, Michael},
  title = {A noise robust method for 2D shape estimation of moving objects in
	video sequences considering a moving camera},
  journal = {Signal Processing},
  year = {1998},
  volume = {66},
  pages = {203--217},
  number = {2},
  key = {mech98},
  language = {english}
}

@ARTICLE{meer94,
  author = {P. Meer},
  title = {Computer Vision: The Goal and the Means},
  journal = {CVGIP: Image Understanding},
  year = {1994},
  volume = {60},
  pages = {257 - 259},
  number = {2},
  doi = {DOI: 10.1006/ciun.1994.1053},
  issn = {1049-9660},
  language = {english},
  owner = {jose},
  timestamp = {2008.12.29},
  url = {http://www.sciencedirect.com/science/article/B6WDD-45P0W80-S/2/36fa7a62e13df1bc370de811235758a6}
}

@INPROCEEDINGS{mezaris03,
  author = {Mezaris, V. and Kompatsiaris, I. and Strintzis, M. G.},
  title = {Still Image Objective Segmentation Evaluation using Ground Truth},
  booktitle = {5th COST 276 Workshop},
  year = {2003},
  editor = {Kovar, B. and Prikryl, J. and Vlcek, M.},
  pages = {9--14},
  abstract = {In this paper, an objective segmentation evaluation metric suitable
	for the evaluation of still image segmentation results is proposed.
	The proposed metric is based on the spatial accuracy approach, originally
	
	proposed for the evaluation of foreground/backgroung segmentation
	masks generated from video sequences. This approach is extended to
	still image segmentation evaluation, where both the estimated
	
	segmentation masks and the ground truth mask typically contain multiple
	regions. The proposed method takes into account, using a single metric,
	not only the accuracy of the boundary localization of the created
	segments but also the under-segmentation and over--segmentation effects,
	which can hinder the performance of any segmentation algorithm and
	decrease the usability of the segmentation results in
	
	content-based applications. Several experiments have shown the potential
	of this approach.},
  file = {Still Image Objective Segmentation Evaluation using Ground Truth (Mezaris, Kompatsiaris, and Strintzis) 5-COST276 Workshop, pp 9-14, 2003.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\Evaluation\\Still Image Objective Segmentation Evaluation using Ground Truth (Mezaris, Kompatsiaris, and Strintzis) 5-COST276 Workshop, pp 9-14, 2003.pdf:PDF},
  language = {english},
  owner = {jose},
  timestamp = {2008.07.28}
}

@MISC{webMEC_bancoImg,
  author = {{Ministerio de Educaci\'on y Ciencia de Espa\~na}},
  title = {Banco de Im\'agenes},
  howpublished = {Website},
  month = apr,
  year = {2005},
  language = {spanish},
  url = {http://bancoimagenes.cnice.mec.es/}
}

@ARTICLE{morellas03,
  author = {Morellas, V. and Pavlidis, I. and Tsiamyrtzis, P.},
  title = {DETER: Detection of events for threat evaluation and recognition},
  journal = {Machine Vision and Applications},
  year = {2003},
  volume = {15},
  pages = {29--45},
  number = {1},
  month = oct,
  abstract = {The current security infrastructure can be summarized as follows:
	(1) Security systems act locally and do not cooperate in an effective
	manner, (2) Very valuable assets are protected inadequately by antiquated
	technology systems and (3) Security systems rely on intensive human
	concentration to detect and assess threats.
	
	In this paper we present DETER (Detection of Events for Threat Evaluation
	and Recognition), a research and development (R&D) project aimed
	to develop a high-end automated security system. DETER can be seen
	as an attempt to bridge the gap between current systems reporting
	isolated events and an automated cooperating network capable of inferring
	and reporting threats, a function currently being performed by humans.
	
	The prototype DETER system is installed at the parking lot of Honeywell
	Laboratories (HL) in Minneapolis. The computer vision module of DETER
	reliably tracks pedestrians and vehicles and reports their annotated
	trajectories to the threat assessment module for evaluation. DETER
	features a systematic optical and system design that sets it apart
	from ldquotoyrdquo surveillance systems. It employs a powerful Normal
	mixture model at the pixel level supported by an expectation-maximization
	(EM) initialization, the Jeffreys divergence measure, and the method
	of moments. It also features a practical and accurate multicamera
	calibration method. The threat assessment module utilizes the computer
	vision information and can provide alerts for behaviors as complicated
	as the ldquohoppingrdquo of potential vehicle thieves from vehicle
	spot to vehicle spot.
	
	Extensive experimental results measured during actual field operations
	support DETERrsquos exceptional characteristics. DETER has recently
	been successfully productized. The product-grade version of DETER
	monitors movements across the length of a new oil pipeline.},
  doi = {10.1007/s00138-003-0121-6},
  language = {english},
  owner = {jose},
  timestamp = {2008.10.17}
}

@ARTICLE{murat02,
  author = {Murat Bagci, A. and Yardimci, Yasemin and Enis {\c{C}}etin, A.},
  title = {Moving object detection using adaptive subband decomposition and
	fractional low--order statistics in video sequences},
  journal = {Signal Processing},
  year = {2002},
  volume = {82},
  pages = {1941--1947},
  key = {mura02},
  language = {english}
}

@ARTICLE{neisser75,
  author = {Neisser, U. and Becklen, R.},
  title = {Selective looking: Attending to visually specified events},
  journal = {Cognitive Psychology},
  year = {1975},
  volume = {7},
  pages = {480-494},
  language = {english},
  owner = {jose},
  timestamp = {2007.08.14}
}

@ARTICLE{neri98,
  author = {Neri, A. and Colonnese, S. and Russo, G. and Talone, P.},
  title = {Automatic moving object and background separation},
  journal = {Signal Processing},
  year = {1998},
  volume = {66},
  pages = {219--232},
  number = {2},
  key = {neri98},
  language = {english}
}

@MISC{lowVisionOMS,
  author = {OMS},
  title = {Magnitude and causes of visual impairment},
  howpublished = {Website},
  month = nov,
  year = {2004},
  note = {Fact Sheet $\mathrm{N}^\mathrm{o}$ 282},
  language = {english},
  owner = {jose},
  timestamp = {2007.08.08},
  url = {http://www.who.int/mediacentre/factsheets/fs282/en/index.html}
}

@BOOK{oppenheim00,
  title = {Questionnaire Design, Interviewing and Attitude Measurement},
  publisher = {Continuum},
  year = {2000},
  author = {Oppenheim, A. N.},
  address = {London and New York},
  edition = {New},
  keywords = {Questionnaires},
  language = {english},
  owner = {jose},
  timestamp = {2006.08.04}
}

@ARTICLE{oppenheim69,
  author = {Oppenheim, Alan V.},
  title = {Speech analysis--synthesis system based on homomorphic filtering},
  journal = {Journal of Acoustic Society of America},
  year = {1969},
  volume = {45},
  pages = {458--465},
  number = {2},
  month = feb,
  abstract = {A digital speech analysis--synthesis system based on a recently proposed
	approach to the deconvolution of speech is presented. The analyzer
	is based on a computation of the cepstrum considered as the inverse
	Fourier transform of the log magnitude of the Fourier transform.
	The transmitted parameters represent pitch and voice--unvoiced information
	and the low--time portion of the cepstrum representing an approximation
	to the cepstrum of the vocal--tract impulse response. In the synthesis,
	the low--time cepstral information is transformed to an impulse response
	function, which is then convolved with a train of impulses during
	voiced portions or a noise waveform during unvoiced portions to reconstruct
	the speech. Since no phase information is retained in the analysis,
	phase must be regenerated during synthesis. Either a zero--phase
	or minimum--phase characteristic can be obtained by simple weighting
	of the cepstrum before transformation.},
  file = {speechanaly_1969.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\Homomorphic filtering\\speechanaly_1969.pdf:PDF},
  key = {oppe69},
  keywords = {Homomorphic Filtering},
  language = {english},
  url = {http://www.rle.mit.edu/dspg/documents/speechanaly\_1969.pdf}
}

@ARTICLE{oppenheim68,
  author = {Oppenheim, Alan V. and Schafer, Ronald W. and {Stockham JR.}, Thomas
	G.},
  title = {Nonlinear Filtering of Multiplied and Convolved Signals},
  journal = {IEEE Transactions on Audio and Electroacoustics},
  year = {1968},
  volume = {AU--16},
  pages = {437--466},
  number = {3},
  month = sep,
  abstract = {An approach to some nonlinear filtering problems through a generalized
	notion of superposition has proven useful. In this paper this approach
	is investigated for the nonlinear filtering of signals which can
	be expressed as products or as convolutions of components. The applications
	of this approach in audio dynamic range compression and expansion,
	image enhancement with applications to bandwidth reduction, echo
	removal, and speech waveform processing are presented.},
  file = {nonnlinearfiltering_1968.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\Homomorphic filtering\\nonnlinearfiltering_1968.pdf:PDF},
  keywords = {Homomorphic Filtering},
  language = {english},
  url = {http://www.rle.mit.edu/dspg/documents/nonnlinearfiltering\_1968.pdf}
}

@INPROCEEDINGS{palomar10,
  author = {Palomar, Rafael and Palomares, Jos\'e M. and Castillo, Jos\'e M. and Olivares, Joaqu\'in and G\'omez--Luna, Juan},
  title = {Parallelizing and Optimizing {LIP--Canny} Using {NVIDIA CUDA}},
  booktitle = {Proceedings of the IEA/AIE 2010},
  year = {2010},
  editor = {Garc\'ia--Pedrajas, N.},
  volume = {6098 -- {Part III}},
  series = {Lecture Notes on Artificial Intelligence, LNAI},
  pages = {389--398},
  address = {Córdoba (España)},
  month = {Junio},
  language = {english},
  owner = {jose},
  timestamp = {2010.08.23}
}

@PHDTHESIS{palomaresPhD,
  author = {Palomares, Jose M.},
  title = {Extracción eficiente de la estructura de escenas naturales},
  school = {Universidad de Granada},
  year = {2010},
  language = {english},
  owner = {jose},
  timestamp = {2009.10.24}
}

@INPROCEEDINGS{palomares05a,
  author = {Palomares, Jos\'e M. and Gonz\'alez, Jes\'us and Ros, Eduardo},
  title = {Designing a fast convolution under the {LIP} paradigm applied to
	edge detection},
  booktitle = {Proceedings of the III International Conference on Advances in Pattern
	Recognition {ICAPR 2005}},
  year = {2005},
  editor = {Sameer {Singh et al.}},
  volume = {3},
  series = {Lecture Notes in Computer Science -- {LNCS 3687}},
  pages = {560--569},
  address = {Bath, UK.},
  month = {22--25, August},
  abstract = {The Logarithmic Image Processing model (LIP) is a robust mathematical
	framework for the processing of transmitted and reflected images.
	It follows many visual, physical and psychophysical laws. This works
	presents a new formulation of a 2D--convolution of separable kernels
	using the LIP paradigm. A previously stated LIP--Sobel edge detector
	is redefined with the new proposed formulation, and the performance
	of the edge detectors programmed following the two formulations (the
	previous one and the new one proposed) is compared. Another operator,
	Laplacian of Gaussian, is also stated under the LIP paradigm. The
	experiments show that both methods obtain same results although our
	proposed method is much faster than the previous one.},
  doi = {10.1007/11552499_62},
  file = {36870560.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\Mis artículos\\2005\\congresos\\icapr05\\36870560.pdf:PDF},
  keywords = {LIP},
  language = {english}
}

@INPROCEEDINGS{palomares05b,
  author = {Palomares, Jos\'e M. and Gonz\'alez, Jes\'us and Ros, Eduardo},
  title = {Detecci\'on de Bordes en Im\'agenes con Sombras mediante {LIP}--Canny},
  booktitle = {Actas del I Simposio de Reconocimiento de Formas y Análisis de Imágenes:
	AERFAI 2005},
  year = {2005},
  pages = {71--76},
  address = {Granada (Spain)},
  note = {ISBN:84--9732--445--5},
  abstract = {En el presente trabajo, se presenta una nueva t\'ecnica que unifica
	el conocido m\'etodo de Canny para la obtenci\'on de bordes con un
	paradigma de procesamiento de im\'agenes conocido como LIP, que tiene
	un comportamiento logar\'{\i}tmico parecido al del ojo humano. Se
	ha observado que el m\'etodo de Canny no detecta bien los bordes
	en zonas de baja iluminaci\'on y que el paradigma LIP permite trabajar
	en zonas de iluminaci\'on pobre. Esta nueva t\'ecnica (LIP--Canny)
	se compara con Canny, mostrando que LIP--Canny es capaz de detectar
	bordes en zonas de baja iluminaci\'on. Tambi\'en se compara con otra
	t\'ecnica, en la que se realiza un filtrado homom\'orfico previo
	al m\'etodo de Canny, obteni\'endose unos resultados visuales similares,
	pero LIP--Canny obtiene dichos resultados m\'as r\'apidamente y con
	un ajuste de umbral menos sensible y, por tanto, mucho m\'as sencillo.},
  language = {spanish}
}

@ARTICLE{palomares06,
  author = {Palomares, Jos\'e M. and Gonz\'alez, Jes\'us and Ros, Eduardo and
	Prieto, Alberto},
  title = {General Logarithmic Image Processing Convolution},
  journal = {IEEE Transactions on Image Processing},
  year = {2006},
  volume = {15},
  pages = {3602--3608},
  number = {11},
  month = nov,
  note = {ISSN: 1057--7149},
  abstract = {The Logarithmic Image Processing model (LIP) is a robust mathematical
	framework, which, among other benefits, behaves invariantly to illumination
	changes. This paper presents, for the first time, two general formulations
	of the 2D-convolution of separable kernels under LIP paradigm. Although
	both formulations are mathematically equivalent, one of them has
	been designed avoiding the operations which are computationally expensive
	in current computers. Therefore, this fast LIP convolution method
	allows to obtain significant speedups and it is more adequate for
	real-time processing. To support these statements, some experimental
	results are shown in section V.},
  doi = {10.1109/tip.2006.881967},
  keywords = {LIP},
  language = {english}
}

@INPROCEEDINGS{patrascu03,
  author = {Patrascu, Vasile},
  title = {Color Image Enhancement Using the Support Fuzzification},
  booktitle = {Proceedings of the 10th International Fuzzy Systems Association World
	Congress {IFSA--2003}},
  year = {2003},
  editor = {T. {Bilgi\c{c} et al.}},
  series = {Lecture Notes in Computer Sciences -- {LNCS 2715}},
  pages = {412--419},
  address = {Istanbul, Turkey.},
  month = {30 June -- 2 July},
  publisher = {Springer--Verlag, Berlin Heidelberg},
  abstract = {Simple and efficient methods for image enhancement can be obtained
	through affine transforms, defined by the logarithmic operations.
	Generally, a single affine transform is calculated for the whole
	image. A better quality is possible to obtain if a fuzzy partition
	is defined on the image support and then, for each element of the
	partition an affine transform is determined. Finally the enhanced
	image is computed by summing up in a weight way the images obtained
	for the fuzzy partition elements.},
  file = {Color image using the support fuzzification (V Patrascu).pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\LIP\\Color image using the support fuzzification (V Patrascu).pdf:PDF},
  keywords = {LIP},
  language = {english},
  optpublisher = {#Springer#},
  url = {http://springerlink.metapress.com/link.asp?id=vpkenhk3d5uf95g0}
}

@INPROCEEDINGS{peli00,
  author = {Peli, Eli},
  title = {Augmented vision for central scotoma and peripheral field loss},
  booktitle = {Vision Rehabilitation: Assessment, intervention and outcomes},
  year = {2000},
  editor = {C. Stuen \emph{et al.}},
  series = {Selected Paper from Vision99: International Conference on Low Vision},
  pages = {70--74},
  address = {Lisse},
  publisher = {Swets and Zeitlinger},
  file = {:home/jose/Documentos/articulos/Low-Vision/Augmented Vision for central scotoma and peripheral field loss (E. Peli) in Proc. of vision99 Int. Conf. on Low Vision. Ed. C.Stuen et al., Lisse 2000, p. 70-74.pdf:PDF},
  keywords = {Low Vision},
  language = {english},
  owner = {jose},
  timestamp = {2009.10.22}
}

@ARTICLE{peli01,
  author = {Peli, Eli},
  title = {Vision Multiplexing: an Engineering approach to vision rehabilitation
	device development},
  journal = {Optometry and Vision Science},
  year = {2001},
  volume = {78},
  pages = {304--315},
  number = {5},
  month = may,
  file = {:F\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\Low-Vision\\Vision Multiplexing an engineering approach to vision rehabilitation device development (E. Peli) Opt. Vis. Sci. 78(5) pp 304-315, 2001.pdf:PDF},
  keywords = {Low Vision},
  language = {english},
  owner = {Jose Manuel},
  timestamp = {2009.03.12}
}

@ARTICLE{peli07,
  author = {Peli, Eli and Luo, Gang and Bowers, Alex and Rensing, Noa},
  title = {Applications of augmented--vision head--mounted systems in vision
	rehabilitation},
  journal = {Journal of the Society for Information Display},
  year = {2007},
  volume = {15},
  pages = {1037--1045},
  number = {12},
  file = {:home/jose/Documentos/articulos/Low-Vision/JSID 07 Augmented HMD.pdf:PDF},
  keywords = {Low Vision},
  language = {english},
  owner = {jose},
  timestamp = {2009.10.22}
}

@ARTICLE{peli08,
  author = {Peli, Eli and Vargas--Martin, Fernando},
  title = {In--the--spectacle--lens telescopic device},
  journal = {Journal of Biomedical Optics},
  year = {2008},
  volume = {13},
  pages = {1--11},
  number = {3},
  month = {may/june},
  keywords = {Low Vision},
  language = {english},
  owner = {Jose Manuel},
  timestamp = {2009.03.12}
}

@ARTICLE{petrovic04,
  author = {Ana Petrovic and Oscar {Divorra Escoda} and Pierre Vandergheynst},
  title = {{Multiresolution Segmentation of Natural Images: From Linear to Nonlinear
	Scale--Space Representations}},
  journal = {IEEE Transactions on Image Processing},
  year = {2004},
  volume = {13},
  pages = {1104--1114},
  number = {8},
  month = aug,
  language = {english}
}

@ARTICLE{pinoli97,
  author = {Jean--Charles Pinoli},
  title = {A General Comparative Study of the Multiplicative Homomorphic, Log--Ratio
	and Logarithmic Image Processing Approaches},
  journal = {Signal Processing},
  year = {1997},
  volume = {58},
  pages = {11--45},
  number = {1},
  month = apr,
  abstract = {This article presents a comparative study of the multiplicative homomorphic
	image processing (MHIP), the log-ratio image processing (LRIP) and
	the logarithmic image processing (LIP). These three image processing
	approaches are based on abstract linear mathematics and provide specific
	operations and structures that have opened up new pathways to the
	development of image processing techniques. The MHIP approach was
	designed for the processing of multiplied images, the LRIP approach
	was introduced to overcome the out-of-range problem associated with
	many image processing techniques, while the LIP approach was developed
	for the processing of images valued in a bounded intensity range.
	First, it is claimed that an image processing framework must be physically
	relevant, mathematically consistent, computationally tractable and
	practically fruitful. It is also pointed out that the classical linear
	image processing (CLIP) is not adapted to non-linear and/or bounded
	range images or imaging systems, such as transmitted light images,
	practical digital images or the human brightness perception system.
	Then, the importance and usefulness of several mathematical fields,
	such as abstract linear algebra and abstract analysis, for image
	representation and processing within such image settings are discussed.
	Third, the MHIP, LRIP and LIP approaches are presented, focusing
	on their distinctive ideas, structures and properties for image representation
	and processing, rather than an in-depth review. Next, a study of
	the relationships and differences between their image representations
	and basic algebraic operations is detailed. Finally, a general comparative
	discussion is developed, showing the main physical, mathematical,
	computational and practical characteristics of these three abstract-linear-mathematics-based
	image processing approaches, and summarizing their respective advantages
	and disadvantages. It is concluded and highlighted through real application
	examples in both image enhancement and edge detection areas that
	the LIP approach surpasses the two other approaches, although, from
	a strictly practical point of view, a detailed quantitative comparative
	study on real applications is now necessary.},
  doi = {10.1016/S0165-1684(97)00011-X},
  file = {A general comparative study of the multiplicative homomorphic, log-ratio and logarithmic image processing approaches (JC Pinoli) Signal Proc 58 (1) pp 11-45 (1997).pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\LIP\\A general comparative study of the multiplicative homomorphic, log-ratio and logarithmic image processing approaches (JC Pinoli) Signal Proc 58 (1) pp 11-45 (1997).pdf:PDF},
  keywords = {LIP, Logarithmic image processing, abstract linear mathematics, human
	brightness perception, image processing, image representation, log--ratio
	image processing, multiplicative homomorphic image processing, reflected
	light images, transmitted light images},
  language = {english}
}

@ARTICLE{pinoli97b,
  author = {Jean--Charles Pinoli},
  title = {The Logarithmic Image Processing Model: Connections with Human Brightness
	Perception and Contrast Estimators},
  journal = {Journal of Mathematical Imaging and Vision},
  year = {1997},
  volume = {7},
  pages = {341--358},
  number = {4},
  abstract = {The logarithmic image processing (LIP) model is a mathematical framework
	based on abstract linear mathematics which provides a set of specific
	algebraic and functional operations that can be applied to the processing
	of intensity images valued in a bounded range. The LIP model has
	been proved to be physically justified in the setting of transmitted
	light and to be consistent with several laws and characteristics
	of the human visual system. Successful application examples have
	also been reported in several image processing areas, e.g., image
	enhancement, image restoration, three-dimensional image reconstruction,
	edge detection and image segmentation. The aim of this article is
	to show that the LIP model is a tractable mathematical framework
	for image processing which is consistent with several laws and characteristics
	of human brightness perception. This is a survey article in the sense
	that it presents (almost) previously published results in a revised,
	refined and self-contained form. First, an introduction to the LIP
	model is exposed. Emphasis will be especially placed on the initial
	motivation and goal, and on the scope of the model. Then, an introductory
	summary of mathematical fundamentals of the LIP model is detailed.
	Next, the article aims at surveying the connections of the LIP model
	with several laws and characteristics of human brightness perception,
	namely the brightness scale inversion, saturation characteristic,
	Weber‘s and Fechner‘s laws, and the psychophysical contrast notion.
	Finally, it is shown that the LIP model is a powerful and tractable
	framework for handling the contrast notion. This is done through
	a survey of several LIP-model-based contrast estimators associated
	with special subparts (point, pair of points, boundary, region) of
	intensity images, that are justified both from a physical and mathematical
	point of view.},
  doi = {http://dx.doi.org/10.1023/A:1008259212169},
  file = {The Logarithmic Image Processing Model (JC Pinoli) J. Math. .pdf:home/jose/Documentos/articulos/LIP/The Logarithmic Image Processing Model (JC Pinoli) J. Math. .pdf:PDF},
  keywords = {LIP},
  language = {english},
  owner = {Jose Manuel},
  timestamp = {13/10/2005}
}

@INPROCEEDINGS{potmesil83,
  author = {M. Potmesil and I. Chakravarty},
  title = {{Modeling Motion Blur in Computer--Generated Images}},
  booktitle = {Proceedings of the 10th Annual Conference on Computer Graphics and
	Interactive Techniques, SIGGRAPH'83},
  year = {1983},
  pages = {389--399},
  address = {Detroit (MI), USA},
  month = jul,
  language = {english},
  optpublisher = {#ACM#}
}

@INPROCEEDINGS{powell82,
  author = {P. G. Powell and B. E. Bayer},
  title = {{A Method for the Digital Enhancement of Unsharp, Grainy Photographic
	Images}},
  booktitle = {Proceedings of the IEEE International Conference on Electronic Image
	Processing},
  year = {1982},
  pages = {179--183},
  month = jul,
  language = {english}
}

@BOOK{pratt01,
  title = {Digital Image Processing: {PIKS} Inside},
  publisher = {John Wiley \& Sons, Inc.},
  year = {2001},
  author = {Pratt, William K.},
  series = {ISBN: 0--471--22132--5},
  address = {New York City (NY), USA.},
  edition = {3},
  file = {Digital Image Processing (William K. Pratt) Ed. Wiley - 3rd Ed.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\libros\\Image & Video Processing\\Digital Image Processing (William K. Pratt) Ed. Wiley - 3rd Ed.pdf:PDF},
  language = {english}
}

@BOOK{pratt91,
  title = {Digital Image Processing},
  publisher = {John Wiley \& Sons, Inc.},
  year = {1991},
  author = {Pratt, William K.},
  edition = {2},
  language = {english}
}

@INBOOK{prewitt70,
  chapter = {Object Enhancenment and Extraction},
  title = {Picture Processing and Psychopictorics},
  publisher = {Academic Press},
  year = {1970},
  editor = {Lipkin, B.S. and Rosenfeld, A.},
  author = {Prewitt, J.M.S.},
  address = {New York},
  language = {english},
  owner = {jose},
  timestamp = {2009.08.22}
}

@ARTICLE{radke05,
  author = {Radke, Richard J. and Andra, Srinivas and Al--Kafahi, Omar and Roysam,
	Badrinath},
  title = {Image change detection algorithms: a systematic survey},
  journal = {IEEE Transactions on Image Processing},
  year = {2005},
  volume = {14},
  pages = {294--307},
  number = {3},
  month = mar,
  abstract = {Detecting regions of change in multiple images of the same scene taken
	at different times is of widespread interest due to a large number
	of applications in diverse disciplines, including remote sensing,
	surveillance, medical diagnosis and treatment, civil infrastructure,
	and underwater sensing. This paper presents a systematic survey of
	the common processing steps and core decision rules in modern change
	detection algorithms, including significance and hypothesis testing,
	predictive models, the shading model, and background modeling. We
	also discuss important preprocessing methods, approaches to enforcing
	the consistency of the change mask, and principles for evaluating
	and comparing the performance of change detection algorithms. It
	is hoped that our classification of algorithms into a relatively
	small number of categories will provide useful guidance to the algorithm
	designer.},
  doi = {10.1109/TIP.2004.838698},
  file = {Image Change Detection Algorithms_A Systematic Survey (Radke et al.).pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\change detection\\Image Change Detection Algorithms_A Systematic Survey (Radke et al.).pdf:PDF},
  key = {andr03},
  keywords = {Change Detection},
  language = {english}
}

@ARTICLE{radke03,
  author = {Radke, Richard J. and Andra, Srinivas and Al--Kafahi, Omar and Roysam,
	Badrinath},
  title = {Image change detection algorithms: a systematic survey ({DRAFT})},
  journal = {IEEE Transactions on Image Processing},
  year = {2003},
  volume = {N/A},
  pages = {1--30},
  file = {radketip03.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\change detection\\radketip03.pdf:PDF},
  keywords = {Change Detection},
  language = {english}
}

@ARTICLE{ramponi98,
  author = {Giovanni Ramponi},
  title = {{A Cubic Unsharp Masking Technique for Contrast Enhancement}},
  journal = {Signal Processing},
  year = {1998},
  volume = {67},
  pages = {211--222},
  number = {2},
  month = jun,
  abstract = {The cubic unsharp masking method is introduced in this paper. It is
	demonstrated, through both a statistical study and some computer
	simulations, that the proposed method has a much reduced noise sensitivity
	with respect to the linear unsharp masking technique and it permits
	to obtain perceptually pleasant results. The proposed operator also
	compares favourably with other algorithms which recently have been
	studied to improve the behaviour of the unsharp masking approach.},
  doi = {http://dx.doi.org/10.1016/S0165-1684(98)00038-3},
  file = {A cubic unsharp masking technique for contrast enhancenment (G Ramponi).pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\LIP\\A cubic unsharp masking technique for contrast enhancenment (G Ramponi).pdf:PDF},
  keywords = {image enhancement, image processing, nonlinear filtering, unsharp
	masking},
  language = {english}
}

@ARTICLE{rash08,
  author = {Rash, Clarence E.},
  title = {A 25-year retrospective review of visual complaints and illusions
	associated with a monocular helmet-mounted display},
  journal = {Displays},
  year = {2008},
  volume = {29},
  pages = {70--80},
  number = {2},
  month = mar,
  abstract = {In the early 1980s the U.S. Army fielded the first integrated helmet-mounted
	display (HMD) for use in the AH-64 Apache helicopter. To reduce head-supported
	weight and minimize center-of-mass offsets, a monocular optical design
	was selected. Although early design concerns of binocular rivalry
	and the Pulfrich phenomenon never materialized, user surveys have
	documented persistent reports of visual complaints and illusions
	in peacetime training flights. However, a recent evaluation conducted
	under battle conditions in Operation Iraqi Freedom found statistically
	lower reports of complaints and illusions. While these reported problems
	are short-term, questions have been raised regarding potential long-term
	physiological effects resulting from long-term use of this monocular
	display. A 10-year longitudinal study, currently underway in the
	U.K., has been implemented to definitively answer the question of
	whether long-term exposure produces any degradation in binocular
	visual function.},
  doi = {10.1016/j.displa.2007.09.011},
  language = {english},
  owner = {jose},
  timestamp = {2008.10.17}
}

@INBOOK{roberts65,
  chapter = {Machine Perception of Three-Dimensional Solids},
  pages = {159-197},
  title = {Optical and Electro-Optical Information Processing},
  publisher = {MIT Press},
  year = {1965},
  editor = {J.T. Tippett and D.A. Berkowitz and L.C. Clapp and C.J. Koester and
	A. Vanderburgh, Jr.},
  author = {L.G. Roberts},
  address = {Cambridge, Massachusetts, USA},
  language = {english},
  owner = {jose},
  timestamp = {2008.12.27}
}

@INPROCEEDINGS{ros06,
  author = {Ros, Eduardo and Díaz, Javier and Mota, Sonia and Vargas--Martin,
	Fernando and Peláez--Coca, M.D.},
  title = {Real Time image processing on a portable aid device for low vision
	patients},
  booktitle = {ARC 2006},
  year = {2006},
  editor = {Bertels, K. and Cardoso, J.M.P. and Vassiliadis, S.},
  series = {LNCS 3985},
  pages = {158--163},
  publisher = {Springer--Verlag, Berlin Heidelberg},
  language = {english},
  owner = {Jose Manuel},
  timestamp = {2009.03.12}
}

@INPROCEEDINGS{rosin98,
  author = {Rosin, Paul},
  title = {Thresholding for change detection},
  booktitle = {Proceedings of International Conference on Computer Vision {{ICCV}--1998}},
  year = {1998},
  pages = {274--279},
  key = {rosi98},
  language = {english}
}

@ARTICLE{rosin03,
  author = {Rosin, Paul and Ioannidis, Efstathios},
  title = {Evaluation of global image thresholding for change detection},
  journal = {Pattern Recognition Letters},
  year = {2003},
  volume = {24},
  pages = {2345--2356},
  key = {rosi03},
  language = {english}
}

@BOOK{rudin70,
  title = {Real and Complex Analysis},
  publisher = {McGraw--Hill, Inc.},
  year = {1970},
  author = {Rudin, Walter},
  series = {Higher Mathematical Series},
  address = {Ljubljana, Slovenja.},
  edition = {International Student Edition.},
  file = {Real And Complex Analysis (Rudin).pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\libros\\matematicas\\Real And Complex Analysis (Rudin).pdf:PDF},
  language = {english}
}

@ARTICLE{russell85,
  author = {Russell, PW and Sekuler, R and Fetkenhour, C},
  title = {Visual function after pan--retinal photocoagulation: a survey},
  journal = {Diabetes Care},
  year = {1985},
  volume = {8},
  pages = {57--63},
  language = {english},
  owner = {jose},
  timestamp = {2008.10.02}
}

@MISC{scharr00,
  author = {H. Scharr and J. Weickert},
  title = {An anisotropic diffusion algorithm with optimized rotation invariance},
  year = {2000},
  language = {english},
  text = {H. Scharr and J. Weickert. An anisotropic diffusion algorithm with
	optimized rotation invariance. In G. Sommer, N. Kr uger, C. Perwass
	(Eds.), Mustererkennung 2000.},
  url = {http://citeseer.ist.psu.edu/scharr00anisotropic.html}
}

@ARTICLE{shapiro65,
  author = {Shapiro, S.S. and Wilk, M.B.},
  title = {An analysis of variance test for normality (complete samples)},
  journal = {Biometrika},
  year = {1965},
  volume = {52},
  pages = {591--611},
  number = {3--4},
  doi = {http://dx.doi.org/10.1093/biomet/52.3-4.591},
  language = {english},
  owner = {jose},
  timestamp = {2010.05.28}
}

@ARTICLE{sheehan01,
  author = {Sheehan, Kim},
  title = {E-mail Survey Response Rates: A Review},
  journal = {Journal of Computer--Mediated Communication},
  year = {2001},
  volume = {6},
  pages = {1--13},
  number = {2},
  month = jan,
  abstract = {Electronic mail (e-mail) has been used to distribute surveys and collect
	data from online users for almost fifteen years. However, some have
	suggested that the use of e-mail is becoming obsolete. This study
	analyzes response rates to e-mail surveys undertaken since 1986 and
	examines five influences to response rates: the year the study was
	undertaken, the number of questions in the survey, the number of
	pre-notification contacts, the number of follow-up contacts and survey
	topic salience. Response rates to e-mail surveys have significantly
	decreased since 1986. Correlation and regression analyses suggest
	that year that the survey was undertaken and number of follow-up
	contacts had the most influence on response rates. A discussion of
	other influences and future research into this area is provided.},
  howpublished = {http://jcmc.indiana.edu/vol6/issue2/sheehan.html},
  language = {english},
  owner = {jose},
  timestamp = {2010.03.15}
}

@INPROCEEDINGS{shin98,
  author = {Shin, M.C. and Goldgof, D. and Bowyer, Kevin W.},
  title = {An Objective Comparison Methodology of Edge Detection Algorithms
	Using a Structure from Motion Task},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
  year = {1998},
  pages = {190--195},
  address = {Santa Barbara, CA, USA},
  month = jun,
  publisher = {IEEE Computer Society},
  abstract = {This paper presents a task-oriented evaluation methodology for edge
	detectors. Performance is measured based on the task of structure
	from motion. Eighteen real image sequences from 2 different scenes
	varying in the complexity and scenery types are used. The task-level
	ground truth for each image sequence is manually specified in terms
	of the 3D motion and structure. An automated tool computes the accuracy
	of the motion and structure achieved using the set of edge maps.
	Parameter sensitivity and execution speed are also analyzed. Four
	edge detectors are compared. All implementations and data sets are
	publicly available},
  doi = {10.1109/CVPR.1998.698608},
  language = {english},
  owner = {jose},
  timestamp = {2008.07.29}
}

@ARTICLE{shirai94,
  author = {Y. Shirai},
  title = {Performance Characterization in Computer Vision},
  journal = {CVGIP: Image Understanding},
  year = {1994},
  volume = {60},
  pages = {260 - 261},
  number = {2},
  doi = {DOI: 10.1006/ciun.1994.1054},
  issn = {1049-9660},
  language = {english},
  owner = {jose},
  timestamp = {2008.12.29},
  url = {http://www.sciencedirect.com/science/article/B6WDD-45P0W80-T/2/5a15478b8a84d292e1b7f146e31b264e}
}

@ARTICLE{shrout79,
  author = {Shrout, Patrick E. and Fleiss, Joseph L.},
  title = {Intraclass Correlations: Uses in assessing rater reliability},
  journal = {Psychological Bulletin},
  year = {1979},
  volume = {86},
  pages = {420--428},
  number = {2},
  language = {english},
  owner = {jose},
  timestamp = {2010.05.09}
}

@ARTICLE{shvayster87,
  author = {Shvayster, Haim and Peleg, Shmuel},
  title = {Inversion of picture operators},
  journal = {Pattern Recognition Letters},
  year = {1987},
  volume = {5},
  pages = {49--61},
  number = {1},
  month = jan,
  abstract = {Inversion of operators on picturesnext term is shown to be an important
	part of classical image restoration techniques. A method is presented
	for nonlinear previous terminversion of operatorsnext term that enables
	nonlinear restoration. The problem of out of range values is handled
	by introducing a new definition for operations on previous termpicturesnext
	term such that the set of all previous termpicturesnext term is a
	vector space. It is empirically shown that the Conjugate Gradients
	algorithm converges quickly in this vector space and enables previous
	terminversion of operatorsnext term on big previous termpicturesnext
	term with relatively little computation. Examples are given for applications
	of this method to linear and nonlinear previous termoperators.next
	term},
  doi = {10.1016/0167-8655(87)90025-0},
  keywords = {LRIP},
  language = {english}
}

@INPROCEEDINGS{shvayster83,
  author = {Shvayster, Haim and Peleg, Shmuel},
  title = {Pictures as elements in a vector space},
  booktitle = {Proceedings of the 1983 IEEE Conference on Computer Vision and Pattern
	Recognition},
  year = {1983},
  volume = {1},
  pages = {442--446},
  address = {Washington, USA.},
  month = jun,
  keywords = {LRIP},
  language = {english}
}

@ARTICLE{skifstad89,
  author = {Skifstad, Kurt and Jain, Ramesh},
  title = {Illumination independent Change Detection for real world image sequences},
  journal = {Computer Vision, Graphics and Image Processing},
  year = {1989},
  volume = {46},
  pages = {387--399},
  number = {3},
  month = jun,
  key = {skif89},
  language = {english}
}

@TECHREPORT{sloane92,
  author = {Sloane, ME and Ball, K and Owsley, C},
  title = {The visual activities questionnaire: developing an instrument for
	assessing problems in everyday visual tasks},
  institution = {Optical Society of America: OSA Tech Dig Noninvasive Assess Vis Sys},
  year = {1992},
  number = {1},
  address = {Washington DC., USA},
  note = {pp. 26--29},
  language = {english},
  owner = {jose},
  timestamp = {2008.10.02}
}

@PHDTHESIS{sobelPhD,
  author = {Sobel, Irwin},
  title = {Camera Models and Machine Perception},
  school = {Standford University},
  year = {1970},
  type = {Ph.D. thesis},
  language = {english},
  owner = {jose},
  timestamp = {2008.07.28}
}

@UNPUBLISHED{sobel68,
  author = {Sobel, Irwin and Feldman, G.},
  title = {A 3x3 Isotropic Gradient Operator for Image Processing},
  note = {Talk at the Stanford Artificial Project},
  year = {1968},
  language = {english},
  owner = {jose},
  timestamp = {2008.01.09}
}

@MISC{wikitudeWeb,
  author = {Mobilizy Mobile Software},
  title = {Wikitude},
  month = sep,
  year = {2010},
  language = {english},
  owner = {jose},
  timestamp = {2010.09.21},
  url = {http://www.wikitude.org}
}

@ARTICLE{steinberg94,
  author = {Steinberg, EP and Tielsch, JM and Schein, OD},
  title = {The VF-14. An index of functional impairment in patients with cataract},
  journal = {Arch Ophthalmol},
  year = {1994},
  volume = {112},
  pages = {630--638},
  language = {english},
  owner = {jose},
  timestamp = {2008.10.02}
}

@ARTICLE{stockham72,
  author = {{Stockham JR.}, {Thomas G.}},
  title = {Image Processing in the context of a visual model},
  journal = {Proceedings of the IEEE},
  year = {1972},
  volume = {60},
  pages = {828--842},
  month = jul,
  key = {stoc72},
  language = {english}
}

@ARTICLE{szlyk90,
  author = {Szlyk, JP and Arditi, A and Coffey-Bucci, P},
  title = {Self-report in functional assessment of low vision},
  journal = {Journal of Visually Impaired and Blind},
  year = {1990},
  volume = {84},
  pages = {61--66},
  language = {english},
  owner = {jose},
  timestamp = {2008.10.02}
}

@ELECTRONIC{cuestionarioEng,
  author = {{The American Heritage Dictionary of the English Language}},
  title = {``questionnaire''},
  language = {English},
  howpublished = {Fourth Edition.},
  organization = {Houghton Mifflin Company, 2004.},
  note = {Accessed: December 30, 2008.},
  url = {http://dictionary.reference.com/browse/questionnaire.},
  chapter = {questionnaire},
  keywords = {Questionnaires},
  owner = {jose},
  timestamp = {2008.12.30}
}

@ELECTRONIC{sesgoEng,
  author = {{The American Heritage Dictionary of the English Language}},
  title = {``bias''},
  language = {English},
  howpublished = {Fourth Edition},
  organization = {Houghton Mifflin Company, 2004.},
  note = {Accessed: December 30, 2008.},
  url = {http://dictionary.reference.com/browse/bias},
  keywords = {Questionnaires},
  owner = {jose},
  timestamp = {2008.12.30}
}

@ARTICLE{thorpe01,
  author = {S. Thorpe and A. Delorme and R. Van Rullen},
  title = {{Spike--Based Strategies for Rapid Processing}},
  journal = {Neural Networks},
  year = {2001},
  volume = {14},
  pages = {715--725},
  number = {6-7},
  month = {July--September},
  note = {Special Issue.},
  language = {english}
}

@INPROCEEDINGS{thorpe00,
  author = {S. Thorpe and A. Delorme and R. Van Rullen and W. Paquier},
  title = {{Reverse Engineering of the Visual System using Networks of Spiking
	Neurons}},
  booktitle = {Proceedings of the IEEE International Symposium on Circuits and Systems,
	{{ISCAS}--2000}},
  year = {2000},
  volume = {4},
  pages = {405--408},
  address = {Geneva, Switzerland},
  month = apr,
  language = {english}
}

@ARTICLE{thorpe96,
  author = {S. Thorpe and D. Fize and C. Marlot},
  title = {{Speed of Processing in the Human Visual System}},
  journal = {Nature},
  year = {1996},
  volume = {6582},
  pages = {520--522},
  number = {381},
  month = jun,
  language = {english}
}

@INPROCEEDINGS{toth00,
  author = {Toth, Daniel and Aach, Til and Metzler, Volker},
  title = {Illumination--Invariant Change Detection},
  booktitle = {Proceedings of the 4th IEEE Southwest Symposium on Image Analysis
	and Interpretation, {{SSIAI}--00}},
  year = {2000},
  pages = {3--7},
  address = {Austin, Texas, USA},
  month = apr,
  isbn = {0-7695-0595-3},
  keywords = {Change Detection, Homomorphic Filtering},
  language = {english}
}

@INPROCEEDINGS{toth00b,
  author = {Toth, Daniel and Aach, Til and Metzler, Volker},
  title = {Bayesian Spatio--Temporal Motion Detection under Varying Illumination},
  booktitle = {Proceedings of European Signal Processing Conference 2000 {{EUSIPCO}--2000}},
  year = {2000},
  pages = {2081--2084},
  address = {Tampere, Finland},
  month = sep,
  file = {Bayesian Spatio--Temporal Motion Detection under Varying Illumination (Toth, Aach and Metzler) EUPSICO-00, 2081--2084.pdf:F\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\change detection\\Bayesian Spatio--Temporal Motion Detection under Varying Illumination (Toth, Aach and Metzler) EUPSICO-00, 2081--2084.pdf:PDF},
  keywords = {Change Detection, Homomorphic Filtering},
  language = {english}
}

@ARTICLE{valera05,
  author = {Valera, M. and Velastin, S.A.},
  title = {Intelligent distributed surveillance systems: a review},
  journal = {IEE Proceedings - Vision, Image and Signal Processing},
  year = {2005},
  volume = {152},
  pages = {192--204},
  number = {2},
  month = apr,
  abstract = {This survey describes the current state-of-the-art in the development
	of automated visual surveillance systems so as to provide researchers
	in the field with a summary of progress achieved to date and to identify
	areas where further research is needed. The ability to recognise
	objects and humans, to describe their actions and interactions from
	information acquired by sensors is essential for automated visual
	surveillance. The increasing need for intelligent visual surveillance
	in commercial, law enforcement and military applications makes automated
	visual surveillance systems one of the main current application domains
	in computer vision. The emphasis of this review is on discussion
	of the creation of intelligent distributed automated surveillance
	systems. The survey concludes with a discussion of possible future
	directions.},
  doi = {10.1049/ip-vis:20041147},
  file = {intelligent distributed surveillance systems_ a review (Valera and Velastin) IEE Proc - Vis, Img and Sig Proc. pdf.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\nuevos\\intelligent distributed surveillance systems_ a review (Valera and Velastin) IEE Proc - Vis, Img and Sig Proc. pdf.pdf:PDF},
  language = {english},
  owner = {jose},
  timestamp = {2008.10.17}
}

@ARTICLE{vanrullen01,
  author = {R. {Van Rullen} and S. Thorpe},
  title = {{Rate Coding Versus Temporal Order Coding: What the retinal Ganglion
	Cells tell the Visual Cortex}},
  journal = {Neural Computation},
  year = {2001},
  volume = {13},
  pages = {1255--1283},
  number = {6},
  month = jun,
  language = {english}
}

@ARTICLE{vanrullen02,
  author = {{Van Rullen}, Rufin and Thorpe, Simon J.},
  title = {Surfing a spike wave down the ventral stream},
  journal = {Vision Research},
  year = {2002},
  volume = {42},
  pages = {2593--2615},
  abstract = {Numerous theories of neural processing, often motivated byexperimental
	observations, have explored the computational properties of neural
	codes based on the absolute or relative timing of spikes in spike
	trains. Spiking neuron models and theories however, as well as their
	experimental counterparts, have generallybeen limited to the simulation
	or observation of isolated neurons, isolated spike trains, or reduced
	neural populations. Such theories would therefore seem inappropriate
	to capture the properties of a neural code relying on temporal spike
	patterns distributed across large neuronal populations. Here we report
	a range of computer simulations and theoretical considerations that
	were designed to explore the possibilities of one such code and its
	relevance for visual processing. In a unified framework where the
	relation between stimulus saliencyand spike relative timing plays
	the central role, we describe how the ventral stream of the visual
	system could process natural input scenes and extract meaningful
	information, both rapidlyand reliably. The first wave of spikes generated
	in the retina in response to a visual stimulation carries information
	explicitlyin its spatio-temporal structure: the most salient information
	is represented by the first spikes over the population. This spike
	wave, propagating through a hierarchyof visual areas, is regenerated
	at each processing stage, where its temporal structure can be modified
	by(i) the selectivityof the cortical neurons, (ii) lateral interactions
	and (iii) top-down attentional influences from higher order cortical
	areas. The resulting model could account for the remarkable efficiencyand
	rapidityof processing observed in the primate visual system.},
  keywords = {Rank Order Coding},
  language = {english},
  owner = {jose},
  timestamp = {2009.11.01}
}

@ARTICLE{vargas03,
  author = {Vargas--Martin, Fernando},
  title = {A free--cost visual field expander for peripheral vision loss},
  journal = {Journal of Vision},
  year = {2003},
  volume = {3},
  pages = {40--40},
  number = {12},
  month = dec,
  abstract = {Reversed Galilean telescopes have been used for rehabilitation of
	peripheral visual field loss and are commercially available with
	a magnification up to x0.5. A more cost effective visual field expander
	is constructed by making very minor modifications to off-the-shelf
	photographic viewfinders from cheap, disposable cameras. These devices
	can be mounted as spectacles either centrally or peripherally (e.g.
	bioptic). Optical properties are analyzed objectively with a high
	resolution web cam. Additionally, expansion of the visual field in
	subjects is demonstrated by perimetry. Several different types of
	viewfinders were tested although most of the viewfinders used in
	this study had a 20 degree field of view with x0.5 magnification.
	Comments on the ease of using the visual field expander as well as
	the advantages and disadvantages between different types of viewfinders
	are presented. Since creating low cost devices is one of the major
	goals in low vision aid design (especially in underdeveloped countries),
	the proposed viewfinders could be a cheaper and more practical solution
	for visual field expanders.},
  language = {english},
  url = {http://journalofvision.org/3/12/40/}
}

@ARTICLE{vargas02,
  author = {Vargas--Martin, Fernando and Peli, Eli},
  title = {Augmented--View for restricted visual field: Multiple Device Implementations},
  journal = {Optometry and Vision Science},
  year = {2002},
  volume = {79},
  pages = {715--723},
  number = {11},
  abstract = {Purpose. An augmented-view device for patients with severely restricted
	peripheral visual fields (tunnel vision) was proposed, combining
	a see-through head-mounted display and a simultaneous minified view
	of a wide field presented as contour information. Here we create
	and evaluate multiple implementations of the augmented-view concept
	and report responses from potential users. Methods. Several prototypes
	using commercial off-the-shelf devices were implemented. Then they
	were evaluated in real environments in daylight and at night by two
	retinitis pigmentosa patients. Results. Effective expansion of the
	visual field of patients was achieved. Patients indicated their preferences
	for different properties, devices, and combinations. Conclusions.
	Patients found the augmented-view concept of help for their impairment,
	but wanted much more ergonomic design than the prototypes provided.
	Benefits, limitations, and possible improvements for the evaluated
	devices are discussed.},
  doi = {1040-5488/02/7911-0715/0},
  file = {OVS02AugView.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\Low-Vision\\OVS02AugView.pdf:PDF},
  language = {english},
  owner = {jose},
  timestamp = {2007.08.10}
}

@BOOK{vernon91,
  title = {{Machine Vision --- Automated Visual Inspection and Robot Vision}},
  publisher = {Prentice--Hall, Inc.},
  year = {1991},
  author = {D. Vernon},
  language = {english}
}

@BOOK{walonick04,
  title = {Excerpts from: ``Survival Statistics''},
  publisher = {StatPac, Inc.},
  year = {2004},
  author = {David S. Walonick},
  address = {Bloomington, MN, USA},
  note = {ISBN: 0-918733-11-1},
  language = {english},
  owner = {jose},
  timestamp = {2009.01.01}
}

@ARTICLE{wang94,
  author = {Wang, John Y.A. and Adelson, Edward H.},
  title = {Representing moving Images with layers},
  journal = {IEE Transactions on Image Processing},
  year = {1994},
  volume = {3},
  pages = {625--638},
  number = {5},
  month = sep,
  key = {wang94},
  language = {english}
}

@BOOK{watt91,
  title = {{Understanding Vision}},
  publisher = AcadPress,
  year = {1991},
  author = {R. Watt},
  language = {english}
}

@ARTICLE{weng94,
  author = {J. Y. Weng and T. S. Huang},
  title = {Performance of Computer Vision Algorithms},
  journal = {CVGIP: Image Understanding},
  year = {1994},
  volume = {60},
  pages = {253 - 256},
  number = {2},
  doi = {DOI: 10.1006/ciun.1994.1052},
  issn = {1049-9660},
  language = {english},
  owner = {jose},
  timestamp = {2008.12.29},
  url = {http://www.sciencedirect.com/science/article/B6WDD-45P0W80-R/2/f98e64c91604e72dbde9dd3096bf9ccb}
}

@MISC{wikipediaEng,
  author = {{Wikimedia Foundation, Inc.}},
  title = {{English Wikipedia}},
  howpublished = {Website},
  month = aug,
  year = {2008},
  language = {english},
  owner = {jose},
  timestamp = {2008.08.01},
  url = {http://en.wikipedia.org}
}

@INPROCEEDINGS{winkler07,
  author = {Winkler, Stefan},
  title = {Video Quality and Beyond},
  booktitle = {Proceedings of the European Signal Processing Conference},
  year = {2007},
  address = {Poznan, Poland},
  month = {september 3--7},
  note = {invited paper},
  language = {english},
  owner = {Jose Manuel},
  timestamp = {2009.04.10}
}

@BOOK{winkler05,
  title = {Digital Video Quality --- Vision Models and Metrics},
  publisher = {John Wiley \& Sons, Inc.},
  year = {2005},
  author = {Winkler, Stefan},
  note = {ISBN 0-470-02404-6},
  abstract = {Visual quality assessment is an interdisciplinary topic that links
	image/video processing, psychology and physiology. Many engineers
	are familiar with the image/video processing; transmission networks
	side of things but not with the perceptual aspects pertaining to
	quality. Digital Video Quality first introduces the concepts of human
	vision and visual quality. Based on these, specific video quality
	metrics are developed and their design is presented. These metrics
	are then evaluated and used in a number of applications, including
	image/video compression, transmission and watermarking. Introduces
	the concepts of human vision and vision quality. Presents the design
	and development of specific video quality metrics. Evaluates video
	quality metrics in the context of image/video compression, transmission
	and watermarking. Presents tools developed for the analysis of video
	quality},
  language = {english},
  owner = {jose},
  timestamp = {2008.06.22},
  url = {http://books.google.com/books?id=NDNfMaht37cC}
}

@INPROCEEDINGS{witkin83,
  author = {A.P. Witkin},
  title = {{Scale--Space Filtering}},
  booktitle = {Proceedings of the International Joint Conference on Artificial Intelligence
	{IJCAI}},
  year = {1983},
  pages = {1019--1022},
  address = {Karlsruhe, Germany},
  language = {english}
}

@ARTICLE{wu02,
  author = {Quen--Zong Wu and Bor--Shen Jeng},
  title = {{Background Subtraction based on Logarithmic Intensities}},
  journal = {Pattern Recognition Letters},
  year = {2002},
  volume = {23},
  pages = {1529--1536},
  number = {13},
  doi = {10.1016/S0167-8655(02)00116-2},
  issn = {0167--8655},
  language = {english}
}

@ARTICLE{xu04,
  author = {Xiaoyin Xu and Eric Miller and Dongbin Chen and Mansoor Sarhadi},
  title = {{Adaptive Two--Pass Rank Order Filter to Remove Impulse Noise in
	Highly Corrupted Images}},
  journal = {IEEE Transactions on Image Processing},
  year = {2004},
  volume = {13},
  pages = {238--247},
  number = {2},
  language = {english},
  optdoi = {http://dx.doi.org/10.1109/TIP.2004.823827}
}

@ARTICLE{yitzhaky03,
  author = {Yitzhaky, Yitzhak and Peli, Eli},
  title = {A method for objective edge detection evaluation and detector parameter
	selection},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {2003},
  volume = {25},
  pages = {1027--1033},
  number = {8},
  month = aug,
  abstract = {Subjective evaluation by human observers is usually used to analyze
	and select an edge detector parametric setup when real-world images
	are considered. In this paper, we propose a statistical objective
	performance analysis and detector parameter selection, using detection
	results produced by different detector parameters. Using the correspondence
	between the different detection results, an estimated best edge map,
	utilized as an estimated ground truth (EGT), is obtained. This is
	done using both a receiver operating characteristics (ROC) analysis
	and a Chi-square test, and considers the trade off between information
	andnoisiness in the detection results. The best edge detector parameter
	set (PS) is then
	
	selected by the same statistical approach, using the EGT. Results
	are demonstrated for several edge detection techniques, and compared
	to published subjective evaluation results. The method developed
	here suggests a general tool to assist in practical implementations
	of parametric edge detectors where an automatic process is required.},
  file = {A method for objective edge detection evaluation and detector parameter selection (Y.Yitzhaky and E.Peli) IEEE PAMI 25(8) pp 1027-1034, Aug 2003.pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\Evaluation\\A method for objective edge detection evaluation and detector parameter selection (Y.Yitzhaky and E.Peli) IEEE PAMI 25(8) pp 1027-1034, Aug 2003.pdf:PDF},
  keywords = {Evaluation},
  language = {english},
  owner = {jose},
  timestamp = {2008.07.28}
}

@INPROCEEDINGS{zaharescu2005,
  author = {Zaharescu, E.},
  title = {Medical Image Enhancement using Logarithmic Image Processing},
  booktitle = {Proceeding of the 2005 Visualization, Imaging, and Image Processing
	{VIIP 2005}},
  year = {2005},
  editor = {J.J. Villanueva},
  volume = {1},
  number = {1},
  address = {Benidorm, Spain.},
  month = {7--9, September},
  abstract = {The logarithmic image processing theory is a mathematical framework
	that provides a set of specific algebraic and functional operations
	and structures that are well adapted to the representation and processing
	of non linear images, and more generally of non-linear signals, valued
	in a bounded intensity range. The purpose of this paper is to introduce
	a new mathematical LIP model focused on theoretical and practical
	aspects concerning the enhancement of the transmitted medical images
	and the physical absorption/transmission laws expressed within LIP
	mathematical framework. First of all the bounded interval (-1,1)
	is considered as the set of gray levels and we define two operations:
	addition <+> and real scalar multiplication <x>. With these operations,
	the set of gray levels becomes a real vector space. Then, defining
	the scalar product (.|.) and the norm || .|| , we obtain an Euclidean
	space of the gray levels. Secondly, we extend these operations and
	functions for color images. Finally, the experimental results, shown
	as enhanced medical images, reveal that this method has wide potential
	areas of impact which may include: Digital X ray, Digital Mammography,
	Computer Tomography Scans, Nuclear Magnetic Resonance Imagery and
	Telemedicine Applications.},
  keywords = {LIP},
  language = {english},
  url = {http://www.actapress.com/PaperInfo.aspx?PaperID=21719}
}

@INPROCEEDINGS{zhang2001,
  author = {Zhang, Yo Jin},
  title = {A Review of Recent Evaluation Methods for Image Segmentation},
  booktitle = {International Symposium on Signal Processing and its Applications
	(ISSPA)},
  year = {2001},
  pages = {148--151},
  address = {Kuala Lumpur, Malaysia},
  month = {13--16 August},
  organization = {Dept. of Microelectronics and Computer Engineering, (UTM, Malaysia)
	and Signal Processing Research Centre, (QUT, Australia)},
  publisher = {IEEE Computer Society Press},
  file = {a review of recent evaluation methods for image segmentation (Y.Zhang) Proceedings of the ISSPA2001, Kuala Lumpur, Malaysia (13-16 August 2001).pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\Evaluation\\a review of recent evaluation methods for image segmentation (Y.Zhang) Proceedings of the ISSPA2001, Kuala Lumpur, Malaysia (13-16 August 2001).pdf:PDF},
  language = {english},
  owner = {jose},
  timestamp = {2008.06.29}
}

@INPROCEEDINGS{zhong97,
  author = {Zhong, D. and Chang, S.--F.},
  title = {Video Object Model and Segmentation for Content--Based Video Indexing},
  booktitle = {IEEE International Symposium on Circuits and Systems},
  year = {1997},
  pages = {1492--1495},
  address = {Hong Kong},
  month = jun,
  key = {zhon97},
  language = {english}
}

@ARTICLE{zuidema83,
  author = {Zuidema, P. and Koenderink, J.J. and Bouman, M.A.},
  title = {A mechanistic approach to threshold behavior of the visual system},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  year = {1983},
  volume = {13},
  pages = {923–-933},
  language = {english},
  owner = {jose},
  timestamp = {2009.07.24}
}

@BOOK{bovik00,
  title = {Handbook of Image and Video Processing},
  publisher = {Academic Press},
  year = {2000},
  editor = {Bovik, Al},
  series = {ISBN: 0--12--119790--5},
  address = {San Diego (CA), USA and London, UK.},
  edition = {1},
  file = {Handbook of Image and Video Processing (Al Bovik) Academic Press - 2000 .pdf:C\:\\Documents and Settings\\jose.JURELICO2\\Mis documentos\\articulos\\libros\\Image & Video Processing\\Handbook of Image and Video Processing (Al Bovik) Academic Press - 2000 .pdf:PDF},
  key = {bovi00},
  language = {english}
}

@BOOK{mclachlan97,
  title = {The {EM} algorithm and Extensions},
  publisher = {Wiley Interscience},
  year = {1997},
  editor = {McLachlan, G.J. and Krishnan, T.},
  key = {mcla97},
  language = {english}
}

@BOOK{drae02,
  title = {{Diccionario de la Lengua Espa\~nola}},
  publisher = {{Real Academia Espa\~nola de la Lengua}},
  year = {2002},
  editor = {{R.A.E.}},
  volume = {1},
  edition = {22},
  language = {spanish},
  owner = {jose},
  timestamp = {2006.12.21}
}

@BOOK{rash01,
  title = {Helmet Mounted Displays: Design Issues for Rotary-wing Aircraft},
  publisher = {SPIE Press},
  year = {2001},
  editor = {Rash, Clarence E.},
  pages = {258},
  abstract = {The incorporation of technology into aviation has been exponential.
	Advancements in microelectronics, stealth technology, engine design,
	and electronic sensors and displays have converted simple aircraft
	into formidable flying machines. In this book, recognized experts
	in aviation helmet-mounted displays (HMDs) summarize 25 years of
	knowledge and experience in the area of HMD visual, acoustic, and
	biodynamic performance, and user interface issues such as sizing,
	fitting, and emergency egress.},
  language = {english},
  owner = {jose},
  timestamp = {2008.10.17},
  url = {http://books.google.es/books?id=fl6OpXvwmLEC}
}

@BOOK{tippett65,
  title = {Optical and Electro-Optical Information Processing},
  publisher = {MIT Press},
  year = {1965},
  editor = {J.T. Tippett and D.A. Berkowitz and L.C. Clapp and C.J. Koester and
	A. Vanderburgh, Jr.},
  address = {Cambridge, Massachusetts, USA},
  language = {english},
  owner = {jose},
  timestamp = {2008.12.27}
}

@MISC{baylor84a,
  howpublished = {http://jp.physoc.org/content/357/1/575.abstract},
  month = dec,
  year = {1984},
  language = {english},
  url = {http://jp.physoc.org/content/357/1/575.abstract}
}

@comment{jabref-meta: selector_publisher:Academic Press;Continuum;Else
vier;IEEE Computer Society Press;John Wiley & Sons, Inc.;McGraw--Hill,
 Inc.;MIT Press;Oxford University Press;Prentice--Hall, Inc.;SPIE Pres
s;Springer--Verlag, Berlin Heidelberg;{Real Academia Espa\\~nola de la
 Lengua};}

@comment{jabref-meta: selector_author:Aach, Til;Abdou, Ikram E.;Abidi,
 Besma;Abidi, Mongi;Al--Kafahi, Omar;Andra, Srinivas;Apfelbaum, D.;Apf
elbaum, H.;Baja Visi'on Angel Bara~nano;Baylor, D. A.;Bichsel, Martin;
Bovik, Al;Bowers, Alex;Bowyer, Kevin W.;Bradburn, Norman M.;Brostow, G
abriel J.;Bruni, Vittoria;Bruzzone, Lorenzo;Burgess, Thomas F.;Cahill,
 Lawrence W.;Canny, John;Castillo, Jos\\'e M.;Cavallaro, Andrea;Comani
ciu, Dorin;Courbebaisse, Guy;Davis, Larry S.;Dawson--Howe, Kenneth M.;
Debayle, Johan;Delorme, Arnaud;Deng, Guang;Deng, Yizong;Drelie Gelasca
, Elisa;Duc, Benoit;Durucan, Emrullah;Dusaussoy, Nicolas J.;Ebrahimi, 
Touradj;Elgammal, Ahmed;Erhardt--Ferron, Angelika;Essa, Irfan;Feldman,
 G.;Fern\\'andez Prieto, Diego;Foley, Hugh J.;G\\'omez--Luna, Juan;Gon
z\\'alez, Jes\\'us;Gonzalez, Rafael C.;Gottesfeld Brown, Lisa;Harwood,
 David;Hayes, Bob E.;Heath, Michael D.;J\\"ahne, Bernd;Jeng, Bor--Shen
;Jourlin, Michel;Kaup, Andr{\\'e};Lamb, T.D.;Liang, Jimin;Luo, Gang;Ma
rr, David;Matlin, Margaret W.;McKoen, Kevin;Meer, Peter;Mester, Rudolf
;Metzler, Volker;Mitckes, Mark;Navarro--Prieto, Raquel;Olivares, Joaqu
\\'in;OMS;Oppenheim, A. N.;Oppenheim, Alan V.;Palomares, Jos\\'e M.;Pa
trascu, Vasile;Peleg, Shmuel;Peli, Eli;Pinoli, Jean--Charles;Pratt, Wi
lliam K.;Prieto, Alberto;Radke, Richard J.;Ramponi, Giovanni;Rensing, 
Noa;Ros, Eduardo;Rosin, Paul;Roysam, Badrinath;Rubin, Donald B.;Rudin,
 Walter;Sanocki, Thomas;Sarkar, Sudeep;Schafer, Ronald W.;Shvayster, H
aim;Snoeckx, Joel;Sobel, Irwin;Stockham JR., Thomas G.;Sudman, Seymour
;Thorpe, Simon J.;Tobin, Geoffrey Richard;Toth,Daniel;Trunde, Frederic
;Vargas--Martin, Fernando;Visvanathan, Ramesh;Vitulano, Domenico;Wansi
nk, Brian;Weilenmann, Yves;win;Winkler, Stefan;Woods, R.;Woods, Richar
d E.;Wu, Quen--Zong;Yau, K.W.;Zaharescu, E.;Zhang, Yo Jin;Ziliani, Fra
ncesco;{Van Rullen}, Rufin;}

@comment{jabref-meta: selector_journal:Acta Stereologica;Computer Visi
on and Image Understanding;Electronic Letters on Computer Vision and I
mage Analysis;Electronics Letters;IEEE Spectrum (INT);IEEE Transaction
s on Audio and Electroacoustics;IEEE Transactions on Computers;IEEE Tr
ansactions on Image Processing;IEEE Transactions on Pattern Analysis a
nd Machine Intelligence;IEEE Transactions on Systems, Man, and Cyberne
tics;Image Analysis and Stereology;Image and Vision Computing;Journal 
of Biomedical Optics;Journal of Electronic Imaging;Journal of Mathemat
ical Imaging and Vision;Journal of Microscopy;Journal of Physiology;Jo
urnal of the Society for Information Display;Journal of Vision;Nature;
Neural Computation;Neural Networks;Neuroreport;Optometry and Vision Sc
ience;Pattern Recognition;Pattern Recognition Letters;Proceedings of t
he IEEE;Proceedings of the Royal Society of London Series B -- Biologi
cal Sciences;Signal Processing;Vision Research;}

@comment{jabref-meta: selector_keywords:Background Subtraction;ChangeD
etection;Evaluation;Gibbs Random Fields;Homomorphic Filtering;ImageQua
lity;LIP;Logarithmic Wavelet Transform;Low Vision;LRIP;Mean Shift;Moti
on detection;Optical Flow;Questionnaires;Rank Order Coding;Wavelet Tra
nsform;}

@comment{jabref-meta: groupsversion:3;}

@comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 ExplicitGroup:Automatically created groups\;2\;;
2 KeywordGroup:Logarithmic Wavelet Transform\;0\;keywords\;Logarithmic
 Wavelet Transform\;0\;0\;;
2 KeywordGroup:nonlinear filtering\;0\;keywords\;nonlinear filtering\;
0\;0\;;
2 KeywordGroup:image enhancement\;0\;keywords\;image enhancement\;0\;0
\;;
2 KeywordGroup:LIP\;0\;keywords\;LIP\;0\;0\;;
2 KeywordGroup:Mean Shift\;0\;keywords\;Mean Shift\;0\;0\;;
2 KeywordGroup:reflected light images\;0\;keywords\;reflected light im
ages\;0\;0\;;
2 KeywordGroup:transmitted light images\;0\;keywords\;transmitted ligh
t images\;0\;0\;;
2 KeywordGroup:log--ratio image processing\;0\;keywords\;log--ratio im
age processing\;0\;0\;;
2 KeywordGroup:Rank Order Coding\;0\;keywords\;Rank Order Coding\;0\;0
\;;
2 KeywordGroup:Change Detection\;0\;keywords\;Change Detection\;0\;0\;
;
2 KeywordGroup:abstract linear mathematics\;0\;keywords\;abstract line
ar mathematics\;0\;0\;;
2 KeywordGroup:human brightness perception\;0\;keywords\;human brightn
ess perception\;0\;0\;;
2 KeywordGroup:Logarithmic image processing\;0\;keywords\;Logarithmici
mage processing\;0\;0\;;
2 KeywordGroup:Wavelet Transform\;0\;keywords\;Wavelet Transform\;0\;0
\;;
2 KeywordGroup:Gibbs Random Fields\;0\;keywords\;Gibbs Random Fields\;
0\;0\;;
2 KeywordGroup:multiplicative homomorphic image processing\;0\;keyword
s\;multiplicative homomorphic image processing\;0\;0\;;
2 KeywordGroup:image processing\;0\;keywords\;image processing\;0\;0\;
;
2 KeywordGroup:unsharp masking\;0\;keywords\;unsharp masking\;0\;0\;;
2 KeywordGroup:image representation\;0\;keywords\;image representation
\;0\;0\;;
}

